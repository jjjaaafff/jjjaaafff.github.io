<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Causal Models | Aofan Jiang</title> <meta name="author" content="Aofan Jiang"> <meta name="description" content="Lecture Notes on Causal Inference"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <script src="https://code.iconify.design/iconify-icon/1.0.7/iconify-icon.min.js"></script> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.png"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jjjaaafff.github.io/blog/2021/causal4/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">{
      "title": "Causal Models",
      "description": "Lecture Notes on Causal Inference",
      "published": "July 13, 2021",
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span>Aofan Jiang (蒋傲凡)</span></a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="post distill"> <d-title> <h1>Causal Models</h1> <p>Lecture Notes on Causal Inference</p> </d-title> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#the-do-operator">The do-operator</a></div> <div><a href="#main-assumption-modularity">Main assumption-modularity</a></div> <div><a href="#backdoor-adjustment">Backdoor adjustment</a></div> <div><a href="#structural-causal-models">Structural causal models</a></div> </nav> </d-contents> <h2 id="the-do-operator">The do-operator</h2> <p>Conditioning vs. intervening</p> <ul> <li>Conditioning通过增加条件限制，将整体数据划分为一个子集，并针对该子集进行分析</li> <li>Intervening是对整体的所有数据采取同一个treatment，没有对其划分</li> </ul> <p>对于Interventional distributions，通常可记作</p> \[P(Y (t) = y) \triangleq P(Y = y \vert do(T = t)) \triangleq P(y \vert do(t))\] <p>在 Identification 的过程中，我们借助 Causal model 将 \(P(y\vert do(t))\) 转化为 \(P(y\vert t)\) (这是在没有confounder的情况下)。前者可由实验获取，后者可由观察数据获取。</p> <h2 id="main-assumption-modularity">Main assumption: modularity</h2> <p>在这里我们引入一个重要的假设，我们假设 the causal mechanisms are modular<br> 具体来说，在DAG中，如果我们 intervene on node \(X_i\)，则只改变\(P(x_i\vert parent(x_i))\)。对于其他 \(j \neq i\) 的节点，\(P(x_j\vert parent(x_j))\)保持不变。</p> <p>也就是说，我们通过do operation，对选取的intervene节点 \(X_i\)，将其概率\(P(x_i\vert parent(x_i))\)直接设置为1，而不再关注父节点对其的影响。(注意，这里为了一致性，我们需要保证\(x_i\)就是do operation中\(X_i\)被设置的值，否则概率为0)</p> <p>该假设还有其他称呼：independent mechanisms, autonomy, invariance, etc.</p> <p>基于这种假设，我们可以得到对应的数学表达形式，即</p> \[P(x_1,x_2,...,x_n\vert do(S=s)) = \prod_{i\neq S}P(x_i\vert parent(x_i))\] <p>回到 introduction中的例子，X 共同影响 T 和 Y，T 影响 Y，此时</p> \[P(y\vert do(t)) = \sum_xP(y,x\vert do(t)) = \sum_xP(x)P(y\vert t,x)\] <p>而</p> \[P(y\vert t) = \sum_xP(y,x\vert t) = \sum_xP(x\vert t)P(y\vert t,x)\] <p>可以看出\(P(y\vert do(t))\neq P(y\vert t)\)，这也从另一个角度说明了Association not equal causation</p> <h2 id="backdoor-adjustment">Backdoor adjustment</h2> <p>我们可以通过do-operation来消除其他原因产生的影响，但我们想从观测数据出发，就需要利用条件概率。这也引出了backdoor adjustment</p> <p>我们首先定义 backdoor criteria。对于由 T 到 Y 的因果关系，假设存在一组其他变量W，backdoor criteria的要求是</p> <ol> <li>W 能阻塞从 T 到 Y 的所有backdoor path</li> <li>W 不能包含 T 的所有子节点</li> </ol> <p>我们可以利用该标准，来选择 conditional exchangeability 假设中的条件。那么，结合 Modularity 假设和满足 backdoor criteria 的 W，We can identify the causal efftec of T on Y，即</p> \[P(y \vert do(t)) = \sum_w P(y | t, w) P(w)\] <p>这个式子即为 backdoor adjustment</p> <h2 id="structural-causal-models">Structural causal models</h2> <p>在因果推理中，等号并不能传递任何的因果信息。那么，为了表示 A 是 B 的一个原因，我们用结构方程来表示，即 \(B:=f(A)\)<br> 为了提升泛化能力，我们在这里增加一项U，表示可能存在的隐藏原因，即\(B:=f(A, U)\)</p> <p>在结构化因果模型(SCMs)中，我们用一系列这样的方程来进行建模。其中，直接原因称为endogenous variables，而可能存在的隐藏原因称为exogenous variables</p> <p>在 Interventional SCM 中，我们需要改写部分结果对应的方程，例如从\(T := f_T (X, U_T)\) 变到 \(T:=t\)。we get this by performing the intervention do(T = t).</p> <p>在建立 SCM 之后，我们再回头看之前定义的 backdoor criteria 第二条，为什么不能对子节点进行条件处理呢？有两种可能</p> <ol> <li>对子节点condition，可能会阻塞 chain 形式的因果图模型，即 block causal association</li> <li>可能会产生新的association，如果对 immorality 类型的子节点condition，则会产生新的 unblocked path，对结果产生影响。而隐藏原因的存在增大了这样 immorality 类型的出现。这样一种影响称为 Collider bias</li> </ol> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2024 Aofan Jiang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Last updated: February 27, 2024. </div> <div id="map-container" style="display: none;"> <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&amp;w=300&amp;t=n&amp;d=vcetvMKxQeU0A74GGVddvtKdDYpzY562Hjs3OBdOjBw"></script> </div> </footer> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> </body> </html>