<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <h1 id="bounds-and-sensitivity-analysis">Bounds and Sensitivity Analysis</h1> <p>Here’s the table of contents:</p> <ol id="markdown-toc"> <li> <a href="#bounds-and-sensitivity-analysis" id="markdown-toc-bounds-and-sensitivity-analysis">Bounds and Sensitivity Analysis</a> <ol> <li> <a href="#bounds" id="markdown-toc-bounds">Bounds</a> <ol> <li><a href="#no-assumption-bound" id="markdown-toc-no-assumption-bound">No-Assumption Bound</a></li> <li><a href="#monotone-treatment-bound" id="markdown-toc-monotone-treatment-bound">Monotone Treatment Bound</a></li> <li><a href="#optimal-treatment-selection" id="markdown-toc-optimal-treatment-selection">Optimal Treatment Selection</a></li> </ol> </li> <li><a href="#sensitivity-analysis" id="markdown-toc-sensitivity-analysis">Sensitivity Analysis</a></li> </ol> </li> </ol> <h2 id="bounds">Bounds</h2> <p>在之前的(T,W,Y)例子中，还可能存在潜在原因U同时作用与T和Y。此时，不存在未观察到的Confounding这样一种假设是不现实的。如果还是基于这种unconfoundedness假设，那么我们indentify的其实是一个point (一个具体的值)，而如果我们做一些更弱的假设，则此时我们indentify的是一个区间。在这里，我们来确定不同假设下该区间的范围，即为bounds</p> <h3 id="no-assumption-bound">No-Assumption Bound</h3> <p>在这里，我们假设所有的potential outcomes都具有统一的bound，即 $\forall t, a\le Y(t) \le b$<br> 由此我们可以得到 $a-b\le E[Y(1)-Y(0)] \le b-a$ ，整个区间的长度为 2(b-a) 。我们可以通过Observational-Counterfactual Decomposition来进一步压缩区间长度。首先我们用 $\pi$ 来表示 P(T=1)，根据定义展开ATE，可得到</p> \[E[Y(1)-Y(0)]=\pi E[Y\vert T=1]+(1-\pi) E[Y(1)\vert T=0] -\pi E[Y(0)\vert T=1]-(1-\pi) E[Y\vert T=0]\] <p>其中，展开后的第一项和第四项称为 observation term，可以从观察结果中直接计算得到。而第二项和第三项称为 Counterfactual term，无法通过计算得到。为此，我们保留observation term，将counterfactual term替换为(a,b) bound 区间。此时我们可以得到</p> \[E[Y(1)-Y(0)]\le \pi E[Y\vert T=1]+(1-\pi) b -\pi a-(1-\pi) E[Y\vert T=0]\] \[E[Y(1)-Y(0)]\ge \pi E[Y\vert T=1]+(1-\pi) a -\pi b-(1-\pi) E[Y\vert T=0]\] <p>我们可以发现，此时 E[Y(1)-Y(0)] 的区间长度被压缩到了 b-a</p> <h3 id="monotone-treatment-bound">Monotone Treatment Bound</h3> <ul> <li> <p>Monotone Treatment Response (MTR)<br> 这个假设是指，我们假设treatment永远有帮助，即 $\forall i,\ Y_i(1) \ge Y_i(0)$</p> <p>基于此假设，我们可以得到 $E[Y(1)\vert T=0]\ge E[Y\vert T=0]$ ，再结合Observational-Counterfactual Decomposition 得到的式子，我们可以将区间的下限提升至0，即 $E[Y(1)-Y(0)]\ge 0$</p> <p>同样，如果我们假设treatment永远帮倒忙，则是将区间的上限降至0</p> </li> <li> <p>Monotone Treatment Selection (MTS)<br> 这个假设是指，假设treatment group的潜在结果永远比control group结果更好，即 $E[Y (1) \vert T = 1] \ge E[Y (1) \vert T = 0], \ E[Y (0) \vert T = 1] \ge E[Y (0) \vert T = 0]$ ，再结合Observational-Counterfactual Decomposition 得到的式子，我们可以得到区间的上界，即 $E[Y(1)-Y(0)]\le E[Y\vert T=1]-E[Y\vert T=0]$</p> </li> </ul> <h3 id="optimal-treatment-selection">Optimal Treatment Selection</h3> <ul> <li> <p>OST1<br> 这个假设是指，我们假设每个个体永远接受最好的treatment，即 $T_i=1 \Rightarrow Y_i(1) \ge Y_i(0), \ T_i=0 \Rightarrow Y_i(0) &gt; Y_i(1)$</p> <p>基于此假设，我们可以得到 $E[Y(1)\vert T=0]\le E[Y\vert T=0], \ E[Y (0) \vert T = 1] \le E[Y \vert T = 1]$ ，再结合展开式子，我们可以得到</p> \[E[Y(1)-Y(0)]\le \pi E[Y\vert T=1]-\pi a\] \[E[Y(1)-Y(0)]\ge (1-\pi)a - (1-\pi) E[Y\vert T=0]\] </li> <li> <p>OST2<br> 以上提到的假设，都使得ATE区间包含0，即无法indentify ATE的符号。为此我们结合OST1假设及其逆否命题，得到OST2假设，可确定区间内的值均为正或负。</p> <p>在OST2假设中，我们可以得到 $E[Y (1) \vert T = 0] \le E[Y \vert T = 1]$ 。该关系的证明如下：<br> 首先利用OST1中的假设，我们有 $E[Y (1) \vert T = 0] = E[Y (1) \vert Y_i(0)&gt;Y_i(1)] \le E[Y (1) \vert Y_i(0)\le Y_i(1)]$<br> 在结合OST1假设的逆否命题，我们有 $E[Y (1) \vert Y_i(0)\le Y_i(1)] = E[Y(1)\vert T=1]$<br> 结合以上两个式子，即可得到 OST2 假设的内容， $E[Y (1) \vert T = 0] \le E[Y \vert T = 1]$</p> <p>在知道这个假设之后，我们结合展开式化简，可以得到对应的区间上下界，即</p> \[E[Y(1)-Y(0)]\le E[Y\vert T=1]-\pi a - (1-\pi)E[Y\vert T=0]\] \[E[Y(1)-Y(0)]\ge \pi E[Y\vert T=1]+(1-\pi) a - E[Y\vert T=0]\] </li> </ul> <p>总的来说，具体使用哪种假设取决于具体问题。在有的问题里，某些假设可能完全没有意义，而在其他问题里，又可能是最合适的假设 (区间范围最小等)。因此需要具体情况具体分析</p> <h2 id="sensitivity-analysis">Sensitivity Analysis</h2> <p>正如之前所提到的 (T,W,U,Y) 例子，真实的causal effect应该是 $E_{W,U}[…]$ ，而因为我们无法观测到U，实际上我们计算的是 $E_{W}[…]$ ，这就导致了偏差的产生。sensitivity analysis 就是为了分析这样一种偏差程度</p> <ul> <li> <p>Linear Single Confounder<br> 我们主要考虑最简单的一种情况，即线性关系下的敏感性分析。<br> 我们定义 $T:=\alpha_w W+\alpha_u U$ 和 $Y:=\beta_w W+\beta_u U + \delta T$ 。<br> 在理想情况(全知全能)下，causal effect 就是 $\delta$ ，我们的目的也就是恢复 $\delta$ 。<br> 而近似情况下，$E_W[…] = \delta + \frac{\beta_u}{\alpha_u}$<br> 此时的偏置值 (bias) 为近似减真实，即 $E_W[…]-E_{W,U}[…]=\beta_u / \alpha_u$<br> 对应的causal effect可视为 $\delta = Constant-\beta_u / \alpha_u$ ，我们也可以借此找到 causal effect&gt;0 的分界线。根据 $\beta_u - 1/\alpha_u$ 坐标轴作图找分界线的方式也称为 contour plot，经常应用于敏感性分析。</p> <p>接下来是上述公式的证明</p> <ol> <li>首先通过化简得到 $E_W [E[Y \vert T = t, W]]=(\delta+\frac{\beta_u}{\alpha_u})t+(\beta_w-\frac{\beta_u\alpha_w}{\alpha_u})E[W]$</li> <li>分别代入t=1和t=0，并相减即可得到 $E_W [E[Y \vert T = 1, W] - E[Y \vert T = 0, W]] = \delta+\frac{\beta_u}{\alpha_u}$</li> </ol> </li> </ul> <p>以上是最简单形式的 Linear SCM，for arbitrary estimands in arbitrary graphs, where the structural equations are still linear，对应的参考文献为 <a href="http://proceedings.mlr.press/v97/cinelli19a.html" rel="external nofollow noopener" target="_blank">Sensitivity Analysis of Linear Structural Causal Models” from Cinelli et al. (2019)</a></p> <p>其他更广泛形式下的敏感性分析方法见课后参考文档</p> </body></html>