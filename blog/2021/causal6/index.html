<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <h1 id="estimation">Estimation</h1> <p>Here’s the table of contents:</p> <ol id="markdown-toc"> <li> <a href="#estimation" id="markdown-toc-estimation">Estimation</a> <ol> <li><a href="#preliminaries" id="markdown-toc-preliminaries">Preliminaries</a></li> <li><a href="#conditional-outcome-modeling-com" id="markdown-toc-conditional-outcome-modeling-com">Conditional outcome modeling (COM)</a></li> <li><a href="#increasing-data-efficiency" id="markdown-toc-increasing-data-efficiency">Increasing Data Efficiency</a></li> <li><a href="#propensity-scores" id="markdown-toc-propensity-scores">Propensity scores</a></li> <li><a href="#inverse-probability-weighting-ipw" id="markdown-toc-inverse-probability-weighting-ipw">Inverse probability weighting (IPW)</a></li> <li><a href="#other-methods" id="markdown-toc-other-methods">Other Methods</a></li> </ol> </li> </ol> <h2 id="preliminaries">Preliminaries</h2> <p>在之前的内容中，我们通过indentification，将Causal Estimand转换为Statistical Estimand，即 $P(Y\vert do(t)) \rightarrow P(Y\vert t)$ 。接下来在本章的部分，我们进行的是下一阶段，对Statistical Estimand $P(Y\vert t)$ 进行估计。在Estimation中，我们输入数据，得到预测结果</p> <p>此外，我们还需要引入一个新的概念Conditional average treatment effects (CATEs)，和之前讲过的ATE相比，多了一个条件，记为</p> \[\tau(x) \triangleq E[Y(1)-Y(0)\vert X=x]\] <p>按与之类似的写法，之前的ATE可以表示为</p> \[\tau \triangleq E[Y(1)-Y(0)]\] <p>在该公式中，X不一定必须是观测变量，尽管通常都是。</p> <h2 id="conditional-outcome-modeling-com">Conditional outcome modeling (COM)</h2> <p>展开我们之前写出的ATE的公式，我们可以得到熟悉的<br> \(\tau = E_W [E[Y \vert T = 1, W] - E[Y \vert T = 0, W]]\)<br> 在estimation阶段，我们需要对$E[Y \vert T = 1, W]$进行建模，为了方便，我们重写ATE的公式</p> \[\tau = E_W [\mu(1,W) - \mu(0,W)]\] <p>这里的 $\mu(1,W)$ 和 $\mu(0,W)$ 即为我们的建模(比如利用DNN，则这里表示两个网络模型)。接下来我们需要对W近似，因为可能其维度太高，数据太多，无法得到准确的期望值，此时近似后的ATE我们称为ATE COM Estimator，即</p> \[\hat{\tau} = \frac{1}{n} \sum_i(\hat{\mu}(1,w_i) - \hat{\mu}(0,w_i))\] <p>同理，对于CATE，我们也是首先定义$\mu$来方便表示我们建立的模型，因为包含条件概率，我们记作</p> \[\mu(t,w,x)\triangleq E[Y\vert T=t,W=w,X=x]\] <p>再对W进行近似，得到近似后的 $\hat{\tau(x)}$，我们称为CATE COM Estimator，即</p> \[\hat{\tau}(x) = \frac{1}{n_x} \sum_{i:x_i=x}(\hat{\mu}(1,w_i,x) - \hat{\mu}(0,w_i,x))\] <p>COM还有一些其它的称呼，比如G-computation estimators、Parametric G-formula、Standardization and S-learner where “S” is for “Single”</p> <p>但现在存在一个问题，此时模型的输入为 W 和 T，W 为高维数据，T为一维数据。大量从 T 出来的权值都为0或极小值，对结果的影响几乎为零。该问题称为 estimate can be biased toward zero，那么我们应该怎么做来让模型不再忽略 T 的作用呢，由此我们引出Grouped COM (GCOM)</p> <p>在 GCOM 下，我们用两个网络(模型)分别去模拟T=0和T=1的情况，此时T信息就被隐含地编码的不同网络中了，此时可以写出对应的GCOM Estimator，即</p> \[\hat{\tau} = \frac{1}{n} \sum_i(\hat{\mu}_1(w_i) - \hat{\mu}_0(w_i))\] <p>对于T=1的网络，我们称为treatment group，就只用包含T=1的数据训练；同样，对于T=0的网络，我们称为control group，只用包含T=0的数据训练。这又引出了新的问题，这样数据的利用效率是很低的，我们应该如何提升利用效率呢？</p> <h2 id="increasing-data-efficiency">Increasing Data Efficiency</h2> <ul> <li> <p>TARNet<br> <img src="/images/ICI_lec6_1.JPG" alt="TARNet结构" title="TARNet结构"> <br> 相比与GCOM，TARNet的第一步利用的是全部数据，因此数据利用效率更高。但此方式仍然有局限性，那就是在第二步，指向 $T=0$ 和 $T=1$ 时，这里还是分别用treatment 和 control group的数据</p> </li> <li> <p>X-Learner<br> 该方法流程如下</p> <ol> <li>估计 $\hat{\mu}_1(x)$ 和 $\hat{\mu}_0(x)$</li> <li>提前计算ITE，对于treatment group, \(\hat{\tau}_{1,i} = Y_i(1) - \hat{\mu}_0(x_i)\)<br> 对于control group, \(\hat{\tau}_{0,i} = \hat{\mu}_1(x_i) - Y_i(0)\)</li> <li>用 treatment group 中的 $x_i$ 拟合模型 \(\hat{\tau}_{1}(x)\) 来预测 \(\hat{\tau}_{1,i}\)<br> 用 control group 中的 $x_i$ 拟合模型 \(\hat{\tau}_{0}(x)\) 来预测 \(\hat{\tau}_{0,i}\)</li> <li>最终的估计, \(\hat{\tau}(x) = g(x)\hat{\tau}_{0}(x) + (1-g(x))\hat{\tau}_{1}(x)\) ,这里的g(x)是权重方程，比如可以是propensity score</li> </ol> </li> </ul> <h2 id="propensity-scores">Propensity scores</h2> <p>我们定义Propensity scores e(w)为 $e(w)\triangleq P(T=1 \vert W)$<br> 我们可以发现，无论 W 是多少维的数据，其Propensity scores e(w)永远是一维数据。基于Propensity scores，我们有一个定理</p> \[(Y(1),Y(0)) \perp \!\!\! \perp T\vert W \Rightarrow (Y(1),Y(0)) \perp \!\!\! \perp T\vert e(W)\] <p>这个定理成立是因为condition on W 时，我们相当于移除因果图中 W 这个节点，使Y与T独立。而condition on e(W)时，我们相当于移除因果图中 W 到 T 的所有边，这样block掉了所有的backdoor path，同样得到独立</p> <p>为此我们想到了Positivity-Unconfoundedness Tradeoff，我们能不能用e(W)去代替W实现降维呢？这样的话overlap的程度就会更高。</p> <p>但这样是不行的，因为我们无法得到 $P(T=1 \vert W)$，在实际中，最好的方式是对其建模，把降维问题转化为对e(W)的建模问题</p> <h2 id="inverse-probability-weighting-ipw">Inverse probability weighting (IPW)</h2> <p>在介绍IPW之前，我们首先说明一下应用背景。在经典的(T,W,Y)三元例子中，correlation并不等于causality，即 $P(T\vert W)\neq P(T)$ ，这也导致我们无法分析T与Y的causal effect。但是如果 $P(T\vert W)= P(T)$ 或者是 $P(T\vert W)=1$ ，则此时 T 与 Y 之间就只存在因果关系，没有其他关系了。为了实现这种情况，我们可以对 $P(T\vert W)$ 这一项除以相同大小的值，即可将其变为1。由此引出 IPW</p> <p>在IPW中，我们对 Y 这一变量进行处理，此时 $E[Y(t)]=E[\frac{1(T=t)Y}{p(t\vert W)}]$ ，ATE的公式也随之发生改变，即</p> \[\tau \triangleq E[Y(1)-Y(0)] = E[\frac{1(T=1)Y}{e(W)}] - E[\frac{1(T=0)Y}{1-e(W)}]\] <p>对 W 近似后的公式为</p> \[\hat{\tau} = \frac{1}{n_1} \sum_{i:t_i=1}\frac{y_i}{\hat{e}(w_i)} - \frac{1}{n_0} \sum_{i:t_i=0}\frac{y_i}{1-\hat{e}(w_i)}\] <p>在CATE estimation下应该如何应用呢？这超出了课程范围，可以阅读参考文献<br> <a href="https://www.tandfonline.com/doi/full/10.1080/07350015.2014.975555" rel="external nofollow noopener" target="_blank">https://www.tandfonline.com/doi/full/10.1080/07350015.2014.975555</a></p> <h2 id="other-methods">Other Methods</h2> <p>这里简要介绍一些其他的建模估计方法</p> <ul> <li>同时利用COM和propensity score models，分别对 $\mu(t,w)$ 和e(w)进行建模<br> Consistent if either or is consistent<br> 理论上比 COM/IPW 更快地收敛到estimand</li> <li>Matching，将treatment group中的点对应到control group，使其对应两点间距离最小，有各种不同的criteria</li> <li>Double machine learning<br> 该方法分为两步，首先训练一个模型从W预测Y，得到预测值$\hat{Y}$，再训练一个模型从W预测T，得到预测值$\hat{T}$。第二步训练模型从$T-\hat{T}$中预测$Y-\hat{Y}$，以此来消除W的影响</li> <li>Causal trees and forests<br> Flexible and yield valid confidence intervals (for sampling variability)</li> </ul> </body></html>