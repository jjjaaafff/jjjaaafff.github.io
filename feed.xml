<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://jjjaaafff.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://jjjaaafff.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-11-14T09:52:58+00:00</updated><id>https://jjjaaafff.github.io/feed.xml</id><title type="html">blank</title><subtitle>Aofan Jiang&apos;s personal website. </subtitle><entry><title type="html">a post with bibliography</title><link href="https://jjjaaafff.github.io/blog/2023/post-bibliography/" rel="alternate" type="text/html" title="a post with bibliography"/><published>2023-07-12T13:56:00+00:00</published><updated>2023-07-12T13:56:00+00:00</updated><id>https://jjjaaafff.github.io/blog/2023/post-bibliography</id><content type="html" xml:base="https://jjjaaafff.github.io/blog/2023/post-bibliography/"><![CDATA[<p>This post shows how to add bibliography to simple blog posts. If you would like something more academic, check the <a href="/blog/2021/distill/">distill style post</a>.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="bib"/><summary type="html"><![CDATA[an example of a blog post with bibliography]]></summary></entry><entry><title type="html">Ml11</title><link href="https://jjjaaafff.github.io/blog/2021/ml11/" rel="alternate" type="text/html" title="Ml11"/><published>2021-08-25T00:00:00+00:00</published><updated>2021-08-25T00:00:00+00:00</updated><id>https://jjjaaafff.github.io/blog/2021/ml11</id><content type="html" xml:base="https://jjjaaafff.github.io/blog/2021/ml11/"><![CDATA[<h1 id="combining-models">Combining Models</h1> <p>Here’s the table of contents:</p> <ol id="markdown-toc"> <li><a href="#combining-models" id="markdown-toc-combining-models">Combining Models</a> <ol> <li><a href="#introduction" id="markdown-toc-introduction">Introduction</a></li> <li><a href="#committees" id="markdown-toc-committees">Committees</a></li> <li><a href="#boosting" id="markdown-toc-boosting">Boosting</a></li> <li><a href="#bagging" id="markdown-toc-bagging">Bagging</a></li> <li><a href="#conditional-mixture-models" id="markdown-toc-conditional-mixture-models">Conditional Mixture Models</a> <ol> <li><a href="#mixtures-of-linear-regression-models" id="markdown-toc-mixtures-of-linear-regression-models">Mixtures of linear regression models</a></li> <li><a href="#mixtures-of-logistic-models" id="markdown-toc-mixtures-of-logistic-models">Mixtures of logistic models</a></li> <li><a href="#mixtures-of-experts" id="markdown-toc-mixtures-of-experts">Mixtures of experts</a></li> </ol> </li> </ol> </li> </ol> <h2 id="introduction">Introduction</h2> <p>在之前的内容中，我们提出了一系列的分类回归模型。在最后一节我们考虑结合若干模型以提供更好的预测结果。在具体介绍模型结合的不同方式前，我们首先要区分模型结合与贝叶斯模型平均的区别。</p> <p>以高斯混合模型为例，我们就结合了若干个高斯分布模型。我们通过二进制隐变量 z 来指示具体模型的选择，所以该模型输出的是 $p(x,z)$ 联合分布。我们可以通过边缘化隐变量来得到观测数据的分布，假设我们用了 K 个高斯模型</p> \[p(x) = \sum_z p(x,z) \Rightarrow p(x) = \sum_{k=1}^K \pi_k N(x\vert u_k,\Sigma_k)\] <p>对于独立同分布的数据，每个数据点 $x_i$ 都有唯一对应的隐变量 $z_i$ 控制，对于整个数据集 $X={x_1,…,x_n}$ ，每个数据是由不同的子模型成分构成的，我们可以写出其概率分布</p> \[p(X) = \prod_{i=1}^n p(x_i) = \prod_{i=1}^n(\sum_{z_i}p(x_i,z_i))\] <p>而在贝叶斯模型平均中，我们有若干个不同下标 $h=1,…,H$ 对应的模型，比如一个是混合高斯，另一个是神经网络等。我们用 $p(h)$ 表示具体模型选择的先验概率，整个数据集都是同一种模型生成得到的，即</p> \[p(X) = \sum_{h=1}^H p(X|h)p(h)\] <p>随着数据量的增大，后验概率 $p(h\vert X)$ 会越来越趋近于某一个具体模型，这对应整个数据集都是同一种模型生成得到的</p> <h2 id="committees">Committees</h2> <p>最简单的一种组合模型的方法是将组合内的模型输出值进行平均，尤其是在回归任务中。接下来我们来分析为什么这种平均的方式可以提升效果。</p> <p>我们假设组合模型内总共有 M 个模型，回归的真实函数我们用 $h(x)$ 表示，第 m 个模型的预测输出我们用 $y_m(x)$ 表示，那么我们可以得到</p> \[y_m(x) = h(x) + \epsilon_m(x)\] <p>这里的 $\epsilon_m(x)$ 表示第 m 个模型下的预测误差。我们采用最小二乘作为损失函数，首先考虑单个模型的 Loss</p> \[L_m(X) = E_x[\epsilon_m^2(x)]\] <p>如果我们只采用第 m 个模型进行预测，那么这就是对应的 Loss，我们对单个模型预测的 Loss 平均作为统计意义上的单模型 Loss，可以得到</p> \[L_1(X) = \frac{1}{M}\sum_{m=1}^M E_x[\epsilon_m^2(x)]\] <p>接下来我们考虑组合模型的输出，将所有模型的预测进行平均作为最终预测结果，此时的最小二乘损失函数写为</p> \[L_2(X) = E_x[\{\frac{1}{M}\sum_{m=1}^My_m(x) -h(x)\}^2] = E_x [\{\frac{1}{M}\sum_{m=1}^M \epsilon_m(x)\}^2]\] <p>如果我们假设误差的均值为零，$E_x[\epsilon_m(x)] = 0$ 且不同模型之间的误差是不相关的 $E_x[\epsilon_i(x)\epsilon_j(x)] = 0$ ，那么可以得到</p> \[L_2(X) = \frac{1}{M} L_1(X)\] <p>也就是说，组合模型的误差只有单个模型误差的 1/M 。但实际中，不同模型间的误差是高度相关的，我们之前的假设太严格了。即使是这样，我们依然有 $L_2\leq L_1$ ，保证了组合模型的误差不大于其中的单个模型</p> <h2 id="boosting">Boosting</h2> <p>Boosting 是一种结合多个分类器以实现更好效果的方法，也可以扩展到回归任务。这里我们介绍最常用的 adaptive boosting，简称为 AdaBoost 。以二分类问题为例，假设数据集数据为 ${(x_i,y_i^\star)\vert i=1,…,n}$ 并且 $y_i^\star \in {+1,-1}$</p> <p>在 AdaBoost 中，我们为每一个训练数据分配权重，初始时所有数据的权重相同。在训练过程中，我们串行地训练组合模型中的子模型。根据上一个子模型的分类预测结果，修改数据权重。对于正确预测的数据，权重减小；分类错误的数据，其权重或增加。这种权重会传递至下一个子模型，并继续被修改。</p> <p>而我们最终的预测，是基于所有的子模型预测结果，结合每个模型之前对应的数据权重，通过加权平均的方式输出最终的分类预测。接下来我们给出具体的算法流程以更好地说明 AdaBoost。和之前假设一样，我们假设一共有 M 个子模型，模型参数用 $w$ 表示</p> <ul> <li> <p>第一步，初始化。将第一个模型的权重全部初始化为 1/n ，即</p> \[w_i^{(1)} = 1/n \quad for\ i = 1,2,...,n\] </li> <li> <p>第二步，串行训练组合模型中的子模型，从第 1 个一直训练到第 M 个模型。我们假设当前正在训练第 m 个模型。</p> <ol> <li> <p>训练第 m 个模型，我们用 $y_m(x)$ 表示其预测输出。采用带权重的损失函数，即</p> \[L_m = \sum_{i=1}^n \frac{w^{(m)}_i I(y_m(x_i)\neq y_i^*)}{\sum_{j=1}^n w^{(m)}_j}\] </li> <li> <p>统计该模型的错误分类率，计算方式为</p> \[\epsilon_m = \frac{\sum_{i=1}^n w_i^{(m)} I(y_m(x_i)\neq y_i^*)}{\sum_{i=1}^n w_i^{(m)}}\] <p>如果错误分类率 $\epsilon_m$ 大于0.5，说明此时模型表现甚至不如随机猜测，可以直接结束算法流程。如果小于0.5，则用这个错误分类率 $\epsilon_m$ 来计算权重系数 $\alpha$ ，即</p> \[\alpha_m = \frac{1}{2}\ln \frac{1-\epsilon_m}{\epsilon_m}\] </li> <li> <p>更新数据的权重 w ，并传至下一个(第 m+1 个子模型)模型</p> \[w_i^{(m+1)} = w_i^{(m)} e^{-y_i^*\alpha_iy_m(x_i)}\] </li> </ol> </li> <li> <p>最后当所有子模型都训练完毕后，结合权重系数加权平均，给出 AdaBoost 的最终预测结果，即</p> \[y_{pred}(x) = sign(\sum_{m=1}^M\alpha_m y_m(x))\] </li> </ul> <p>对于最终的预测结果 $y_{pred}$ ，我们同样需要损失函数来计算更新。这里我们考虑使用指数损失函数，我们假设选用 m 个子模型组合作为最终的预测，记为 $f_m(x)$ ，可以写出损失函数</p> \[L = \sum_{i=1}^n\frac{ w_i^{(m)}exp\{-y_i^*f_m(x_i)\}}{\sum_{j=1}^n w_j^{(m)}}, \quad where\ f_m(x) = \sum_{i=1}^m \alpha_i y_i(x)\] <p>我们首先来看第一个问题，为什么这里选用指数损失函数，用这种损失函数是否是正确的？</p> <p>如果最终的预测模型 $f_m(x)$ 可以让指数损失函数最小，我们令其偏导为零</p> \[\frac{\partial L}{\partial f_m} = -e^{-f_m(x)}P(y^*=1|x) + e^{f_m(x)}P(y^*=-1|x) = 0\] <p>可以得到</p> \[f_m(x) = \frac{1}{2}\ln \frac{P(y^*=1|x)}{P(y^*=-1|x)} \Rightarrow sign(f_m(x)) = argmax_y P(y^*=y|x)\] <p>可以看出，$sign(f_m(x))$ 达到了贝叶斯最优错误率。也就是说，当指数损失函数最小时，分类错误率也将达到最小。我们选用指数损失函数并不会对该任务本身造成影响。</p> <p>接下来我们分析 AdaBoost 算法中，模型 $y_m$ 更新公式及损失函数的由来。同样在这里，我们只考虑第 m 个子模型，假设之前的模型已经训练好了，将指数损失函数中的 $f_m(x)$ 进行拆分</p> \[L(y_m) = \sum_{i=1}^n \frac{w^{(m)}_i e^{-y_i^*f_{m-1}(x_i)}e^{-y_i^*y_m(x_i)}}{\sum_{j=1}^n w^{(m)}_j}\] <p>因为是二分类问题，$(y_i^\star)^2 = y_m(x_i)^2 = 1$ ，我们可以对上式中的后一项 $e^{-y_i^\star y_m(x_i)}$ 进行泰勒展开得到</p> \[e^{-y_i^*y_m(x_i)} \approx 1 - y_i^*y_m(x_i) + 1/2\] <p>代入上式可以发现，对于理想的子模型 $y_m(x)$ ，应该满足</p> \[y_m(x) = argmin\ L(y_m) = argmax\ \sum_{i=1}^n \frac{w^{(m)}_i y_i^*y_m(x_i)}{\sum_{j=1}^n w^{(m)}_j}\] <p>我们利用正负一的二分类条件，可以得到如下关系</p> \[y_i^*y_m(x_i) = 1-2I(y_m(x_i)\neq y_i^*)\] <p>所以我们就可以得到之前算法中的损失函数形式，即</p> \[y_m(x) = argmin\ \sum_{i=1}^n \frac{w^{(m)}_i I(y_m(x_i)\neq y_i^*)}{\sum_{j=1}^n w^{(m)}_j} = argmin\ L_m\] <p>接下来我们分析 AdaBoost 算法中，模型权重 $\alpha_m$ 更新公式的由来，此时我们已经训练好了对应的模型 $y_m(x)$。当我们训练好第 m 个模型 $y_m(x)$ 时，该模型权重 $\alpha_m$ 的选取应当使指数损失函数最小。假设在最后的优化中，前 m-1 个子模型及其权重参数 $\alpha$ 是固定的。只有第 m 个模型 $y_m(x)$ 和对应的权重 $\alpha_m$ 可以优化。把最后的第 m 个子模型从损失函数中单独拆分出来，可以写成</p> \[L = \sum_{i=1}^n \frac{w^{(m)}_iexp\{-y_i^*f_{m-1}(x_i) -y_i^*\alpha_my_m(x_i)\}}{\sum_{j=1}^n w^{(m)}_j} = L(\alpha_my_m) \times constant\] <p>进一步改写 $L(\alpha_my_m)$ 可以得到</p> \[L(\alpha_my_m) = \sum_{i=1}^n\frac{ w_i^{(m)}exp\{-y_i^* \alpha_m y_m(x_i)\}}{\sum_{j=1}^n w_j^{(m)}} = e^{-\alpha_m}(1-\epsilon_m) + e^{\alpha_m}\epsilon_m\] <p>将其对 $\alpha_m$ 求导为零就可以得到之前算法中的模型权重更新公式，即</p> \[\frac{\partial L(\alpha_my_m)}{\partial \alpha_m} = 0\Rightarrow \alpha_m = \frac{1}{2}\ln \frac{1-\epsilon_m}{\epsilon_m}\] <p>最后，我们来分析 AdaBoost 算法中，数据权重 w 更新公式的由来。假设我们已经完成了前 m 个子模型的训练，需要以此修改传递到第 (m+1) 个模型的数据权重。根据归一化，我们写出针对数据 i 的权重更新公式</p> \[w_i^{(m+1)} = \frac{e^{-y_i^*f_m(x_i)}}{\sum_{j=1}^n w_j^{(m)} e^{-y_j^*f_m(x_j)}} = \frac{e^{-y_i^*f_{m-1}(x_i)} e^{-y_i^*\alpha_iy_m(x_i)}}{\sum_{j=1}^n w_j^{(m)} e^{-y_j^*f_m(x_j)}}\] <p>我们在分子分母同乘针对前 m-1 项的和，以得到 $w_i^{(m)}$ 的形式，代入后得到之前算法中的数据权重更新公式，即</p> \[w_i^{(m+1)} = w_i^{(m)} e^{-y_i^*\alpha_iy_m(x_i)} \times constant\] <p>至此我们就推导出了算法中所有更新公式的来源。最后我们来比较一下这里的指数误差函数和之前的交叉熵函数的优劣。</p> <ul> <li>两者都可以看成对理想误分类函数的连续逼近，指数函数的串行最小化过程契合 AdaBoost 的训练方式</li> <li>指数函数对较大负值的 $y^*y$ 惩罚要高于交叉熵函数（前者是指数级别增长，后者是线性级别增长），这就导致了指数函数不适用于误分类，outlier 较多的数据集</li> <li>指数函数无法被解释为概率模型的似然函数，而交叉熵可以</li> <li>指数函数只能用于二分类任务，无法泛化到多分类任务</li> </ul> <h2 id="bagging">Bagging</h2> <p>相对于 Boosting 的串行集成学习，Bagging 是并行式集成学习的一种。这种方法主要是基于自主采样法 (bootstrap sampling)。因此，在介绍 Bagging 之前，我们先介绍这种采样方法。</p> <p>bootstrap sampling 的采样流程是这样的，假如我们已知包含 n 个样本的数据集，想要获得包含 n 个样本的采样集。我们每次从数据集中随机选择一个样本，将其复制放入采样集中，如此重复 n 次即可得到采样集。</p> <p>从这个流程中也可以看出，我们的采样集中很可能包含相同的样本，有些数据集中的数据也可能不会出现在采样集中。每次采样，每个数据被采中的概率为 1/n。我们可以通过极限逼近，对于某一个数据，其不会出现在采样集中的概率为</p> \[\lim_{n\rightarrow 0}\ (1-\frac{1}{n})^n = \frac{1}{e} \approx 0.368\] <p>根据这个概率，结合大量数据的统计意义。我们可以知道，初始数据集中约有 $63.2\%$ 的数据出现在采样集中。</p> <p>接下来对 Bagging 进行介绍。我们假设总共有 m 个子模型。Bagging 的基本流程就是通过 m 次 bootstrap sampling 得到 m 个样本数为 n 的采样集，分别用来训练这 m 个子模型，最后将这 m 个子模型的输出进行结合作为最终的预测输出。</p> <p>对于不同的任务，可以选取不同的模型输出结合策略。</p> <ul> <li> <p>针对回归问题，我们可以简单采用平均法，将不同子模型的输出平均作为最终输出，即</p> \[y_{pred}(x) = \frac{1}{m}\sum_{i=1}^m y_i(x)\] <p>也可以采用加权平均法，即</p> \[y_{pred}(x) = \frac{1}{m}\sum_{i=1}^m w_i y_i(x)\] <p>这里的权重一般是从训练数据中学习得到。一般而言，在子模型性能相差大时宜使用加权平 均，子模型性能接近时宜使用简单平均</p> </li> <li> <p>针对分类问题，主要采用的是投票法。即针对每个数据，选取不同子模型分类预测中，出现次数最高的那个类别作为最终的预测分类。</p> </li> </ul> <p>最后，我们介绍一种通过一个单独的子模型结合其他子模型的模型混合方法，其中的典型代表是 Stacking 。这种方法的原理很简单，将不同子模型的输出作为这个单独子模型（也称为次级模型，meta-learner）的输入，次级模型的输出即为整个混合模型的输出。</p> <p>这里存在一个问题，次级模型的训练集是利用子模型产生的，若直接用子模型的训练集来产生次级训练集，则过拟合风险会比较大。因此，一般是通过使用交叉验证或留一法这样的方式，用训练子模型时未使用的样本来产生次级模型的训练样本。</p> <p>有研究表明，将子模型的输出类概率作为次级模型的输入属性，用多响应线性回归(Multi-response Linear Regression，简称 MLR) 作为次级模型效果较好。</p> <h2 id="conditional-mixture-models">Conditional Mixture Models</h2> <p>接下来我们考虑条件分布的混合模型。最简单的情况下，混合系数与输入变量相互独立，我们将介绍线性回归混合模型和 logistic 回归混合模型。如果混合系数依赖于输入变量，我们可以得到 mixture of experts 模型。更进一步，如果我们让混合模型中的每一个子模型同样是 mixture of experts 模型，那么可以得到层次 mixture of experts 模型</p> <h3 id="mixtures-of-linear-regression-models">Mixtures of linear regression models</h3> <p>我们假设混合 K 个回归模型，每一个回归模型用参数 $w_k$ 表示。混合系数我们用 $\pi$ 表示。同时，假设这 K 个模型下的噪声方差由相同的参数 $\beta$ 控制。现在我们可以写出混合分布</p> \[p(y|\theta) = \sum_{k=1}^K \pi_k N(y\vert w_k^Tx,\beta^{-1})\] <p>这里的 $\theta$ 代表所有可调整参数 ${w,\pi,\beta}$ 。在给定数据集 ${(x_i,y_i^*)\vert i=1,…,n}$ 的情况下，可以写出 log 似然方程</p> \[\ln p(Y^*\vert \theta) = \sum_{i=1}^n \ln (\sum_{k=1}^K \pi_kN(y_i^*\vert w_k^Tx_i,\beta^{-1}))\] <p>为了最大化这个似然方程，我们可以引入二进制隐变量 z 结合 EM 算法进行求解。混合系数 $\pi$ 的求法和之前介绍的高斯混合模型完全相同，不同的是回归模型 $w$ 和噪声方差 $\beta$ 的更新式。</p> <p>我们首先来看回归模型的求解，我们针对第 k 个模型 $w_k$ ，将 EM 的目标函数 $Q(\theta,\theta^{t})$ 中关于回归模型的部分拆分出来可以得到</p> \[Q(\theta,\theta^{t}) = \sum_{i=1}^n \gamma_{ik}\{-\frac{\beta}{2}(y_i^*-w_k^Tx_i)^2\} + constant\] <p>接着对回归模型参数求导并令其为零，消去常数系数 $\beta$ 可得</p> \[\sum_{i=1}^n \gamma_{ik}(y_i^*-w_k^Tx_i)x_i = 0\] <p>和单纯的回归模型求解不同的是，这里多了一个数据权重 $\gamma_{ik}$ 。这个权重表示第 i 个数据在第 k 个回归模型中的权重，会随着 EM 算法的迭代而更新。在带权参数的影响下，模型的解也会发生变化，此时的解析解可以写为</p> \[w_k = (X^TR_kX)^{-1}X^TR_kY^* ,\quad where\ \ R_k = diag(\gamma_{nk})\] <p>和没有权参数的单纯线性回归模型的解比较一下，$w_k = (X^TX)^{-1}X^TY^*$ ，也就是多了对权重的考虑。</p> <p>最后看下对噪声方差 $\beta$ 的优化。同样的方法，我们将 EM 的目标函数 $Q(\theta,\theta^{t})$ 中关于 $\beta$ 的部分拆分出来</p> \[Q(\theta,\theta^{t}) = \sum_{i=1}^n\sum_{k=1}^K \gamma_{ik}\{\frac{\ln \beta}{2}-\frac{\beta}{2}(y_i^*-w_k^Tx_i)^2\}\] <p>因为 $\beta$ 是一个标量，我们可以直接对其求导令导数为零得到 EM 中的更新公式</p> \[\frac{1}{\beta} = \frac{1}{n}\sum_{i=1}^n\sum_{k=1}^K \gamma_{ik}(y_i^*-w_k^Tx_i)^2\] <p>我们求出了 EM 算法中 ${\pi,w,\beta}$ 的更新公式，最后按照算法流程更新即可。</p> <h3 id="mixtures-of-logistic-models">Mixtures of logistic models</h3> <p>我们假设混合 K 个回归模型，每一个回归模型用参数 $w_k$ 表示，$y_k(x) = \sigma(w_k^Tx)$。混合系数我们用 $\pi$ 表示。同时，假设是 0-1 二分类问题。现在我们可以写出混合分布</p> \[p(y^*\vert x,\theta) = \sum_{k=1}^K \pi_k y_k^{y^*}[1-y_k]^{1-y^*}\] <p>这里的 $\theta$ 代表所有可调整参数 ${w,\pi}$ 。在给定数据集 ${(x_i,y_i^*)\vert i=1,…,n}$ 的情况下，可以写出似然方程</p> \[p(Y^*\vert \theta) = \prod_{i=1}^n(\sum_{k=1}^K \pi_k y_{ik}^{y^*_i}[1-y_{ik}]^{1-y^*_i})\] <p>和上面一样的方法，我们引入隐变量 Z 结合 EM 算法最大化似然函数，此时目标方程为</p> \[Q(\theta,\theta^t) = E_z[\ln p(Y^*Z\vert\theta)] = \sum_{i=1}^n\sum_{k=1}^K\gamma_{ik}\{\ln \pi_k + y_i^*(\ln y_{ik}) + (1-y_i^*)\ln (1-y_{ik})\}\] <p>这里混合系数 $\pi$ 的更新和之前一致，但 logistic 回归模型 $w$ 没有解析解，必须通过其他的迭代算法去逼近近似。这种混合模型可以扩展到多分类任务，只需将二分类的 sigmoid 函数替换为 softmax 函数</p> <h3 id="mixtures-of-experts">Mixtures of experts</h3> <p>最后简要介绍一下 Mixtures of experts 模型，在这个模型中，我们认为混合系数也是和输入变量相关的。和之前的两个混合模型相比，变化为 $\pi_k \rightarrow \pi_k(x)$</p> <p>此时的条件概率分布可以写为</p> \[p(Y^*\vert x) = \sum_{k=1}^K \pi_k(x) p_k(Y^*\vert x)\] <p>这里的混合系数 $\pi_k(x)$ 被称为 gating 函数，它需要满足和之前一样的约束条件，即</p> \[0\leq \pi_k(x) \leq 1,\quad \sum_{k=1}^K \pi_k(x) =1\] <p>而这里的子概率密度 $p_k(y^*\vert x)$ 被称为 experts。</p> <p>Mixtures of experts 和我们之前在神经网络中提到的 mixture density network 关联很密切。前者的优点是可以通过 EM 算法结合凸优化求解，后者的优点是子模型与混合系数共享神经网络的隐藏单元，对输入空间划分约束更少</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Combining Models]]></summary></entry><entry><title type="html">Ml10</title><link href="https://jjjaaafff.github.io/blog/2021/ml10/" rel="alternate" type="text/html" title="Ml10"/><published>2021-08-22T00:00:00+00:00</published><updated>2021-08-22T00:00:00+00:00</updated><id>https://jjjaaafff.github.io/blog/2021/ml10</id><content type="html" xml:base="https://jjjaaafff.github.io/blog/2021/ml10/"><![CDATA[<h1 id="sequential-data">Sequential Data</h1> <p>Here’s the table of contents:</p> <ol id="markdown-toc"> <li><a href="#sequential-data" id="markdown-toc-sequential-data">Sequential Data</a> <ol> <li><a href="#introduction" id="markdown-toc-introduction">Introduction</a></li> <li><a href="#hidden-markov-models" id="markdown-toc-hidden-markov-models">Hidden Markov Models</a></li> <li><a href="#linear-dynamical-systems" id="markdown-toc-linear-dynamical-systems">Linear Dynamical Systems</a></li> </ol> </li> </ol> <h2 id="introduction">Introduction</h2> <p>在之前的内容中，我们都假设观测数据是独立同分布的。但在实际中，这种假设很多情况下并不成立。这里我们关注一种特殊的情况，那就是时序数据。尽管时序数据并不一定与时间相关，我们还是用过去，未来等称呼来描述关系。</p> <p>在时序数据中，一个直觉的观点是最近的数据可以比历史上的数据更好地预测未来的结果。最理想的情况是，我们建立一个模型，可以考虑到当前状态之前的所有数据。但此时模型的复杂度会随着时间推移而指数级增长。最基础，最简单的情况是马尔科夫模型，即我们只考虑上一次数据对当前的影响。</p> <p>但基础的马尔科夫模型约束又太强了，所以我们考虑引入隐变量来泛化模型。我们假设由隐变量 z 决定观测数据 x，而隐变量是马尔科夫链。此时我们对观测数据不做要求，离散或者连续都可以。而隐变量的不同对应接下来要介绍的两种模型。</p> <p>当隐变量 z 是离散变量时，我们可以得到隐式马尔科夫模型 HMM 。当隐变量和观测变量都服从高斯分布时，我们可以得到线性动态系统 linear dynamical system</p> <p>最后值得一提的是，我们在这里讨论的都是 stationary 时序分布。也就是说 $z_n \vert z_{n-1}$ 和 $z_{i} \vert z_{i-1}$ 的分布是一致的。</p> <h2 id="hidden-markov-models">Hidden Markov Models</h2> <p>在 HMM 中，我们认为隐变量是离散变量。假设隐变量有 K 个状态，我们用长度为 K 的 0-1 向量来表示每一个隐变量，且每次只有一个元素为 1， 其余为0。那么就可以用状态转移矩阵 A 来表示隐变量的变化，即</p> \[A_{ji} \equiv p(z_{ni}=1| z_{n-1,j}=1),\ where\ 0\leq A_{ji}\leq 1\ ,\ \sum_{i=1}^K A_{ji} = 1\] <p>基于这个转移矩阵 A ，我们可以直接写出相邻两个隐变量之间的条件分布，</p> \[p(z_{n}\vert z_{n-1}) = \prod_{i=1}^K\prod_{j=1}^K A_{ji}^{z_{n-1,j}z_{ni}}\] <p>只知道条件转移概率是不够的，我们还需要知道初始分布，即 $p(z_1)$</p> \[p(z_1) = \prod_{i=1}^K \pi_i^{z_{1i}}, \quad where\ \pi_i \equiv p(z_{1i}=1)\] <p>现在我们就完整建模了隐变量的变化及分布，下一步是建模观测变量 x 基于隐变量的分布，我们称这个分布为发射分布 (emission distributions)。我们用符号 $\phi$ 来统一表示控制 $x\vert z$ 分布的参数。如果 x 是离散变量，$\phi$ 可以认为是概率表；如果 x 是高斯连续变量，$\phi$ 可以认为是高斯分布参数。现在我们可以表示出这个条件分布</p> \[p(x_n\vert z_n,\phi) = \prod_{i=1}^K p(x_n\vert \phi)^{z_{ni}}\] <p>接下来我们就可以表示出观测变量和隐变量的联合分布，即</p> \[p(X,Z|\theta) = p(z_1|\pi)[\prod_{n=2}^N p(z_n\vert z_{n-1},A)]\prod_{m=1}^N p(x_m\vert z_m,\phi)\] <p>这里 $X={x_1,…,x_N}, Z = {z_1,…,z_N}, \theta = {\pi,A,\phi }$ 。自此我们完成了 HMM 的建模。</p> <p>我们可以先从生成模型的角度来理解 HMM。首先我们根据 $\pi$ 来随机选择初始隐变量 $z_1$ 的值，接着根据发射分布参数 $\phi$ 来采样得到第一个生成数据 $x_1$ 。同时我们根据转移矩阵 A 结合初始隐变量选择第二个隐变量的值 $z_2$ ，再采样得到第二个生成数据 $x_2$ ，以此类推得到一系列隐变量值和对应的一系列生成数据。</p> <p>在实际中，我们已知一系列的观测数据，需要去确定这些具体的模型参数 $\theta$ 。这可以通过极大似然结合 EM 算法求解。</p> <h2 id="linear-dynamical-systems">Linear Dynamical Systems</h2> <p>在之前提到过，在 LDS 中，我们认为隐变量和观测变量都服从高斯分布，为此可以写出他们的分布</p> \[z_n\vert z_{n-1} \sim N(Az_{n-1},\Gamma),\qquad x_n\vert z_n \sim N(Cz_n,\Sigma)\] <p>而初始的隐变量 $z_1$ 同样服从高斯分布，即</p> \[z_1 \sim N(u_0,V_0)\] <p>此时我们的模型参数 $\theta = {A,\Gamma,C,\Sigma,u_0,V_0 }$</p> <p>接下来我们考虑根据已知观测数据 ${x_1,…,x_n}$ 来推断隐变量 $z_n$ 。我们记</p> \[\hat{\alpha}(z_n) \equiv p(z_n\vert x_1,...,x_n) \sim N(u_n,V_n), \quad c_n \equiv p(x_n\vert x_1,...,x_{n-1})\] <p>那么我们有</p> \[c_n\hat{\alpha}(z_n) = p(x_n\vert z_n)\int \hat{\alpha}(z_{n-1})p(z_n\vert z_{n-1})dz_{n-1}\] <p>首先对积分求解，可以得到</p> \[\int ... dz_{n-1} = N(Z_n\vert Au_{n-1},P_{n-1}), \quad where\ P_{n-1} = AV_{n-1}A^T+ \Gamma\] <p>进一步求解，可以得到我们期望的参数表达式，即</p> \[u_n = Au_{n-1}+K_n(x_n-CAu_{n-1})\] \[V_n = (I-K_nC)P_{n-1}\] \[c_n = N(x_n\vert CAu_{n-1},CP_{n-1}C^T+\Sigma)\] <p>这里的 K 我们定义为 Kalman gain matrix，即</p> \[K_n = P_{n-1}C^T(CP_{n-1}C^T+\Sigma)^{-1}\] <p>我们可以从 $z_{n-1}$ 到 $z_n$ 的过程来理解上述表达式。我们可以将 $Au_{n-1}$ 看成基于 $z_{n-1}$ 的均值结合转移矩阵 A 得到的 $z_n$ 预测均值。基于这个预测均值，我们进一步得到预测观测 $CAu_{n-1}$ ，这和真实的观测值 $x_n$ 显然存在差距。我们用两者之间的误差来修正对 $z_n$ 均值的预测，Kalman gain matrix 作为系数控制着误差修正程度。</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Sequential Data]]></summary></entry><entry><title type="html">Ml9</title><link href="https://jjjaaafff.github.io/blog/2021/ml9/" rel="alternate" type="text/html" title="Ml9"/><published>2021-08-19T00:00:00+00:00</published><updated>2021-08-19T00:00:00+00:00</updated><id>https://jjjaaafff.github.io/blog/2021/ml9</id><content type="html" xml:base="https://jjjaaafff.github.io/blog/2021/ml9/"><![CDATA[<h1 id="principal-component-analysis">Principal Component Analysis</h1> <p>Here’s the table of contents:</p> <ol id="markdown-toc"> <li><a href="#principal-component-analysis" id="markdown-toc-principal-component-analysis">Principal Component Analysis</a> <ol> <li><a href="#formulation" id="markdown-toc-formulation">Formulation</a> <ol> <li><a href="#maximum-variance-formulation" id="markdown-toc-maximum-variance-formulation">Maximum variance formulation</a></li> <li><a href="#minimum-error-formulation" id="markdown-toc-minimum-error-formulation">Minimum error formulation</a></li> </ol> </li> <li><a href="#pca-in-high-dimension" id="markdown-toc-pca-in-high-dimension">PCA in High-dimension</a></li> <li><a href="#kernel-pca" id="markdown-toc-kernel-pca">Kernel PCA</a></li> <li><a href="#probabilistic-pca" id="markdown-toc-probabilistic-pca">Probabilistic PCA</a></li> </ol> </li> </ol> <h2 id="formulation">Formulation</h2> <p>PCA 主成分分析，被广泛应用于数据降维，特征提取等领域。我们有两种广泛使用的 PCA 定义，从它们可以引出相同的 PCA 算法。PCA 的第一种定义将数据正交投影在低维线性空间，使得投影数据的 variance 最大化的投影方式。PCA 的第二种定义是最小化原数据和投影数据间均方距离的线性投影方式。接下来我们分别来讨论这两种定义</p> <h3 id="maximum-variance-formulation">Maximum variance formulation</h3> <p>我们假设观测数据集为 ${x_1,…,x_n}$ ，其中每个观测数据 $x_i$ 的维度为 D。我们的目标是将数据 $x_i$ 降维到 M 维，使得投影后的数据方差最大。在这里我们先假设降维维度 M 是已知的，考虑最简单的降为一维的情况 (M=1)</p> <p>我们用一个 D 维向量 $u$ 来表示原空间的方向。因为我们只关心其方向，我们令向量 $u$ 为单位向量 $(u^Tu=1)$ 。每个数据向量都会被投影为一个标量，即 $u^Tx_i$ 。我们写出投影数据的方差</p> \[\frac{1}{n}\sum_{i=1}^n \{u^Tx_i - u^T\overline{x}\}^2, \quad where \ \ \overline{x} = \frac{1}{n}\sum_{i=1}^n x_i\] <p>我们将协方差矩阵提取出来，上式可以写成矩阵向量的形式</p> \[u^TSu, \qquad where\ \ S = \frac{1}{n}\sum_{i=1}^n (x_i-\overline{x})(x_i-\overline{x})^T\] <p>根据 PCA 定义，我们想要使得投影后的数据方差最大，此时我们的目标问题即为</p> \[max_{u}\ u^TSu, \quad s.t.\ u^Tu=1\] <p>通过引入拉格朗日乘子 $\lambda$ 来消除约束，解决这个问题</p> \[L = u^TSu + \lambda (1-u^Tu)\] <p>我们对 $u$ 求导并令其为零可以发现</p> \[\frac{\partial L}{\partial u} = 0 \Rightarrow Su=\lambda u\] <p>因为我们引入的 $\lambda$ 是一个常数，这意味着 $u$ 是协方差矩阵 S 的一个 eigenvector，我们在等式两边同时乘 $u^T$，结合单位向量的假设，可以发现</p> \[u^TSu = \lambda\] <p>为使目标方差 $u^TSu$ 最大，我们需要 $\lambda$ 取最大值。而 $\lambda$ 是协方差矩阵 S 的一个 eigenvalue，这意味着我们需要选取协方差矩阵 S 中最大的 eigenvalue 对应的 eigenvector 作为 $u$ ，此时这个 eigenvector 也被称为第一主成分。</p> <p>至此我们就得到了 PCA 的建立及求解方式。对应非一维的数据降维，我们对应的选取前 M 大 eigenvalue 对应的 eigenvector 组合起来作为投影矩阵 $u$</p> <p>该过程中主要的计算量消耗在 eigenvector 的计算上，对于尺寸为 $D\times D$ 的矩阵，计算的时间复杂度为 $O(D^3)$ 。因为我们只关心前 M 大的 eigenvector，我们可以用 power method 简化，将复杂度降为 $O(MD^2)$</p> <h3 id="minimum-error-formulation">Minimum error formulation</h3> <p>Minimum error formulation 的核心思想是通过旋转坐标系以最小化投影误差。这里同样假设观测数据集为 ${x_1,…,x_n}$ ，其中每个观测数据 $x_i$ 的维度为 D 。我们首先引入一组 D 维的完全正交基向量 ${u_1,…,u_D}$ ，我们可以根据这组基向量来表示出每一个观测数据，即</p> \[x_n = \sum_{i=1}^D \alpha_{ni}u_i\] <p>我们可以认为原来的观测数据 $x_n = {x_{n1},…,x_{nD}}$ 经过旋转得到新的坐标，即这里的 ${\alpha_{n1},…,\alpha_{nD}}$ ，这意味着 $\alpha_{ni} = x_n^Tu_i$ ，我们代入上式可得</p> \[x_n = \sum_{i=1}^D (x_n^Tu_i)u_i\] <p>因为我们需要将数据降到 M 维，我们用前 M 个基向量来表示这个 M 维的线性子空间。此时观测数据的估计值可以写成</p> \[\tilde{x}_n = \sum_{i=1}^M z_{ni}u_i + \sum_{i=M+1}^D b_iu_i\] <p>第一项就是我们希望得到的维数为 M 的子空间。第二项数据中包含较多冗余信息的部分，对于这些冗余的维度，我们对每个维度用一个常数 $b_i$ 来约束。根据 PCA 第二种定义，我们要最小化原数据和投影数据间均方距离，即</p> \[min_{u,z,b}\ J = \frac{1}{n}\sum_{i=1}^n ||x_i-\tilde{x}_i||^2 = \frac{1}{n}\sum_{i=1}^n ||x_i-\sum_{j=1}^M z_{ij}u_j - \sum_{j=M+1}^D b_ju_j||^2\] <p>我们首先对 $z_{ij}$ 求导并令其为零，结合基向量的正交性，可以得到</p> \[z_{ij} = x_i^Tu_j,\quad where\ \ j=1,...,M\] <p>接着我们对 $b_{j}$ 求导并令其为零，结合基向量的正交性，可以得到</p> \[b_j = (\frac{1}{n}\sum_{i=1}^n x_i)^Tu_j = \overline{x}^Tu_j,\quad where\ \ j=M+1,...,D\] <p>现在我们将 $z_{ij}$ 和 $b_{j}$ 的形式代入优化目标中，可以得到</p> \[J = \frac{1}{n}\sum_{i=1}^n\sum_{j=M+1}^{D}\{(x_i-\overline{x})^Tu_j\}u_j = \frac{1}{n}\sum_{i=1}^n\sum_{j=M+1}^{D}(x_i^Tu_j-\overline{x}^Tu_j)^2 = \sum_{i=M+1}^D u_i^TSu_i\] <p>这里的 S 同样是协方差矩阵，我们得到的形式等价于第一种定义。我们可以得到映射后的数据 $\hat{x}$ 根据公式</p> \[\hat{x} = \sum_{i=1}^M (x^Tu_i)u_i\] <h2 id="pca-in-high-dimension">PCA in High-dimension</h2> <p>在高维数据中，有时维数会高于样本数，即 $D&gt;N$ 。在这种情况下，如果我们用之前提到的方法计算 eigenvector，时间复杂度 $O(D^3)$ 是难以接受的。因此需要进一步的修改优化。</p> <p>我们用 X 来表示输入数据集，是一个 $(N\times D)$ 的矩阵，第 n 行表示的是第 n 个归一化的数据 $(x_n-\overline{x})^T$ ，此时的协方差矩阵可以写出 $S=N^{-1}X^TX$ ，此时的 eigenvector 方程为</p> \[\frac{1}{N}X^TXu = \lambda u\] <p>我们在等式两边同时乘 X ，可以得到</p> \[\frac{1}{N}XX^T(Xu) = \lambda (Xu) \Rightarrow \frac{1}{N}XX^Tv = \lambda v\] <p>通过这种方式，我们将问题转化为求 $XX^T$ 矩阵的 eigenvector，时间复杂度从原问题的 $O(D^3)$ 变为 $O(N^3)$。在求出 eigenvector v 之后，我们需要还原到待求的原 eigenvector u，通过在等式两边再同时乘 $X^T$</p> \[\frac{1}{N}X^TX(X^Tv) = \lambda (X^Tv)\] <p>可以发现我们又回到了原问题的协方差矩阵，此时 $X^Tv$ 是对应的 eigenvector。最后我们进行一下归一化，限制 $\vert\vert u \vert\vert=1$ ，得到最后的投影矩阵 u</p> \[u_i = \frac{X^Tv_i}{\sqrt{N\lambda_i}}\] <p>总结来说，在高维数据的 PCA中，我们首先计算 $XX^T$ 的 eigenvector ${v_i}$ ，再用上式去还原出原协方差矩阵的 eigenvector ${u_i}$ 作为最终结果</p> <h2 id="kernel-pca">Kernel PCA</h2> <p>结合之前学过的 Kernel 方法，我们可以通过 kernel 的方式来引入非线性变换。在上面的标准 PCA 中，我们对原数据进行矩阵相乘，将其从 D 维空间线性变换到 M 维空间，即 $x \rightarrow u^Tx$。现在我们考虑用一个变换函数 $\phi(x)$ 实现映射变换，即 $x \rightarrow \phi(x)$。对于某个数据 $x_i$ 而言，它是一个 D 维向量。而变换后的 $\phi(x_i)$ 则变成一个 M 维向量。</p> <p>我们假设映射后的数据同样均值为零，即 $\sum_i \phi(x_i) = 0$ ，那么我们可以写出 MxM 特征空间的协方差矩阵</p> \[C = \frac{1}{n}\sum_{i=1}^n\phi(x_i)\phi(x_i)^T\] <p>我们用 ${v_1,…,v_M}$ 来表示协方差矩阵 C 的特征向量。这些特征向量也可以写为特征空间数据的线性组合，即</p> \[v_i = \sum_{j=1}^n \alpha_{ij}\phi(x_j)\] <p>代入到矩阵 C 的特征值方程中，对于第 k 个特征值 $\lambda_k$ 可以得到，</p> \[(\frac{1}{n}\sum_{i=1}^n\phi(x_i)\phi(x_i)^T) (\sum_{j=1}^n \alpha_{kj}\phi(x_j)) = \lambda_k \sum_{i=1}^n \alpha_{ki}\phi(x_i)\] <p>为了凑出 kernel 的形式，我们在等式两边同时乘 $\phi(x_s)^T$ ，此时上式就可以写成矩阵的形式</p> \[K^2\alpha_k = \lambda_knK\alpha_k\] <p>这里的 K 表示 kernel 矩阵，$K_{ij} = K(x_i,x_j) = \phi(x_i)^T\phi(x_j)$ 。$\alpha_k$ 则表示一个 N 维列向量。我们可以去掉上式等号两边的 K，此时得到的解与原式的不同在于零特征值对应的特征向量，而这种特征向量的差别对主成分的分解不会产生影响。</p> <p>那么现在的问题就和标准 PCA 一样了，我们希望得到矩阵 K 的特征向量，即</p> \[K \alpha_k = \lambda_kn\alpha_k\] <p>此外，我们还需要保证特征向量 $\alpha_i$ 的归一化，这一点可以通过归一化特征空间特征向量来满足，即</p> \[v_i^Tv_i = \alpha_i^TK\alpha_i = \lambda_i n \alpha_i^T\alpha_i = 1\] <p>在确定系数 $\alpha_i$ 后，就可以得到原问题的特征向量 $v_i$ ，进而实现变换。原数据 x 映射在特征空间第 m 维的值同样可以表示为 kernel 的形式</p> \[y_m(x) = \phi(x)^Tv_m = \sum_{i=1}^n \alpha_{mi}\phi(x)^T\phi(x_i) = \sum_{i=1}^n\alpha_{mi}k(x,x_i)\] <p>至此我们就完成了 kernel PCA 的建模。最开始我们假设映射后的数据同样均值为零，即 $\sum_i \phi(x_i) = 0$ 。但这个假设在实际情况中通常并不成立，所以我们需要人为地进行处理</p> \[\tilde{\phi}(x_k) = \phi(x_k) - \frac{1}{n}\sum_{i=1}^n\phi(x_i)\] <p>此时的 kernel 矩阵也会发生变化</p> \[\tilde{K}_{ij} = \tilde{\phi}(x_i)^T\tilde{\phi}(x_j) \Rightarrow \tilde{K} = K-1_nK-K1_n+1_nk1_n\] <p>这里的 $1_n$ 为 nxn 的矩阵，其中每个元素都是 1/n 。这种变化对我们的建模并没有影响。特别地，如果取线性 kernel $k(x_i,x_j)=x_i^Tx_j$ ，那么就可以得到标准的 PCA 模型。</p> <p>最后是 kernel PCA 的缺点。第一个缺点是它需要找到 NxN 尺寸的 kernel 矩阵 K 的特征向量，而在传统 PCA 中，我们只需要找的是 DxD 尺寸的协方差矩阵。当数据量大的时候就需要用到近似。第二个缺点是它必须保留所有的特征向量用于变换，而在传统的 PCA 中，我们只需要保留前 M 大的特征向量即可。</p> <h2 id="probabilistic-pca">Probabilistic PCA</h2> <p>PCA 也可以表示为概率隐变量模型的极大似然解。传统的 PCA 可以看成是将 D 维的数据投影到 M 维的线性子空间。而 probabilistic PCA 则可以看成一种从隐空间到数据空间的映射。probabilistic PCA 是线性高斯框架下的应用，这意味着所有的边缘分布，条件分布都是高斯分布。我们从生成模型的角度来引入 probabilistic PCA</p> <p>我们假设观测数据 x 为 D 维向量，由隐变量 z 控制，z 是 M 维向量。我们首先假设隐变量 z 先验分布为标准高斯分布，即 $z \sim N(0,I)$ ，之后我们可以证明，z 的高斯分布参数对建模没有影响。</p> <p>同样，条件概率分布也是高斯分布，我们假设 $x\vert z \sim N(Wz+u,\sigma^2I)$<br/> 这里 x 可以看成是 z 的线性变换，由矩阵 W ($D \times M$) 控制。也就是说，观测数据可以表示为</p> \[x = Wz + u + \epsilon\] <p>这里 $\epsilon$ 表示噪声，服从均值为零，方差为 $\sigma^2I$ 的高斯分布，对应条件分布中的方差项。</p> <p>在表示出隐变量 z 的先验分布和条件分布后，我们可以写出观测数据 x 的分布，即</p> \[p(x) = \int p(x\vert z)p(z)dz \Rightarrow x \sim N(u,WW^T+\sigma^2I)\] <p>观测数据的分布由参数 $u,W,\sigma$ 控制。通过观察我们可以发现一个现象，如果我们将 $W$ 替换为 $W_0 = WR$ ，这里 R 是一个正交矩阵。此时出现在方差项的 $W_0W_0^T$ 可以写成</p> \[W_0W_0^T = WRR^TW = W^TW\] <p>我们对 W 的变换并不会影响观测数据 x 的分布，也就是说有一系列 W 都会产生相同的预测分布。这里的矩阵 R 可以看成是隐变量空间的旋转，R 的存在表明隐变量空间具有旋转不变性的特征。</p> <p>回到之前对隐变量 z 先验分布的假设。如果我们不约束其高斯分布的参数，记 $z \sim N(m,\Sigma)$ ，此时可以写出 x 的分布 $x\sim N(Wm+u,\sigma^2I+W\Sigma W^T)$。我们令 $\hat{u} = Wm+u, \hat{W}=W\Sigma^{1/2}$ 可以得到和上面标准正态分布假设一样的结果。说明 z 的具体分布形式对建模没有影响。</p> <p>接下来我们考虑用极大似然来确定模型参数，</p> \[\ln p(X|u,W,\sigma) = -\frac{ND}{2}\ln (2\pi)-\frac{N}{2}\ln |C|-\frac{1}{2}\sum_{i=1}^N(x_i-u)^TC^{-1}(x_i-u)\] <p>这里的 C 就是观测数据 x 分布的方差，$C=WW^T+\sigma^2I$</p> <p>我们直接写出通过求导确定的参数解析解</p> \[u = \frac{1}{N}\sum_{i=1}^Nx_i\] \[W = U_M(L_M-\sigma^2I)^{1/2}R\] <p>这里 $U_M$ 是一个 DxM 的矩阵，每一列都是协方差矩阵 S 的一个特征向量。$L_M$ 是一个 MxM 的对角矩阵，每个对角值是 $U_M$ 中特征向量对应的特征值。R 是一个任意的 MxM 正交矩阵。可以证明，只有当 $U_M$ 中的 M 列是 S 的特征值前 M 大对应的特征向量时，可以取得似然方程的最大值（上式的其他解都对应的是鞍点）</p> \[\sigma^2 = \frac{1}{D-M}\sum_{i=M+1}^D \lambda_i\] <p>接下来我们对模型进行分析。考虑观测数据 x 的协方差矩阵 C，假设预测分布在某方向上的方差由单位向量 v 决定，即 $v^TCv$ 。如果我们首先假设 v 垂直与主成分空间，是剩余特征向量的线性组合，此时我们根据 $v^TU=0$ 可以得到 $v^TCv = \sigma^2$ 。如果我们再假设 v 就是某个被保留在 U 中的特征向量，此时我们根据 $v=u_i$ 可以得到 $v^TCv = \lambda_i$ 。这说明我们的模型完整地保留了数据在主成分方向上的方差，而用 $\sigma^2$ 去近似估计数据在其余方向的方差。</p> <p>在最开始我们提到 probabilistic PCA 则可以看成一种从隐空间 ${z}$ 到数据空间 ${x}$ 的映射，那么我们也可以利用贝叶斯定理来反向映射。</p> <p>和之前的假设一致，我们有</p> \[z \sim N(0,I),\ x\vert z \sim N(Wz+u,\sigma^2I) \Rightarrow z\vert x \sim N(M^{-1}W^T(x-u),\sigma^{-2}M)\] <p>这里 $M = W^TW+\sigma^2I$ ，是一个 MxM 的矩阵。代入极大似然的解 $u = \overline{x}$ ，我们写出后验分布的均值</p> \[E[z|x] = M^{-1}W^T(x-\overline{x})\] <p>通过观察可以发现，此时的方差 $\sigma^{-2}M$ 与 观测数据 x 是相互独立的。我们希望方差尽可能地小，取 $\sigma^2 \rightarrow 0$ ，此时后验分布的均值可以化简为</p> \[E[z|x] = (W^TW)^{-1}W^T(x-\overline{x})\] <p>这表示从数据空间投影到隐空间，我们又回到了传统的 PCA</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Principal Component Analysis]]></summary></entry><entry><title type="html">Neural Network</title><link href="https://jjjaaafff.github.io/blog/2021/ml7/" rel="alternate" type="text/html" title="Neural Network"/><published>2021-08-09T00:00:00+00:00</published><updated>2021-08-09T00:00:00+00:00</updated><id>https://jjjaaafff.github.io/blog/2021/ml7</id><content type="html" xml:base="https://jjjaaafff.github.io/blog/2021/ml7/"><![CDATA[<h2 id="multilayer-perceptron">Multilayer Perceptron</h2> <p>在之前的线性模型中，我们的模型基于固定非线性基函数 \(\phi(x)\) 的线性组合，即</p> \[y(x) = f(\sum_{i=1}^M w_i\phi_i(x))\] <p>在分类任务中，\(f(\cdot)\) 为非线性激活函数；在回归任务中，\(f(x)=x\) 。接下来我们进一步考虑，如果不用固定的基函数 \(\phi(x)\) ，而是让基函数内的参数也可以修改调整，这就引出了神经网络。</p> <p>在最基础的神经网络中，每一个基函数本身又可以看作是输入的线性组合。我们首先考虑最简单的两层神经网络。我们假设输入为 \(\{x_0,...,x_D\}\) ，中间层为 \(\{h_0,...,h_M\}\) ，最后的输出为 \(\{y_1,...,y_K\}\) （零下标的引入表示偏置bias）</p> <p>在第一层神经网络中，网络的输入为输入数据 X，输出为中间层数据 H，此时可以写出这一层对应的关系</p> \[h_m = f(\sum_{i=0}^D w_{mi}^{(1)}x_i)\] <p>在第二层神经网络中，网络的输入为中间层数据 H，输出为最终结果 Y，同样可以写出对应关系</p> \[y_k = g(\sum_{i=0}^Mw_{ki}^{(2)}h_i)\] <p>我们把两层网络结合到一起，即可得到数据输出与输入之间的关系</p> \[y_k(x) = g(\sum_{i=0}^Mw_{ki}^{(2)}f(\sum_{j=0}^D w_{ij}^{(1)}x_j))\] <p>这里的 \(f(\cdot)\) 和 \(g(\cdot)\) 都代表激活函数。通常选用连续的 sigmoidal 函数，利于整个网络微分，具体的激活函数选择视具体问题确定。但不管怎样，激活函数都必须具有非线性的性质，否则多层的网络就失去了意义，多重线性叠加等价于单层线性。</p> <p>在实际中，可以用更多层叠加构成网络，此时包括一个输入层，一个输出层和多个中间层</p> \[h_l=f_l(s_l), \quad s_l = w_lh_{l-1}+b_l,\quad for\ l=1,2,...,L\] <p>这里 \(l\) 代表不同的层，\(h_0\) 代表输入 X，\(h_L\) 用于预测输出 Y</p> <p>需要注意的是最后一层输出后，还需要经过一个激活函数得到最后的预测结果。这个激活函数记为输出激活函数。在不同任务中，使用不同的输出激活函数并对应不同的loss。在回归任务中，我们不需要输出激活函数，直接使用最小二乘loss即可。在分类任务中，我们最后要给出的是各个类别的分类预测概率，所以需要输出激活函数需要用 logistics sigmoid(二分类)或 softmax(多分类)，并结合交叉熵Loss进行优化。</p> <p>现在我们已经完成了多层感知机的建模，下一步就是考虑如何去训练优化我们的模型。我们用 \(w\) 统一代表模型所有的待优化参数，例如两层感知机中的 \(w^{(1)}, w^{(2)}\) 。我们的目的是找到一个 \(w\) 使得对应的 Loss 值最小。在这个问题中，很难给出梯度为零的模型解析解，因此通常采用迭代更新的方法逐渐修改模型参数，即</p> \[w^{(t+1)} = w^{(t)} + \Delta w^{(t)}\] <p>而在迭代更新中，我们可以结合梯度信息加速迭代到损失函数极小值的过程，使得每次参数都沿着梯度下降的方向更新，即梯度下降法。</p> <p>我们用 \(L\) 来表示 Loss function 损失函数。最直接的利用梯度信息更新参数的方法就是</p> \[w^{(t+1)} = w^{(t)} - \eta \nabla L(w^{(t)})\] <p>这里的 \(\eta\) 为正数，表示学习率，控制更新的幅度。但这种方法的更新速度显然太慢了，每次更新参数都需要计算整个数据集的 Loss 再求梯度。为此出现了一种在线算法，称为随机梯度下降，每次只选择数据集中的一个数据求其 Loss 的梯度用来更新，即</p> \[w^{(t+1)} = w^{(t)} - \eta \nabla L_i(w^{(t)}), \quad where\ \sum_{i=1}^n L_i = L\] <p>这里比较一下两种方法的优劣</p> <ul> <li>梯度下降法：在更新模型参数时，对所有梯度求和，最后得到一个大致方向，并沿该方向迭代。精度高但是效率低</li> <li>随机梯度下降法：每次迭代随机选择一个数据样本，向对应梯度方向迭代。精度低但是迭代速度快</li> </ul> <p>为了平衡梯度与效率，我们可以选择折中的方式，将数据集划分为一个个batch，每次随机选择一个batch，用该batch内的数据计算梯度，更新模型参数。</p> <p>在我们引入了模型参数迭代更新方法后，下一步就是求损失函数的梯度信息。在神经网络中，梯度信息是通过误差反向传播来高效求解的。</p> <h2 id="error-back-propagation">Error Back-propagation</h2> <p>这里我们继续沿用上面的两层网络的例子。为了区分训练过程中网络的预测输出值和ground-truth标签值，我们用 P 表示网络的预测，用 Y 表示 ground-truth，其他定义和上面一样，这里复制一下。假设输入为 \(\{x_0,...,x_D\}\) ，中间层为 \(\{h_0,...,h_M\}\) （零下标的引入表示偏置bias）</p> \[p_k(x) = g(\sum_{i=0}^Mw_{ki}^{(2)}h_i) = g(\sum_{i=0}^Mw_{ki}^{(2)}f(\sum_{j=0}^D w_{ij}^{(1)}x_j))\] <p>为了简化分析，我们假设激活函数均采用 logistics sigmoid ，并且是二分类任务。我们可以写出极大似然的目标</p> \[max \log P = \log \prod_{i=1}^n p_i^{y_i}(1-p_i)^{1-y_i} = \sum_{i=1}^n [y_iw^{(2)}h-\log (1+e^{w^{(2)}h})]\] <p>将其展开并转换为 Loss 可以得到</p> \[L(w^{(1)},w^{(2)}) = \sum_{i=1}^n \{y_i \sum_{j=1}^M w^{(2)}_{ij}h_j-\log (1+exp(\sum_{j=1}^M w^{(2)}_{ij}h_j)\}\] <p>我们首先对 \(w^{(2)}\) 求导可得</p> \[\frac{\partial L}{\partial w^{(2)}_{ij}} = (y_i-p_i)h_j\] <p>进一步根据链式法则对 \(w^{(1)}\) 求导可得</p> \[\frac{\partial L}{\partial w^{(1)}_{jk}} = \frac{\partial L}{\partial h_j}\frac{\partial h_j}{\partial w^{(1)}_{jk}}\] <p>L 对 h 的求导与对 \(w^{(2)}\) 的求导类似，我们直接写出</p> \[\frac{\partial L}{\partial h_j} =\sum_{i=1}^n (y_i-p_i)w^{(2)}_{ij}\] <p>而 h 对 \(w^{(1)}\) 的求导，我们根据 sigmoid 求导可得</p> \[\frac{\partial h_j}{\partial w^{(1)}_{jk}} = -\frac{exp(-w^{(1)}x_j) (-x_j)}{(1+exp(-w^{(1)}x_j))^2} = h_j(1-h_j)x_k\] <p>综合以上两个求导，我们得到最终 L 对 \(w^{(1)}\) 的求导结果</p> \[\frac{\partial L}{\partial w^{(1)}_{jk}} = \sum_{i=1}^n (y_i-p_i)w^{(2)}_{ij}h_j(1-h_j)x_k\] <p>由此我们也可以看出反向传播这个命名的来源。相比于从输入数据到预测输出的正向传播，我们在求梯度时，信息从输出层经过中间层传至输入层。我们首先根据预测输出和标签值，得到最后一层网络的梯度；再以此类推，直到得到第一层网络的梯度。</p> <p>在反向传播的第一步，我们需要传递的是 \(y-p\) 即误差。这就要求我们的输出层激活函数必须是 sigmoid 或 softmax，只有这样我们才能得到导数表达式中的 error 项（分类任务）。而中间层的激活函数没有要求，就只有求导计算式的不同，还是以上面的例子说明</p> \[Tanh: f(x) = \frac{e^x-e^{-x}}{e^x+e^{-x}} \Rightarrow \frac{\partial h_j}{\partial w^{(1)}_{jk}} = (1-h_j^2) x_k\] \[ReLU: f(x) = max(0,x) \Rightarrow \frac{\partial h_j}{\partial w^{(1)}_{jk}} = 1(h_j&gt;0)\cdot x_k\] <p>最后我们写一下反向传播的矩阵形式。首先写出链式法则的矩阵形式。假设 \(Y = (y_i)_{m\times 1}\) ，\(X = (x_i)_{n\times 1}\)<br/> 如果 \(Y=g(X)\) ，则可定义</p> \[\frac{\partial Y}{\partial X^T} = (\frac{\partial y_i}{\partial x_j})_{m\times n}\] <p>如果 \(Y=g(H), H=f(X)\) ，则有</p> \[\frac{\partial y_i}{\partial x_j} = \sum_{m} \frac{\partial y_i}{\partial h_m}\frac{\partial h_m}{\partial x_j} \Rightarrow \frac{\partial Y}{\partial X^T} = \frac{\partial Y}{\partial H^T}\frac{\partial H}{\partial X^T}\] <p>这里我们保持和之前多层感知机的例子一致，即</p> \[h_l=f_l(s_l), \quad s_l = w_lh_{l-1}+b_l,\quad for\ l=1,2,...,L\] <p>这里 \(l\) 代表不同的层，\(h_0\) 代表输入 X，\(h_L\) 用于预测输出 Y<br/> 我们首先写出链式法则的关系</p> \[\frac{\partial L}{\partial s_l^T} = \frac{\partial L}{\partial h_l^T}\frac{\partial h_l}{\partial s_l^T} = \frac{\partial L}{\partial h_l^T}f_l'\] \[\frac{\partial L}{\partial h_{l-1}^T} = \frac{\partial L}{\partial h_l^T}\frac{\partial h_l}{\partial s_l^T}\frac{\partial s_l}{\partial h_{l-1}^T} = \frac{\partial L}{\partial h_l^T}f_l'W_l\] <p>我们可以得到最后的结论</p> \[\frac{\partial L}{\partial h_{l-1}} = W_l^Tf_l'\frac{\partial L}{\partial h_l}, \qquad \frac{\partial L}{\partial W_l} = f_l'\frac{\partial L}{\partial h_l}h_{l-1}^T\] <p>这里的 \(f_l' = \frac{\partial h_l}{\partial s_l^T}\) 是对角矩阵，第 k 个元素是 \(\frac{\partial h_{lk}}{\partial s_{lk}}\)</p> <h2 id="the-hessian-matrix">The Hessian Matrix</h2> <p>我们首先给出 Hessian Matrix 的定义。我们将 Loss function L(w) 在某一点 \(\hat{w}\) 泰勒展开可以得到</p> \[L(w) \approx L(\hat{w}) + (w-\hat{w})^T\nabla L|_{w=\hat{w}} + \frac{1}{2} (w-\hat{w})^T H (w-\hat{w})\] <p>这里的 H 即为 Hessian Matrix，\(H = \nabla \nabla L\) ，展开可以写成</p> \[H_{ij} = \frac{\partial^2 L}{\partial w_i \partial w_j}\vert_{w=\hat{w}}\] <p>接下里我们考虑用反向传播的思想来求 Hessian Matrix ，PRML书中提到了几种求 Hessian Matrix 的近似方法</p> <ul> <li>Diagonal approximation：这种方法将 Hessian Matrix 近似为一个对角矩阵求解，所有非对角位置上的元素均为零。</li> <li>Outer product approximation：这种方法将 Hessian Matrix 近似看成梯度的内积，这种情况下只需要梯度信息就可以得到 Hessian Matrix，即</li> </ul> \[H \approx \sum_{i=1}^n b_ib_i^T, \quad where\ b_i = \nabla y_i = \nabla a_i\] <p>这种方法只适用于训练好的网络，因为我们在近似过程中忽略的一项与误差相关。在更广泛的网络下，误差会很大，此时这一项则不能忽略，这种近似变得不精确</p> <ul> <li>Inverse Hessian：基于上面的 Outer product approximation，我们可以进一步用迭代的方式去近似 Hessian 矩阵的逆，假设我们已经得到了根据前 L 个数据计算出的 Hessian 矩阵 \(H_L\) ，进一步加入第 L+1 个数据，则可以得到</li> </ul> \[H_{L+1} = H_L + b_{L+1}b_{L+1}^T\] \[H_{L+1}^{-1} = H_{L}^{-1} - \frac{H_{L}^{-1}b_{L+1}b_{L+1}^TH_{L}^{-1}}{1+b_{L+1}^TH_{L}^{-1}b_{L+1}}\] <p>所以我们假设初始矩阵 \(H_0 = \alpha I\)，这里 \(\alpha\) 是一个小量，最后就可以根据这个迭代算法找到 \(H+\alpha I\) 的逆</p> <ul> <li>Finite differences：这种方法利用微分的思想</li> </ul> \[\frac{\partial^2L}{\partial w_{ji}\partial w_{lk}} = \frac{1}{2\epsilon}\{\frac{\partial L}{\partial w_{ji}}(w_{lk}+\epsilon) - \frac{\partial L}{\partial w_{ji}}(w_{lk}-\epsilon)\} + O(\epsilon^2)\] <p>Hessian 矩阵的作用有很多，接下来举一个例子来说明其重要性。</p> <p>在我们训练网络的时候，如果某一时刻 Loss 的梯度突然为零。此时按照 SGD 的迭代方式，模型参数将不再更新。此时有两种情况，一种是我们来到了局部的极小值，另一种是我们来到了鞍点 saddle point</p> <p>那么如何区分具体是哪一种情况呢，我们需要利用 Hessian Matrix 来了解 Loss surface 的情况。这里直接给出结论</p> <ul> <li>当 Hessian Matrix 为正定时，此时梯度为零的点对应极小值</li> <li>当 Hessian Matrix 为负定时，此时梯度为零的点对应极大值</li> <li>其他情况下，梯度为零的点是鞍点</li> </ul> <p>如果来到了鞍点，我们可以也利用 Hessian Matrix 来进一步确定参数更新的方向，从而逃离鞍点。我们取小于零的 eigen value 值对应的 eigen vector 的方向作为参数更新方向。（这种方法在实际中很少用，因为涉及 H 的计算量很大）</p> <p>随着维度的增加，在低维中看起来是局部极小值的点，可能在高维中仍然可以优化。所以当模型参数很多，形成的维度空间很大时，local minima 可能本身就是很罕见的。</p> <h2 id="regularization-in-neural-networks">Regularization in Neural Networks</h2> <p>在神经网络模型中，我们需要控制模型复杂度来避免过拟合的现象。控制模型复杂度有很多方法，其中一种方法是选择一个较大的模型参数数量，在损失函数中添加正则项来控制复杂度。最简单的正则项是二次函数，也被称为权值衰减，即</p> \[\tilde{L}(w) = L(w) + \lambda w^Tw\] <p>这种正则方式在之前的线性模型中介绍过，超参 \(\lambda\) 控制模型的复杂度。但这种正则方式不能在线性缩放中保持一致。以两层感知机为例，如果我们同时以不同倍数缩放输入值和标签值，那么两层网络参数的变化倍数是不同的，而仅凭 \(\lambda w^Tw\) 这一项则无法进行区分。</p> <p>此外，另一种控制模型复杂度的方法称为早停止 early stopping，是说我们在训练的过程中，添加一个validation set，在validation set上同样去计算误差，当误差达到最小时就提前停止训练。</p> <h2 id="invariances">Invariances</h2> <p>在模式识别中，我们的模型需要具有 Invariances 的性质。也就是说，当我们对输入数据进行变换后，对应的输出预测结果应该是不变的。首先我们用数学来刻画表征这样的变换。</p> <p>以图像数据为例，假设 x 是一张输入图片，s 表示变换（比如旋转），并由一个变换系数 \(\xi\) 控制（比如旋转角度）。此时变换后的数据可表示为 \(s(x,\xi)\) ，同时 \(s(x,0) = x\) 表示无变换。</p> <p>接下来我们介绍两种增加模型泛化能力的方法。第一种方式是最直觉的，我们直接对输入数据进行不同程度的随机变换，将变换后的数据输入模型进行训练。以最小二乘误差为例，原本的 Loss 可写为</p> \[L = \int\int (y(x)-y^*)^2p(y^*|x)p(x)dxdy^*\] <p>而对其变换后可写为</p> \[L = \int\int \{y(s(x,\xi))-y^*\}^2p(y^*|x)p(x)p(\xi)dxdy^*d\xi\] <p>第二种方式是通过添加正则项的方式，这种方法也称为 tangent propagation，我们计算出变换函数的导数 \(\tau\)</p> \[\tau = \frac{\partial s(x,\xi)}{\partial \xi}\vert _{\xi=0}\] <p>当我们输入变换后的数据，我们可以写出第k输出值 \(y_k\) 对 \(\xi\) 的导数</p> \[\frac{\partial y_k}{\partial \xi}\bigg\vert _{\xi=0} = \sum_{i=1}^n \frac{\partial y_k}{\partial x_i}\frac{\partial x_i}{\partial \xi} \bigg\vert_{\xi =0} = \sum_{i=1}^n \frac{\partial y_k}{\partial x_i}\tau_i \bigg\vert_{\xi =0}\] <p>我们就可以用上式作为正则项，即</p> \[\tilde{L} = L + \lambda \Omega, \qquad where\ \Omega = \sum_n\sum_k(\frac{\partial y_k}{\partial \xi}\bigg\vert _{\xi=0})^2\] <p>其中的 \(\frac{\partial y_k}{\partial x_i}\) 可以通过反向传播得到，\(\tau_i\) 可以通过上面提到的 Finite differences 微分得到。</p> <p>通过理论可以证明，这两种方法是高度关联的。</p> <h2 id="mixture-density-network">Mixture Density Network</h2> <p>在我们之前的模型中，只能为每个输入值预测一个输出值。如果想让模型对每个输入有不同的输出值范围，可以借助混合密度网络(Mixture Density Network, MDN)。MDN 并不是让网络预测单一输出值，而是预测输出的整个概率分布。我们以高斯混合模型来刻画，输出值被建模为多个高斯随机值的和。所以，对于每个输入 x ，我们可以通过该模型得到对应的概率分布函数 \(p(y\vert x)\) ，即</p> \[p(y\vert x) = \sum_{i=1}^K \pi_k(x)N(y\vert \mathbf{\mu_k(x)},\sigma^2_k(x))\] <p>我们假设某个输入 x 对应的标签值为 K 维向量，在传统的神经网络中，我们的输出层只有 K 个单元，对应标签的维度。而在混合密度网络中</p> <ul> <li>输出层首先要包含 K 个单元来确定方差 \(\sigma_k(x)\) ，我们用 \(a^{\sigma}_k\) 来表示</li> <li>其次要包含 K 个单元来确定混合系数 \(\pi_k(x)\) ，我们用 \(a^{\pi}_k\) 来表示</li> <li>最后我们假设输入数据为 L 维，则还需要包含 \(L\times K\) 个单元来确定均值 \(\mu_{kj}(x)\) ，我们用 \(a^{\mu}_{kj}\) 来表示。可以看到，总共的输出单元相比于原来的 K，变成了 \((L+2)\times K\)</li> </ul> <p>所以混合密度网络最后的输出包含 \(\{a^{\sigma}_k, a^{\pi}_k, a^{\mu}_{kj}\}\) 。而我们对最后的概率分布函数和网络输出之间的对应关系为</p> \[\pi_k(x) = \frac{exp(a^{\pi}_k)}{\sum_{i=1}^Kexp(a^{\pi}_i)}\] \[\sigma_k(x) = exp(a^{\sigma}_k)\] \[\mu_{kj}(x) = a^{\mu}_{kj}\] <p>接着我们用 w 显式地表示模型中的学习参数，写出混合密度网络中的损失函数</p> \[L(w) = -\sum_{i=1}^n\ln \{\sum_{k=1}^K \pi_k(x_i,w)N(y\vert \mathbf{\mu_k}(x_i,w),\sigma^2_k(x_i,w))\}\] <p>我们同样可以用误差反向传播来更新参数，这里直接给出理论推导后得到输出层更新公式</p> \[\frac{\partial L_n}{\partial a^{\pi}_k} = \pi_k - \gamma_k\] \[\frac{\partial L_n}{\partial a^{\mu}_{kj}} = \gamma_k (\frac{\mu_{kj}-y^*_{j}}{\sigma^2_k})\] \[\frac{\partial L_n}{\partial a^{\sigma}_k} = -\gamma_k (\frac{||y^*_n-\mu_k||^2}{\sigma^3_k} - \frac{D}{\sigma_k})\] <p>该方法和 EM 算法的不同是，EM 算法是通过迭代近似得到高斯混合模型中的一系列参数，而混合密度网络是通过神经网络来学习这些参数。</p>]]></content><author><name></name></author><category term="MachineLearning"/><summary type="html"><![CDATA[Book Notes on Pattern Recognition and Machine Learning (PRML)]]></summary></entry><entry><title type="html">Sampling Methods</title><link href="https://jjjaaafff.github.io/blog/2021/ml8/" rel="alternate" type="text/html" title="Sampling Methods"/><published>2021-08-09T00:00:00+00:00</published><updated>2021-08-09T00:00:00+00:00</updated><id>https://jjjaaafff.github.io/blog/2021/ml8</id><content type="html" xml:base="https://jjjaaafff.github.io/blog/2021/ml8/"><![CDATA[<h2 id="basic-sampling-algorithm">Basic Sampling Algorithm</h2> <p>我们首先来考虑一个最基本的问题，在给定某范围内均匀分布的随机变量后，我们如何用其得到任意分布的随机变量。</p> <p>假设我们已知均匀分布在 (0,1) 上的随机变量 z，我们对 z 进行变换得到 y，即 \(y=f(z)\) ，那么 y 的分布可以写成</p> \[p(y) = p(z)|\frac{dz}{dy}|\] <p>在这个例子中，z 是均匀分布的，所以 \(p(z) = 1\) 。我们的目标是找到这样一个变换函数 \(f(\cdot)\) 使得 y 的分布为 \(p(y)\) 。通过积分可以将这两者联系起来</p> \[z=h(y) \equiv \int_{-\infty}^y p(\hat{y})d\hat{y}\] <p>所以对应的变换函数就是上式的反函数，即 \(y = h^{-1}(z)\)</p> <p>这里通过一个例子来说明，假设我们期望的 y 服从指数分布，即 \(p(y) = \lambda exp(-\lambda y)\) ，这里 y 为非负数，那么此时我们可以得到 z 和 y 的关系</p> \[z=h(y) \equiv \int_{-\infty}^y \lambda exp(-\lambda \hat{y})d\hat{y} = 1-exp(-\lambda y)\] <p>我们对其求反函数，即可得到变换函数</p> \[y = h^{-1}(z) = -\frac{\ln (1-z)}{\lambda}\] <p>所以，通过上式我们实现了从均匀分布中得到指数分布</p> <h3 id="rejection-sampling">Rejection sampling</h3> <p>拒绝采样思想最典型的应用是求圆周率，我们通过随机生成点计算到原点的距离，接受落在圆内的点，以此来进行估计。</p> <p>假设我们要从一个和普通标准分布不同的不常见分布 \(p(z)\) 中采样，直接从该分布中取样不太现实。但我们通常可以对任意给定的 z 值计算 \(p(z)\)</p> <p>给定一个概率分布 \(p(z) = \tilde{p}(z)/Z_p\) ，其中 \(\tilde{p}(z)\) 已知，\(Z_p\) 为未知的归一化常数。我们想对 \(p(z)\) 进行拒绝采样，需要引入一个参考分布 \(q(z)\) ，这是一个人为选择的容易采样的分布。接下来我们找一个常数值 k 对任意值都满足 \(kq(z)\geq \tilde{p}(z)\)</p> <p>现在我们就可以借助 \(q(z)\) 来进行拒绝采样。我们首先从 \(q(z)\) 中随机生成一个数 \(z_0\) ，接着从区间 \([0,k(z_0)]\) 中均匀随机生成另一个数 \(\mu_0\) 。如果 \(\mu_0 &gt; \tilde{p}(z_0)\) 则拒绝该采样；否则接受。最后剩下的接受样本就是我们的采样结果。</p> <p>为了保证采样被接受的概率，我们需要选择满足条件的尽可能小的 k 值，否则将会有非常多的样本被拒绝浪费。但现在仍然存在一个问题，那就是参考分布 \(q(z)\) 的选取。我们希望参考分布和目标分布之间尽可能的相似，但通常我们很难根据先验知识直接构建一个合适的 \(q(z)\) ，所以这里考虑利用已知的 \(p(z)\) 测定值构建包络函数</p> <p>当 \(p(z)\) 是对数凹分布时，我们可以选择 \(\ln p(z)\) 的若干处的切线及交点组成包络函数。其本身由一系列分段指数分布组成，即</p> \[q(z) = k_i\lambda_iexp\{-\lambda_i(z-z_i)\}, \quad z_{i-1} &lt; z \leq z_i\] <p>此时我们在拒绝采样的过程中，也可以根据被拒绝的样本逐步更新优化我们的包络函数 \(q(z)\) ，这种方法也被称为 Adaptive rejection sampling</p> <p>但拒绝采样只适用于一维二维的低维数据。当维度变高时，k 的值会逐渐增大，这意味着接受率会随着维度增加而指数级减小。同时参考分布也会随着维度增加变得更难确定。</p> <h3 id="importance-sampling">Importance sampling</h3> <p>我们采样的根本目的还是为了计算期望，即</p> \[E[f] = \int f(z)p(z)dz\] <p>而重要采样可以直接用来近似期望，跳过了从分布 \(p(z)\) 中采样的环节。</p> <p>当我们可以直接从 \(p(z)\) 中采样时，我们可以用有限项求和代替积分来近似期望，即</p> \[E[f] \approx \frac{1}{L}\sum_{i=1}^L f(z^{(i)})\] <p>但通常从 \(p(z)\) 中直接采样时不现实的，但给定 \(z_0\) 的值则可以容易地计算 \(p(z_0)\)，一种替代方法是</p> \[E[f] \approx \sum_{i=1}^L f(z^{(i)})p(z^{(i)})\] <p>我们可以发现，在这种替代方法中，求和项随着 z 维度的增加而指数级增加。而且从 z 空间中均匀采样的效率很低，我们希望从 \(p(z)\) 较大的区域或者说乘积 \(f(z)p(z)\) 较大的区域采样，这就引出了重要采样。</p> <p>在重要采样中，我们还是引入一个参考分布 \(q(z)\)，不过和拒绝采样不同，在这里我们假设 \(q(z)\) 和 \(p(z)\) 具有相同的性质，即 \(q(z) = \tilde{q}(z)/Z_q\) ，其中 \(\tilde{q}(z)\) 已知，\(Z_q\) 为未知的归一化常数，此时我们再写出期望的计算式</p> \[E[f] = \int f(z)p(z)dz = \frac{Z_q}{Z_p} \int f(z)\frac{\tilde{p}(z)}{\tilde{q}(z)}q(z)dz\] <p>我们用 \(\tilde{r}_i =\tilde{p}(z^{(i)})/\tilde{q}(z^{(i)})\) 代替，用求和代替积分近似。可以从上式变换得到</p> \[E[f] \approx \frac{Z_q}{Z_p}\frac{1}{L} \sum_{i=1}^L \tilde{r}_if(z^{(i)})\] <p>这个 \(\tilde{r}_i\) 也被称为重要权重 (importance weights)，用于纠正从错误分布里采样引入的 bias。不同于拒绝采样，重要采样中所有的样本都会被保留。我们用保留的样本集计算比值 \(Z_p/Z_q\)，有</p> \[\frac{Z_p}{Z_q} = \frac{1}{Z_q}\int \tilde{p}(z)dz = \int \frac{\tilde{p}(z)}{\tilde{q}(z)}q(z)dz \approx \frac{1}{L}\sum_{i=1}^L\tilde{r}_i\] <p>将这个比值代入上面期望的计算式中，我们可以得到重要采样最终的期望计算式</p> \[E[f] \approx \sum_{i=1}^L w_if(z^{(i)}),\quad where \ w_i = \frac{\tilde{r}_i}{\sum_m \tilde{r}_m} = \frac{\tilde{p}(z^{(i)})/q(z^{(i)})}{\sum_m \tilde{p}(z^{(m)})/q(z^{(m)})}\] <p>和拒绝采样类似，重要采样的近似程度取决于 \(q(z)\) 和 \(p(z)\) 之间的相似程度。通常 \(p(z)f(z)\) 集中分布在 z 空间下的很小一部分区域，对应我们的重要权重 \(\{r_i\}\) 中部分元素值很大，剩下的权重则没那么重要。因此有效的采样数实际上是远小于总采样数 L 的。重要采样还有一个缺点，即使期望估计效果非常差，也没有指标能看出来。所以这就要求参考分布 \(q(z)\) 不应该在 \(p(z)\) 较大的地方取值较小或为零</p> <h3 id="sampling-importance-resampling">Sampling-importance-resampling</h3> <p>在拒绝采样中，我们需要找一个 k 值来约束 \(kq(z)\geq \tilde{p}(z)\) 。而在很多情况下，合适的 k 值也很难找。因为一旦 k 值过大就会导致低接受率。所以提出了 sampling-importance-resampling (SIR) 的方法，结合拒绝采样和重要采样来避免寻找合适 k 值</p> <p>SIR 方法分为三个步骤</p> <ul> <li>第一步我们从 \(q(z)\) 中采样 L 个样本，记作 \(\{z^{(1)},...,z^{(L)}\}\)</li> <li>第二步，我们根据这些样本，结合重要采样中权值 \(w\) 的计算式，计算不同采样的权重 \(\{w_1,...,w_L\}\)</li> <li>第三步，我们在这 L 个样本组成的样本集内重新采样，每个样本被采样的概率就是其对应的权重值</li> </ul> <p>此时我们重采样得到的样本就可以近似认为是对 \(p(z)\) 的采样。可以证明，当 \(L \rightarrow \infty\) 时，重采样等同于对 \(p(z)\) 的采样。</p> <p>我们首先写出重采样对应的分布</p> \[p(z\leq a) = \sum_{i:z_i\leq a} w_i = \frac{\sum_i I(z^{(i)}\leq a) \tilde{p}(z^{(i)})/q(z^{(i)})}{\sum_m \tilde{p}(z^{(m)})/q(z^{(m)})}\] <p>当 \(L \rightarrow \infty\) 时，我们就可以用积分来代替求和，此时再写出分布</p> \[p(z\leq a) = \frac{\int I(z\leq a) \{\tilde{p}(z)/q(z)\} q(z)dz}{\int \{\tilde{p}(z)/q(z)\} q(z)dz} = \frac{\int I(z\leq a)\tilde{p}(z)dz}{\int \tilde{p}(z)dz} = \int I(z\leq a)p(z)dz\] <p>可以发现这就是 \(p(z)\) 的累积分布函数</p> <h2 id="markov-chain-monte-carlo">Markov Chain Monte Carlo</h2> <p>在上面的基础采样方法中，我们介绍了用于估计函数期望的两种采样方法。但无论是拒绝采样还是重要采样，都很难应用在高维度的数据上。所以我们在这里引入 Markov chain Monte Carlo (MCMC) 框架。</p> <p>在之前的采样方法中，我们都是不断地从参考分布中独立采样。在 MCMC 中，我们维护对当前状态 \(z^{(\tau)}\) 的记录，参考分布 \(q(z\vert z^{(\tau)})\) 取决于当前的状态。所以我们的一系列采样 \(z^{(1)},z^{(2)},...,\) 构成了马尔科夫链。这里的采样分布和之前一致，\(p(z) = \tilde{p}(z)/Z_p\) ，其中 \(\tilde{p}(z)\) 已知，\(Z_p\) 为未知的归一化常数，我们首先来看最基础的 Metropolis 算法</p> <h3 id="metropolis-algorithm">Metropolis algorithm</h3> <p>使用该算法时，我们假设参考分布具有对称性，即 \(q(z_a\vert z_b) = q(z_b\vert z_a)\) 。在每轮算法迭代中，我们首先从参考分布 \(q(z\vert z^{(\tau)})\) 中生成采样 \(z^\star\) ，然后计算接受概率</p> \[A(z^\star,z^{(\tau)}) = min(1,\frac{\tilde{p}(z^\star)}{\tilde{p}(z^{(\tau)})})\] <p>我们在 (0,1) 区间上取随机数 \(\mu\) ，如果 \(A(z^\star,z^{(\tau)}) &gt; \mu\) ，那么我们就接受这个样本 \(z^\star\) 。</p> <p>我们可以发现，如果从状态 \(z^{(\tau)}\) 转移到状态 \(z^\star\) 可以提升 \(p(z)\)，那么这个样本点 \(z^\star\) 一定会被接受。根据马尔科夫的规则，如果我们接受了样本 \(z^\star\) ，则下一个状态会被设置为该样本，即 \(z^{(\tau+1)} = z^\star\) ；否则被设置为和当前状态一致，即 \(z^{(\tau+1)} = z^{(\tau)}\) 。接着迭代到了下一轮，从参考分布 \(q(z\vert z^{(\tau+1)})\) 中采样并以此类推</p> <p>当我们对问题进行泛化，不再假设参考分布具有对称性时，此时的算法称为 Metropolis-Hastings 算法，A 的计算式发生了改变</p> \[A(z^\star,z^{(\tau)}) = min(1,\frac{\tilde{p}(z^\star)q(z^{(\tau)}\vert z^\star)}{\tilde{p}(z^{(\tau)})q(z^\star \vert z^{(\tau)})})\] <h3 id="gibbs-sampling">Gibbs Sampling</h3> <p>Gibbs 采样可以看成是 Metropolis-Hastings 算法的一个特例。我们假设要采样的分布为 \(p(\mathbf{z}) = p(z_1,..,z_M)\) 。</p> <p>我们首先选取初始状态。之后在算法的迭代中，每次将一个变量的值变成基于剩下变量的采样值。这里直接给出采样流程</p> <ul> <li>确定初始化状态，\(\{z_1^{(1)},...,z_M^{(1)}\}\)</li> <li> <p>记当前状态为 \(\tau\)，在算法的一次更新中</p> <ul> <li>采样 \(z_1^{(\tau+1)} \sim p(z_1\vert z_2^{(\tau)},z_3^{(\tau)},..,z_M^{(\tau)})\)</li> <li>……</li> <li>采样 \(z_j^{(\tau+1)} \sim p(z_j\vert z_1^{(\tau+1)},...,z_{j-1}^{(\tau+1)},z_{j+1}^{(\tau)},..,z_M^{(\tau)})\)</li> <li>……</li> <li>采样 \(z_M^{(\tau+1)} \sim p(z_M\vert z_1^{(\tau+1)},z_2^{(\tau+1)},..,z_{M-1}^{(\tau+1)})\)</li> </ul> </li> </ul> <p>接下来我们来看一下 Gibbs 采样与 Metropolis-Hastings 算法之间的联系。</p> <p>在 Gibbs 采样中，我们每次根据剩下的状态元素来更新某个状态元素。对应的参考分布可以写为 \(q_k(z^\star \vert z) = p(z_k^\star \vert z_{\backslash k})\) ，此时我们写出对应的 A</p> \[A(z^\star,z) = \frac{p(z^\star)q_k(z\vert z^\star)}{p(z)q_k(z^\star \vert z)} = \frac{p(z_k^\star \vert z^\star_{\backslash k}) p(z^\star_{\backslash k}) q_k(z\vert z^\star) }{p(z_k \vert z_{\backslash k}) p(z_{\backslash k}) q_k(z^\star \vert z)} = \frac{p(z_k^\star \vert z^\star_{\backslash k}) p(z^\star_{\backslash k}) p(z_k\vert z^\star_{\backslash k}) }{p(z_k \vert z_{\backslash k}) p(z_{\backslash k}) p(z^\star_k \vert z_{\backslash k})}\] <p>在 Gibbs 采样中，每次更新状态元素时，剩下元素没有发生改变。也就是说 \(z^\star_{\backslash k} = z_{\backslash k}\) ，代入上式可以发现</p> \[A(z^\star,z) = 1\] <p>说明 Metropolis-Hastings 每一步迭代得到的样本都会被接受，对应 Gibbs 采样中的每一次更新</p> <h3 id="slice-sampling">Slice Sampling</h3> <p>这里待采样分布和之前一致，\(p(z) = \tilde{p}(z)/Z_p\) ，其中 \(\tilde{p}(z)\) 已知，\(Z_p\) 为未知的归一化常数。</p> <p>Slice sampling 的思想是引入另一个变量 u，抽取联合分布样本，从概率密度函数 p(x) 所围成的面积里均匀采样，即</p> \[\hat{p}(z,u) = 1/Z_p \ \ if \ 0\leq u \leq \tilde{p}(z); \quad else\ \ 0\] <p>此时上式的边缘分布就是待采样分布，所以我们可以通过对 \(\hat{p}(z,u)\) 采样并忽略 u 来实现对 \(p(z)\) 的采样，证明如下</p> \[\int \hat{p}(z,u)du = \int_0^{\tilde{p}(z)} \frac{1}{Z_p}du = \frac{\tilde{p}(z)}{Z_p} = p(z)\] <p>在进行采样时，可以采用 Gibbs 采样方法，即</p> <ul> <li>初始化变量 \(u^{(0)}\)</li> <li>采样 \(z^{(t)} \sim p(z\vert u^{(t-1)})\)</li> <li>采样 \(u^{(t)} \sim p(u\vert z^{(t)})\)</li> </ul> <p>从直观上来描述，我们首先在上一步选取了样本 \(z^{(t-1)}\) ，然后由均匀分布得到 \(u^{(t)} \sim U(0,\tilde{p}(z^{(t−1)})\) 。此后，再从 \(z^{(t)}\sim U(\tilde{p}(z)&gt;u^{(t)})\) 采样。</p> <p>我们可以发现，\(u\) 是很容易得到的，因为它的分布是确定的。而 \(z\) 的采样则不那么容易，它的分布甚至是不连续的。原论文中给出了两种启发式的解决方案来探寻不连续的 \(z\) 采样（这也就是叫做slice sampling的原因）。第一种方式叫 stepping out and shrinkage procedure，第二种方式叫 doubling procedure</p>]]></content><author><name></name></author><category term="MachineLearning"/><summary type="html"><![CDATA[Book Notes on Pattern Recognition and Machine Learning (PRML)]]></summary></entry><entry><title type="html">Mixture Models and EM</title><link href="https://jjjaaafff.github.io/blog/2021/ml6/" rel="alternate" type="text/html" title="Mixture Models and EM"/><published>2021-08-05T00:00:00+00:00</published><updated>2021-08-05T00:00:00+00:00</updated><id>https://jjjaaafff.github.io/blog/2021/ml6</id><content type="html" xml:base="https://jjjaaafff.github.io/blog/2021/ml6/"><![CDATA[<h2 id="k-means-clustering">K-means Clustering</h2> <p>K-means 聚类是一种无监督学习，从数据本身的特征出发，不依靠标签将数据划分为不同类别。K-means 的算法流程很直观，因此我们先介绍 K-means 聚类的实现流程，再从数学角度刻画分析</p> <p>K-means 算法流程如下：</p> <ol> <li>首先选择 K 值，即最终将数据聚为 K 类。</li> <li>初始化，在每个类中选择一个数据点将其划分进去，作为该类的中心</li> <li>对每个数据点，将其划分到距类中心最近的类中</li> <li>所有点划分完成后，根据划分好的数据更新这 K 个类中心点的位置</li> <li>重新分配每一个数据点到最近的类中</li> <li>重复步骤 4 和 5直到收敛</li> </ol> <p>在介绍完算法流程后，我们用数学形式去刻画该方法。我们假设数据集为 \(\{x_1,...,x_n\}\) ，需要将其聚为 k 类。每个类别 k 的中心点记为 \(\mu_k\) ，由此我们可以写出距离公式作为损失函数，即</p> \[L = \sum_{i=1}^n\sum_{j=1}^k\delta_{ij}||x_i-\mu_j||^2\] <p>这里的 \(\delta_{ij}\) 为 0-1 函数，如果数据 i 被划分到类别 j，那么 \(\delta_{ij}=1\) ；否则为零。我们的目标就是找到每个数据的划分方式 \(\delta\) ，以及各聚类的中心点 \(\mu\) ，使得loss最小。我们可以通过迭代的方式来实现目标。我们最开始先确定初始的中心点 \(\mu\)</p> <p>接下来第一步是确定划分方式 \(\delta\) 。此时我们已经有上一步得到的各聚类中心点 \(\mu\) ，那么对于某个数据 \(x_i\) 而言，我们写出划分方式对应的更新公式</p> \[\delta_{ik} = 1 \quad if\ k=argmin_{j}||x_i-\mu_j||^2 \qquad (else\ \ 0)\] <p>在迭代的第二步，我们要修改中心点的位置。我们对损失函数求导，可以得到其关于 \(\mu\) 的导数</p> \[\frac{\partial L}{\partial \mu_j} = 2\sum_{i=1}^n\delta_{ij}(\mu_j-x_i)=0 \Rightarrow \mu_j = \frac{\sum_{i}\delta_{ij}x_i}{\sum_i\delta_{ij}}\] <p>此外，我们也可以利用在线的随机算法来实现聚类中心 \(\mu\) 的更新。对某个数据 \(x_i\) ，我们更新距其最近的聚类中心 \(\mu_j\) 的值，即</p> \[\mu_j^{new} = \mu_{j}^{old} + \eta(x_i-\mu_{j}^{old})\] <p>最后是关于 K-means 算法的一些细节</p> <ul> <li>收敛的标准是数据点不再移动到其它类，同时各类的中心点位置不变。此时对应的Loss可能只是极小值，不一定是全局最小（这与初始聚类中心的选取有关）</li> <li>算法的复杂度：每一次迭代是 O(KN) ，K 是类别数，N 是数据总数</li> <li>聚类数 K 的选取：尝试不同的 K ，计算数据点到类中心的平均距离。该距离会急剧下降直到合适的 K 值，然后缓慢变化</li> </ul> <h2 id="expectation-maximization-algorithm">Expectation Maximization Algorithm</h2> <p>EM 算法是用来寻找含隐变量的概率模型极大似然解的一种方法。和上面一样，我们还是先给出 EM 算法的流程，再从数学角度刻画分析。</p> <p>我们记观察变量为 X，隐变量为 Z，模型参数统记为 \(\theta\) 。EM 算法用来求解后验概率 \(p(X\vert\theta)\) 的极大似然，包含 E 和 M 两步。</p> <ul> <li>E-step: 计算 \(Q(\theta\vert\theta^{(t)})\) ，这里</li> </ul> \[Q(\theta\vert\theta^{(t)}) = E_{Z\sim P(Z\vert X,\theta^{(t)})}[\ln P(X,Z\vert \theta)]\] <ul> <li>M-step: 选择使 \(Q(\theta\vert\theta^{(t)})\) 最大的参数，用来更新当前模型参数，即</li> </ul> \[\theta^{(t+1)} = argmax_{\theta}Q(\theta\vert\theta^{(t)})\] <p>可以看到，这是一个迭代的过程，因此整体的 EM 算法流程可写为</p> <ol> <li>初始化，给出初始的模型参数 \(\theta^{(0)}\)</li> <li>E-step，在给定模型 \(\theta\) 下，计算不同隐变量值 Z 的概率，进而计算 \(Q(\theta\vert\theta^{(t)})\)</li> <li>M-step，利用计算的 Q 值更好地修改模型</li> <li>重复 2 和 3 步骤直至收敛</li> </ol> <p>在介绍完 EM 算法的流程后，很自然我们有两个问题。E-step 中的优化目标 \(Q(\theta\vert\theta^{(t)})\) 是从何而来的呢？EM算法为什么是正确的呢？</p> <p>我们首先来看第一个问题，E-step中的优化目标从何而来？对此我们有两种解释方式</p> <ul> <li>首先我们想用极大似然估计，用观测数据去确定模型参数，即</li> </ul> \[max_{\theta}\ln P(X\vert \theta) = max_{\theta} \ln \sum_{Z}P(X,Z\vert \theta)\] <p>这里 Z 作为未知的隐变量，表示 X 中各个数据所属的类别。由于 Z 未知，我们无法直接得到原优化目标里的 \(P(X,Z\vert \theta)\) 。但如果给出 X 和 \(\theta\) ，我们可以求出 Z 对应的后验分布，即 \(P(Z\vert X,\theta)\) 。所以我们先根据现有模型去猜测 Z 的分布，再用这个猜测的 Z 去计算极大似然，从而改善模型参数。这样我们就得到了 E-step中的优化目标，即 \(max_{\theta} E_{Z\sim P(Z\vert X,\theta^{(t)})}[\ln P(X,Z\vert \theta)]\)</p> <ul> <li>第二种解释方式是梯度更新的角度。我们的原目标为极大似然 \(max_{\theta} \ln P(X\vert\theta)\) ，我们对优化目标求导可以得到</li> </ul> \[\Delta\theta = \eta\frac{1}{P(X\vert\theta)}\frac{\partial}{\partial\theta}P(X\vert\theta) = \eta\frac{1}{P(X\vert\theta)}\sum_{Z}\frac{\partial}{\partial\theta}P(X,Z\vert\theta)\] \[\Delta\theta = \eta\frac{1}{P(X\vert\theta)}\sum_{Z}P(X,Z\vert\theta)\frac{\partial}{\partial\theta}\ln P(X,Z\vert\theta)\] \[\Delta\theta = \eta\sum_{Z}P(Z\vert X,\theta)\frac{\partial}{\partial\theta}\ln P(X,Z\vert\theta)\] <p>在这里我们进行近似，用 \(\theta^{(t)}\) 代替上式中的 \(\theta\) ，就可以得到</p> \[\Delta\theta = \eta\sum_{Z}P(Z\vert X,\theta^{(t)})\frac{\partial}{\partial\theta}\ln P(X,Z\vert\theta)\] <p>也就是E-step中的优化目标</p> \[\Delta\theta = \eta\frac{\partial}{\partial\theta} E_{Z\sim P(Z\vert X,\theta^{(t)})}[\ln P(X,Z\vert \theta)]\] <p>在解释了 E-step 中优化目标的来源后，下一个问题是为什么 EM 算法是正确的。对此，我们同样有两种证明方式</p> <ul> <li>第一种证明用到了 Jensen 不等式，即对于凸函数 \(f(\cdot)\) 而言，我们有 \(E[f(x)] \ge f(E[x])\) ，而</li> </ul> \[\ln P(X\vert \theta) = \ln \sum_{Z}P(X,Z\vert \theta) = \ln \sum_{Z}P(Z\vert X,\theta^{(t-1)})\frac{P(X,Z\vert \theta)}{P(Z\vert X,\theta^{(t-1)})}\] <p>其中 \(\sum_{Z}P(Z\vert X,\theta^{(t-1)}) = 1\) ，再结合 Jensen 不等式，我们就可以得到</p> \[\ln P(X\vert \theta) \ge \sum_{Z}P(Z\vert X,\theta^{(t-1)}) [\ln P(X,Z\vert \theta) - \ln P(Z\vert X,\theta^{(t-1)})]\] <p>即</p> \[\ln P(X\vert \theta) \ge Q(\theta\vert\theta^{(t)}) + constant\] <p>这意味着我们在优化 \(Q(\theta\vert\theta^{(t)})\) 的过程中，实际上是在不断提升原目标的下界，所以相当于也在提升原目标。</p> <ul> <li>第二种证明利用了条件概率，即</li> </ul> \[\forall Z, \qquad \log P(X\vert \theta) = \log P(X,Z\vert\theta) - \log P(Z\vert X,\theta)\] <p>我们改写原目标可以得到</p> \[\ln P(X\vert \theta) = [\sum_{Z'}P(Z'\vert X,\theta^{(t)})]\ln P(X\vert \theta)\] <p>既然条件概率中的 Z 可以是任意值，那么我们就令 Z 的值为 Z’，代入上式可以得到</p> \[\ln P(X\vert \theta) = [\sum_{Z'}P(Z'\vert X,\theta^{(t)})][\log P(X,Z'\vert\theta) - \log P(Z'\vert X,\theta)] = Q(\theta\vert\theta^{(t)})+H(\theta\vert\theta^{(t)})\] <p>这里的 \(H(\cdot)\) 类似与信息熵的定义，我们有 \(H(\theta\vert\theta^{(t)}) \ge H(\theta^{(t)}\vert\theta^{(t)})\) ，因此我们就可以得到</p> \[\ln P(X\vert\theta)-\ln P(X\vert\theta^{(t)}) \geq Q(\theta\vert\theta^{(t)}) - Q(\theta^{(t)}\vert\theta^{(t)})\] <p>同样说明我们是在不断提升原目标的下界。</p> <h2 id="em-for-gaussian-mixture">EM for Gaussian Mixture</h2> <p>高斯混合分布可以写成不同高斯分布的线性叠加，即</p> \[p(x) = \sum_{i=1}^K \pi_iN(x\vert \mu_i,\Sigma_i)\] <p>接下来我们引入隐变量 z，z 是 K 维的0-1向量，向量中只有一个元素为1，其余元素为0，即 \(\sum_{i=1}^Kz_i=1\) 。为了得到和上式相似的形式，我们用混合系数 \(\pi_i\) 来刻画隐变量 z 的分布，可以写出</p> \[p(z_i=1)=\pi_i, \quad 0\le \pi_i\le 1, \quad \sum_{i=1}^K\pi_i=1\] <p>现在我们就可以写出隐变量 z 的边缘分布 \(p(z)\)</p> \[p(z) = \prod_{i=1}^K \pi_i^{z_i}\] <p>当我们给出一个确定的 z 时，也就是说我们知道了 z 的具体某个元素 \(z_i\) 为一，此时 x 的条件分布同样服从高斯，\(x\vert z_i=1 \sim N(\mu_i,\Sigma_i)\)</p> <p>我们写出整体的条件分布</p> \[p(x\vert z) = \prod_{i=1}^KN(x\vert \mu_i,\Sigma_i)^{z_i}\] <p>在同时得到边缘分布和条件分布后，我们可以写出 x 和 z 的联合分布，进而求出 x 的分布</p> \[p(x) = \sum_zp(z)p(x\vert z) = \sum_z\prod_{i=1}^K (\pi_iN(x|\mu_i,\Sigma_i))^{z_i} = \sum_{i=1}^K \pi_iN(x\vert \mu_i,\Sigma_i)\] <p>在引入隐变量 z 后，我们得到了和原高斯分布等价的形式。我们引入隐变量的目的就是将目标从 x 的边缘分布 \(p(x)\) 转换到 x 和 z 的联合分布 \(p(x,z)\) 。</p> <p>在正式介绍 EM 在高斯混合模型的应用之前，我们还需要引入一个概念，隐变量 z 的后验分布 \(p(z\vert x)\) 。我们用 \(\gamma(z_k)\) 来表示 \(p(z_k=1\vert x)\) ，根据贝叶斯定理可以写出</p> \[\gamma(z_k) = \frac{p(z_k=1)p(x\vert z_k=1)}{\sum_{i=1}^Kp(z_i=1)p(x\vert z_i=1)} = \frac{\pi_kN(x\vert \mu_k,\Sigma_k)}{\sum_{i=1}^K\pi_iN(x\vert \mu_i,\Sigma_i)}\] <p>假设我们有数据集 \(\{x_1,...,x_n\}\) ，我们想用高斯混合模型进行建模，那么此时的模型包含三个参数 \(\pi, \mu, \Sigma\) 。考虑用极大似然来优化模型，我们有</p> \[\ln p(x\vert \pi, \mu, \Sigma) = \sum_{i=1}^n\ln\{\sum_{j=1}^K \pi_jN(x_i\vert \mu_j,\Sigma_j)\}\] <p>首先将其对 \(\mu_k\) 求导并令其为零，可以得到</p> \[\sum_{i=1}^n\gamma(z_{ik})\Sigma^{-1}_k(x_i-\mu_k) = 0 \rightarrow \mu_k = \frac{\sum_{i=1}^n\gamma(z_{ik})x_i}{\sum_{i=1}^n\gamma(z_{ik})}\] <p>其次将其对 \(\Sigma_k\) 求导并令其为零，可以得到</p> \[\Sigma_k = \frac{\sum_{i=1}^n\gamma(z_{ik})(x_i-\mu_k)(x_i-\mu_k)^T}{\sum_{i=1}^n\gamma(z_{ik})}\] <p>最后我们需要考虑 \(\sum_{i=1}^K\pi_i=1\) 的限制条件，利用拉格朗日乘子法将问题转化为</p> \[\ln p(x\vert \pi, \mu, \Sigma)+ \lambda(\sum_{i=1}^K\pi_i-1)\] <p>对 \(\pi_k\) 求导并令其为零，得到 \(\pi_k\) 的计算公式</p> \[\lambda + \sum_{i=1}^n\frac{N(x_i\vert \mu_k,\Sigma_k)}{\sum_{j=1}^K\pi_jN(x_i\vert \mu_j,\Sigma_j)}=0 \rightarrow \pi_k = \frac{\sum_{i=1}^n\gamma(z_{ik})}{n}\] <p>最后我们总结下 EM 算法在高斯混合模型的应用</p> <ul> <li>初始化，确定模型初始值 \(\pi_k, \mu_k, \Sigma_k\)</li> <li>E-step: 根据现有模型值，计算 \(\gamma\)</li> </ul> \[\gamma(z_{nk}) = \frac{\pi_kN(x_n\vert \mu_k,\Sigma_k)}{\sum_{i=1}^K\pi_iN(x_n\vert \mu_i,\Sigma_i)}\] <ul> <li>M-step: 根据计算的 \(\gamma\) 值重新估计更新模型参数</li> </ul> \[\mu_k = \frac{\sum_{i=1}^n\gamma(z_{ik})x_i}{\sum_{i=1}^n\gamma(z_{ik})}\] \[\Sigma_k = \frac{\sum_{i=1}^n\gamma(z_{ik})(x_i-\mu_k)(x_i-\mu_k)^T}{\sum_{i=1}^n\gamma(z_{ik})}\] \[\pi_k = \frac{\sum_{i=1}^n\gamma(z_{ik})}{n}\] <ul> <li>收敛之后，我们就可以去估计 log-likelihood</li> </ul> \[\ln p(x\vert \pi, \mu, \Sigma) = \sum_{i=1}^n\ln\{\sum_{j=1}^K \pi_jN(x_i\vert \mu_j,\Sigma_j)\}\] <p>可以发现，在上述介绍中，并没有明显体现出隐变量 z 的作用。在这里我们从隐变量的角度重新看待 EM 算法。在引入隐变量后，我们可以写出联合分布的极大似然</p> \[p(x,z\vert\pi, \mu,\Sigma) = \prod_{i=1}^n\prod_{j=1}^K\{\pi_jN(x_i\vert \mu_j,\Sigma_j)\}^{z_{ij}}\] <p>其对应的 log-likelihood 为</p> \[\ln p(x,z\vert\pi, \mu,\Sigma) = \sum_{i=1}^n\sum_{j=1}^K z_{ij}\{\ln \pi_j + \ln N(x_i\vert \mu_j,\Sigma_j)\}\] <p>和原问题中的极大似然 \(\ln p(x\vert \pi, \mu, \Sigma)\) 相比，最显著的特点是我们将求和操作从 log 里面拿到了外面，这可以大大简化问题的求解。因为我们引入了隐变量，最后还需要通过期望消除，所以最后的优化目标为</p> \[E_z[\ln p(x,z\vert\pi, \mu,\Sigma)] = \sum_{i=1}^n\sum_{j=1}^K \gamma(z_{ij})\{\ln \pi_j + \ln N(x_i\vert \mu_j,\Sigma_j)\}\] <p>该优化目标下参数 \(\pi, \mu, \Sigma\) 的更新方式和上文介绍的一模一样。</p> <h2 id="connection-between-k-means-and-em">Connection between K-means and EM</h2> <p>与 K-means 算法相比，EM 算法达到收敛需要迭代更多次数，并且每次迭代也需要更多的计算量。所以通常的做法是先用 K-means 来确定模型的初始化参数，再用 EM 算法改进提升。</p> <p>实际上，K-means 算法可以看成是一种特殊极限情况下的 EM 算法结合高斯混合模型。</p> <p>我们假设所有数据的协方差矩阵由共享的常数 \(\epsilon\) 控制，即 \(\Sigma = \epsilon I\) ，此时 x 在第 i 个高斯模型下的分布可以写出来</p> \[p(x\vert \mu_i,\Sigma_i) = \frac{1}{(2\pi\epsilon)^{1/2}}exp\{-\frac{1}{2\epsilon}||x-\mu_i||^2\}\] <p>进一步写出后验概率 \(\gamma(z_{nk})\)</p> \[\gamma(z_{nk}) = \frac{\pi_kexp\{-||x_n-\mu_k||^2/2\epsilon\}}{\sum_{i=1}^K\pi_iexp\{-||x_n-\mu_i||^2/2\epsilon\}}\] <p>当 \(\epsilon\) 逐渐减小直至趋近于零时，\(\vert\vert x_n-\mu_i\vert\vert^2\) 最小的那一项最晚降为零，因此只有这一项为一，其余都很快地变为零。即此时 \(\gamma(z_{nk}) \rightarrow \delta_{nk}\) ，每个数据点都被唯一地划分到均值最小的对应聚类中。此时 M-step 中均值的更新退化为</p> \[\mu_k = \frac{\sum_{i=1}^n\gamma(z_{ik})x_i}{\sum_{i=1}^n\gamma(z_{ik})} \rightarrow \mu_k = \frac{\sum_{i}\delta_{ik}x_i}{\sum_i\delta_{ik}}\] <p>再写出 \(\epsilon \rightarrow 0\) 下的log-likelihood 的期望</p> \[E_z[\ln p(x,z\vert\pi, \mu,\Sigma)] = -\frac{1}{2}\sum_{i=1}^n\sum_{j=1}^K \delta_{ij}||x_i-\mu_j||^2 + constant\] <p>此时最大化上式中的log-likelihood等价于最小化k-means算法中的loss</p>]]></content><author><name></name></author><category term="MachineLearning"/><summary type="html"><![CDATA[Book Notes on Pattern Recognition and Machine Learning (PRML)]]></summary></entry><entry><title type="html">Support Vector Machine</title><link href="https://jjjaaafff.github.io/blog/2021/ml5/" rel="alternate" type="text/html" title="Support Vector Machine"/><published>2021-07-31T00:00:00+00:00</published><updated>2021-07-31T00:00:00+00:00</updated><id>https://jjjaaafff.github.io/blog/2021/ml5</id><content type="html" xml:base="https://jjjaaafff.github.io/blog/2021/ml5/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>在之前的线性模型中，有时我们可以找到很多个模型都可以正确地进行分类。那么此时我们就需要选一个“最好”的模型。也就是说，我们不仅希望模型能正确分类，还希望它能尽可能地把不同类数据分得更开。</p> <p>假设是 \(\{+1,-1\}\) 的二分类问题。为了衡量模型这种分类的信心，我们定义</p> \[r_i = y_i(w^Tx_i+b)\] <p>此时，\(r_i\) 的值越大，表示模型对数据 \(x_i\) 的分类信心越大。然而，我们发现如果同时扩大 w 和 b 相同的倍数，会导致 \(r_i\) 同样变大，但分类结果不会有改变。所以我们还需要归一化，修改后的定义为</p> \[r_i = \frac{y_i(w^Tx_i+b)}{||w||_2}\] <p>这里的 \(r_i\) 可以理解为数据点 i 到分类平面的距离。我们关注的是分类信心最小的那些点，即需要提升 \(r\) 的下界。（在教材中，这些最小的分类信心被称为margin，优化问题为最大化margin），可以写出对应的数学形式</p> \[max_{w,b}(min_{i=1,...,n} (r_i))\] <p>改写一下，用 \(\tau=min(r_i)\) 来表示margin，此时的优化目标为</p> \[max_{\tau,w,b} \tau \qquad s.t.\ \forall i\ \ y_i(w^Tx_i+b)\geq\tau, \quad ||w||=1\] <p>为了简便表示，将约束条件中的归一化挪到优化目标里，我们得到</p> \[max_{\tau,w,b} \frac{\tau}{||w||} \qquad s.t.\ \forall i\ \ y_i(w^Tx_i+b)\geq\tau\] <p>我们可以发现，此时margin的具体值对最终得到的解没有影响，所以我们设为1，得到最终的 SVM 优化问题</p> \[min_{w,b} \frac{1}{2}||w||^2 \qquad s.t.\ \forall i\ \ y_i(w^Tx_i+b)\geq 1\] <p>我们之所以加上 1/2 的系数是为了后续求解的方便。现在我们已经得到了 SVM 对应的优化问题，下一步就是求解。</p> <p>因为原问题很难求解，我们使用拉格朗日乘子法将其转化为对偶问题求解。这里首先介绍拉格朗日乘子法。我们假设原优化问题为</p> \[min_w f(w) \quad s.t.\ g_k(w)\leq 0, k=1,...,K;\ h_{l}(w)=0,l=1,...,L\] <p>对应的对偶问题为</p> \[L(w,\alpha,\beta) =f(w)+\sum_{i=1}^K\alpha_ig_i(w)+\sum_{i=1}^L\beta_ih_i(w)\] <p>此时的约束条件也被称为 KKT condition，即</p> \[\forall k\ \alpha_kg_k(w) = 0, \quad \forall k \ g_k(w)\leq 0, \quad \forall k\ \alpha_k\geq 0\] <p>回到 SVM 的求解中，我们现在的优化问题为</p> \[min_{w,b} \frac{1}{2}||w||^2 \qquad s.t.\ \forall i\ \ 1-y_i(w^Tx_i+b)\leq 0\] <p>我们写出对偶问题</p> \[min_{w,b} max_{\alpha:\alpha\geq 0} L(w,b,\alpha)\] \[where\quad L(w,b,\alpha)=\frac{1}{2}||w||^2 + \sum_{i=1}^n \alpha_i[1-y_i(w^Tx_i+b)]\] <p>我们分别对 w 和 b 求偏导，以消除 L 中的这两个变量只剩下 \(\alpha\)，可以得到</p> \[\frac{\partial L}{\partial w} = 0 \Rightarrow w = \sum_{i=1}^n\alpha_iy_ix_i\] \[\frac{\partial L}{\partial b} = 0 \Rightarrow \sum_{i=1}^n\alpha_iy_i = 0\] <p>将这两个式子代入到 \(L(w,b,\alpha)\) 中消除变量后，我们可以得到只关于 \(\alpha\) 的优化目标，即</p> \[max_{\alpha} L(\alpha) = \sum_{i=1}^n\alpha_i - \frac{1}{2}\sum_{i=1}^n\sum_{j=1}^ny_iy_j\alpha_i\alpha_jx_i^Tx_j\] \[s.t. \quad \forall i \ \alpha_i\geq 0, \sum_{i=1}^n\alpha_iy_i = 0\] <p>这个优化问题就可以更容易地求解，最常用的一种求解方式称为 sequential minimal optimization（SMO）。在求解得到 \(\alpha\) 后，我们代回到 w 和 b 的式子中，可以得到</p> \[w = \sum_{i:\alpha_i &gt; 0}\alpha_iy_ix_i\] \[b = \frac{1}{|S|}\sum_{s\in S}(y_s-\sum_{i\in S}\alpha_iy_ix_i^Tx_s),\quad where\ S = \{j\vert \alpha_j &gt;0\}\] <p>自此我们就求解得到了模型（w 和 b），接下来我们对这个结果进行一下分析。<br/> 正如之前提到的，我们在使用拉格朗日乘子转换为对偶问题时，需要满足 KKT 条件，即</p> \[\forall i,\quad \alpha_i \geq 0,\quad y_i(w^Tx_i+b)-1\geq 0,\quad a_i(1-y_i(w^Tx_i+b))=0\] <p>这意味着，对于每一个数据 \(x_i\) ，要么对应的 \(\alpha_i=0\) ，要么 \(y_i(w^Tx_i+b)=1\) 。前者表明该数据很容易被分类，对最后的模型没有影响。后者表明该数据处于离分类平面最近的位置，是最难分类的。所有满足后者的数据构成了 Support Vector 支撑向量。我们也只用到了支持向量有关的数据作为模型的一部分。</p> <p>所以当模型训练结束后，大部分训练数据都可以丢弃，只保留构成支持向量的数据。这些数据对应最难分类的一系列样本，正是这样一些数据把单个分类平面支撑起来，所以被称为支持向量机</p> <h2 id="svm-with-outlier">SVM with outlier</h2> <p>在之前的介绍中，我们假设训练数据是完全可分类的，而这是一种很强的假设。在这一节，我们通过引入误差项，允许一些样本的分类信心没有那么强，允许一些样本被分错类。我们记误差项为 \(\xi\) ，正则化系数为常数 \(C\) ，此时的优化问题可写为</p> \[min_{\xi,w,b}\frac{1}{2}||w||^2 + C\sum_{i=1}^n\xi_i\quad s.t. \forall i, \ \ y_i(w^Tx_i+b)\geq 1-\xi_i,\ \xi_i\geq 0\] <p>等价于</p> \[min_{\xi,w,b}\frac{1}{2}||w||^2 + C\sum_{i=1}^n max(0,1-y_i(w^Tx_i+b))\] <p>和上面一样的变化方法，这里直接写出对偶问题中的优化函数</p> \[L(w,b,\xi,\alpha,\beta) = \frac{1}{2}||w||^2 + C\sum_{i=1}^n\xi_i + \sum_{i=1}^n\alpha_i[1-\xi_i-y_i(w^Tx_i+b)] - \sum_{i=1}^n \beta_i\xi_i\] <p>和上面的流程一样，接着我们对 w b 和 \(\xi\) 求偏导消除变量，w 和 b 的偏导结果和标准SVM一样，对 \(\xi\) 求偏导则可得到</p> \[\frac{\partial L}{\partial \xi_i} = 0 \Rightarrow \alpha_i + \beta_i = C\] <p>代入原函数后，我们得到变换后的优化问题</p> \[max_{\alpha} L(\alpha) = \sum_{i=1}^n\alpha_i - \frac{1}{2}\sum_{i=1}^n\sum_{j=1}^ny_iy_j\alpha_i\alpha_jx_i^Tx_j\] \[s.t. \quad \forall i \ 0\leq \alpha_i \leq C, \sum_{i=1}^n\alpha_iy_i = 0\] <p>最后我们对结果进行分析。这里因为引入了误差项 \(\xi\) 不等式，KKT条件变为</p> \[\forall i,\quad \alpha_i \geq 0,\quad y_i(w^Tx_i+b)-1+\xi_i\geq 0,\quad a_i(y_i(w^Tx_i+b)-1+\xi_i)=0\] \[\forall i,\quad \beta_i \geq 0,\quad \xi_i\geq 0,\quad \beta_i\xi_i=0\] <ul> <li>如果 \(\alpha_i =0\)，那么此时 \(\beta_i = C-\alpha_i &gt;0, \xi_i=0\) 这个数据 i 很容易被分类，落在margin外面，其误差项为零，对最终训练好的模型没有影响</li> <li>如果 \(0&lt;\alpha_i &lt;C\)，同样有\(\beta_i = C-\alpha_i &gt;0, \xi_i=0\)，此时该数据落在margin上，参与构成了support vector</li> <li>如果 \(\alpha_i =C\)，那么此时 \(\beta_i = C-\alpha_i =0, \xi_i&gt;0\) 此时误差项不为零了，说明该数据落在 margin 内部。 <ul> <li>如果 \(\xi_i&lt;1\) ，说明该数据仍可以被正确分类，但分类的信心很弱，落在分类平面和margin之间。</li> <li>如果 \(\xi_1&gt;1\) ，说明该数据被彻底地错误分类了，落在分类平面的另一边。我们可以发现，尽管如此，其正则项保证该数据对模型的影响随着数据的偏离成正比</li> </ul> </li> </ul> <p>可以看出，这样增加误差项的处理方式防止了过拟合，提升了对训练数据的泛化能力</p> <h2 id="kernel-svm">Kernel SVM</h2> <p>对于非线性的分类问题，有时需要用核函数 \(\phi(X)\) 代替 X 。此时的SVM可表示为 \(Y = w^T\phi(X)+b\)</p> <p>求解可以得到 \(w=\sum_{i=1}^n\alpha_iy_i^*\phi(x_i)\) ，代入原模型可得</p> \[y_j = (\sum_{i=1}^n\alpha_iy_i^*\phi(x_i))^T\phi(x_j)+b = \sum_{i:\alpha&gt;0} \alpha_iy_i^*k(x_i,x_j) + b\] <p>我们可以发现，SVM并不能提供概率输出，即每个数据属于某个类的概率。为了解决这个问题，其中一种方式再拟合，即</p> \[p(y^*=1\vert x) = \sigma(Ay(x)+B)\] <p>这里 \(\sigma(\cdot)\) 是logistic sigmoid函数，\(y(x)\) 为SVM的输出值，A和B为通过交叉熵loss学习的参数。我们需要另一套数据集来训练这个 logistic 模型，必须与之前训练 SVM 的数据集相互独立，否则会有严重的过拟合现象。即使这样，效果仍然很差</p> <p>最后我们来看下 SVM 和 Logistic regression 的联系。<br/> 首先是 SVM，在软间隔的SVM中，优化目标为</p> \[min_{\xi,w,b}\frac{1}{2}||w||^2 + C\sum_{i=1}^n max(0,1-y_i(w^Tx_i+b))\] <p>把它写成Loss的形式可以得到</p> \[L = \sum_{i=1}^n max(0,1-y_i^*y_i) + \lambda ||w||^2,\quad where\ \ \lambda = \frac{1}{2C}\] <p>我们再来看 logistics regression，之前我们针对的是 \(\{0,1\}\) 标签。为了保持和 SVM 标签一致，我们假设为 \(\{+1,-1\}\) 标签，则有</p> \[p(y^*_i=1\vert x) = \frac{1}{1+e^{-x_i^T\beta}}, \quad p(y^*_i=-1\vert x)= 1- p(1) = \frac{1}{1+e^{x_i^T\beta}}\] <p>因此可以得到通式</p> \[p(y_i^*\vert y_i) = \frac{1}{1+e^{-y_i^*y_i}}\] \[L = \sum_{i=1}^n \ln(1+e^{-y_i^*y_i}) + \lambda ||w||^2\] <p>可以看出两者 Loss 函数的相似与不同。</p> <h2 id="relevance-vector-machine-rvm">Relevance Vector Machine （RVM）</h2> <p>之前的SVM存在一些缺陷，比如它直接输出分类决策而不是后验概率，主要用来处理二分类问题等。因此又提出了RVM，在保留SVM特点的同时避免了SVM的局限性。</p> <p>RVM类似与之前的贝叶斯线性回归，给定输入数据 x 后，ground-truth 的分布为 \(y^*\vert x,w \sim N(y(x),\sigma^2)\) ，这里的 \(y(x)\) 写成基函数的形式，即</p> \[y(x) = \sum_{i=1}^{n+1} w_i\phi_i(x) = w^T\phi(x)\] <p>我们用矩阵表示，写出似然函数</p> \[p(Y^*\vert X,w) = \prod_{i=1}^np(y^*_i\vert x_i,w) \Rightarrow Y^*\vert X,w \sim N(\phi w,\sigma^2 I)\] <p>这里 \(\phi\) 是一个 n*(n+1) 的矩阵，\(\phi_{ij} = \phi_j({x_i})\) 。和之前不同的一点是，RVM关键区别是为每个权参数 \(w_i\) 都引入一个单独的超参数 \(\alpha_i\) ，而不是像之前一样共享一个超参数 \(\Sigma\) ，所以此时的模型先验分布为</p> \[p(w\vert \alpha) = \prod_{i=1}^{n+1}N(0,\alpha_i) \Rightarrow w\vert \alpha \sim N(0,\alpha)\] <p>至此结合以上表达式，我们可以写出模型的后验概率 \(p(w\vert X,Y)\) ，即</p> \[w\vert X,Y \sim N(\mu,\Sigma)\] \[where \quad \mu = \sigma^{-2}\Sigma \phi^TY, \quad \Sigma = ((\alpha I)^{-1}+\sigma^{-2}\phi^{T}\phi)^{-1}\] <p>如果我们再知道超参 \(\alpha\) 和 \(\sigma\) 的值，就可以对新数据进行预测了。所以接下来的一步是求这两个超参。我们通过对权向量积分最大化边缘似然函数，即</p> \[p(Y^*\vert X) = \int p(Y^*\vert X,w)p(w\vert\alpha)dw = \int N(Y^*\vert \phi w,\sigma^2I)N(w\vert 0,\alpha)dw\] <p>令上式导数为零，可以得到估计方程</p> \[\alpha_i^{new} = \frac{1-\alpha_i \Sigma_{ii}}{\mu_i^2},\qquad (\sigma^2)^{new} = \frac{||Y^*-\phi\mu||^2}{n-\sum_i(1-\alpha_i \Sigma_{ii})}\] <p>所以超参 \(\alpha\) 和 \(\sigma\) 的整个学习流程为</p> <ol> <li>选择 \(\alpha\) 和 \(\sigma\) 的初始值，利用上面的后验概率公式均值和方差求解公式计算后验概率均值 \(\mu\) 和方差 \(\Sigma\)</li> <li>利用前文中 \(\alpha_i^{new}\) 和 \((\sigma^2)^{new}\) 的计算公式交替重新估计超参数。</li> <li>重新估计后验均值和方差，以此类推，直到满足合适的收敛准则。</li> </ol> <p>我们观察收敛后的超参，可以发现一部分 \(\alpha_i\) 趋于无穷大。那么对应的模型权值 \(w_i\) 的均值和方差都趋近零，也就意味着这些权值及对应的基函数对模型没有贡献。这就和之前的SVM相似了，剩下的非零权值输入 \(x_n\) 称为相关向量，类似与SVM中的支持向量。</p> <p>我们用 \(\alpha^\star\) 和 \(\sigma^\star\) 来表示最后学到的超参。在预测阶段，我们假设输入数据为 \(x_0\)，那么此时可以写出预测输出的概率分布</p> \[p(y_{pred}\vert x_0) = \int p(y_{pred}\vert x_0,w)p(w\vert X,Y)dw = \int N(y_{pred}\vert \phi(x_0)^Tw,(\sigma^*)^2)N(w\vert\mu,\Sigma)dw\] \[y_{pred}\vert x_0 \sim N(\mu^T\phi(x_0),(\sigma^*)^2+\phi(x_0)^T\Sigma\phi(x_0))\] <p>我们就可以根据上式得到我们最后的预测输出 \(y_{pred}\)</p> <p>以上是 RVM 在回归任务中的应用，接下来我们简要介绍一下 RVM 在分类任务的应用。</p> <p>在分类任务中，我们还是保持模型 \(w\) 的高斯先验分布，同样为每个权参数 \(w_i\) 都引入一个单独的超参数控制精度。只是此时的输出变为 \(y(x) = sigmoid(w^T\phi(x))\) (在多分类问题中则变为 softmax)</p> <p>和回归问题不同的是，这里不再对模型 \(w\) 解析求积分来求得最大化边缘似然函数，而是使用了拉普拉斯近似的方法求解。</p> <p>最后总结下 RVM 的优劣</p> <ul> <li>RVM的相关向量的数量比SVM中使用的支持向量的数量少很多，对分类任务和回归任务，RVM生成的模型通常比对应的支持向量机生成的模型简洁一个数量级，使得处理测试数据的速度又极大提升。</li> <li>RVM的主要缺点是，相比较SVM，训练时间相对较长。但是RVM避免了通过交叉验证确定模型复杂度的过程，从而补偿了训练时间的劣势。此外它产生的模型更加稀疏，所以它对于测试点进行预测的计算时间通常更短，对于预测点的计算时间通常在实际应用中更加重要。</li> </ul>]]></content><author><name></name></author><category term="MachineLearning"/><summary type="html"><![CDATA[Book Notes on Pattern Recognition and Machine Learning (PRML)]]></summary></entry><entry><title type="html">Kernel Methods</title><link href="https://jjjaaafff.github.io/blog/2021/ml4/" rel="alternate" type="text/html" title="Kernel Methods"/><published>2021-07-28T00:00:00+00:00</published><updated>2021-07-28T00:00:00+00:00</updated><id>https://jjjaaafff.github.io/blog/2021/ml4</id><content type="html" xml:base="https://jjjaaafff.github.io/blog/2021/ml4/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>在之前的模型中，我们利用训练集的数据来训练我们的模型 \(\beta\) ，训练结束后就可以丢弃掉训练数据，只保留模型用于预测。而还有一种方式是保留全部或部分训练集数据，并在预测阶段使用到这些数据。这样一种方式称为 memory-based method，而 kernel method 就是这样一种方式。</p> <p>我们从线性模型中引入 kernel 的概念。和之前的假设一致，我们假设输入为 n 个数据，每个数据为 p 维；输出为 n 个一维数据。在之前介绍的线性模型中，对于训练集 \(X\) 中的第 i 个数据 \(X_i = [x_{i0},x_{i1},...,x_{ip}]^T\) ，我们直接将其输入到线性模型中训练模型 \(\beta\) ，此时该数据对应的 loss 可写为</p> \[L_{i}(\beta) = \left[ \sum_{j=0}^p (x_{ij}\beta_{j}) \right] - y_i^*\] <p>但有时我们会对输入数据进行预处理，会引入非线性的因素。比如我们想对变换后的数据 \(X_i^{'} = [x_{i0},x_{i1}^2,...,\sqrt{x_{ip}}]^T\) 进行回归分类。此时我们仍然可以使用线性模型，只需要将变换后的数据 \(X^{'}\) 看成新的输入即可。我们用函数 \(\phi(x)\) 来表征这样一种变换，即 \(\phi(X_i) = [\phi_0(x_{i0}),\phi_1(x_{i1}),...,\phi_p(x_{ip})]^T\) 。我们写出ridge正则下基于所有训练数据的loss</p> \[L(\beta) = ||Y-\phi(X)\beta||^2 + \lambda||\beta||^2 =\sum_{i=1}^n(\phi(X_i)^T\beta-y_i^*)^2 + \lambda\beta^T\beta\] <p>令损失函数导数为零可得</p> \[\beta = -\frac{1}{\lambda}\sum_{i=1}^n(\phi(X_i)^T\beta-y_i^*)\phi(X_i) = \sum_{i=1}^n c_i\phi(X_i) = \phi(X)^Tc\] <p>和之前 X 的定义相同，这里的 \(\phi(X) =[\phi(X_1)^T,...,\phi(X_n)^T]^T\) 为 n*(p+1) 的矩阵。而这里 \(c = [c_1,...,c_n]^T\) ，我们用 \(c_i\) 来表示 \(\phi(X_i)\) 前面的系数，即</p> \[c_i = -\frac{1}{\lambda}(\phi(X_i)^T\beta-y_i^*)\] <p>我们将 \(\beta = \phi(X)^Tc\) 代入到损失函数中，此时自变量将由 \(\beta\) 转换为 \(c\) ，我们有</p> \[L(c) = c^T\phi\phi^T\phi\phi^Tc-2c^T\phi\phi^TY+Y^TY+\lambda c^T\phi\phi^Tc\] <p>我们用 \(K=\phi\phi^T\) 来代替，那么我们就引出了kernel的概念。显然，这里K是一个 n*n 的对称矩阵，其中的某个元素 \(K_{ij} = \phi(X_i)^T\phi(X_j)\) 。对于kernel，我们用kernel function来刻画，用来描述两个变量的关系，即 \(k(x_i,x_j) =\phi(x_i)^T\phi(x_j)\) 。所以此时的 K 矩阵也称为 kernel matrix。</p> <p>此时的损失函数为</p> \[L(c) = ||Y-Kc|| + \lambda c^TKc\] <p>此时预测值 \(y_{pred}(x) =\sum_{i=1}^nc_ik(x,X_i)\)<br/> 新的模型 c 的解析解为 \(c = (K+\lambda I_n)^{-1}Y\)</p> <p>我们可以看到，此时我们需要求一个 N*N 矩阵的逆，这在大数据集中几乎是不可能的。但我们可以发现，在解析式和预测方程中，可以直接引入kernel function，而不需要明确 \(\phi(X)\) 。这个性质可以让我们隐式地使用高维甚至无穷维的特征空间。</p> <h2 id="kernel-construction">Kernel Construction</h2> <p>为了利用 kernel method 的好处，我们需要构造出合法的kernel function。最简单的方式是我们先构造映射函数 \(\phi(x)\) ，然后利用 \(k(x_1,x_2) = \phi(x_1)^T\phi(x_2)\) 。而另外一种方法是我们直接构造 kernel function，但在此时我们怎样确定这是合法的kernel function 呢？</p> <p>如果我们可以把 kernel function 拆分成两个映射函数的乘积，那么毫无疑问这种 kernel function 是合法的。但这种拆分并不容易，而且没有普适的拆分方法。不过还是有判断有效kernel的充要条件，那就是看kernel matrix是否是半正定的。这里的kernel matrix和上一节一致，即 \(K_{ij} =k(x_i,x_j)\) 。如果 K 是半正定的，那么对应的kernel是合法的。</p> <p>接下来介绍几种常用的kernel</p> <p>首先是最基础的 polynomial kernel，\(k(x,x^{'}) = (x^Tx^{'}+c)^M\) ，这里 c 是常数而 M 为阶数。如果该kernel计算式中不包含 c 这一项，则对应的映射函数 \(\phi(x)\) 只包含所有 M 阶的项。在加上 c 这一项后，包含所有阶数小于等于 M 的项。</p> <p>其次是最常用的 Gaussian kernel，\(k(x,x^{'}) = exp(\frac{-\vert\vert x-x^{'}\vert \vert ^2}{2\sigma^2})\) 。广泛使用的一个原因是这个kernel对应的特征向量有无穷的维度。我们可以用高斯展开来解释这个原因。</p> \[k(x_1,x_2) = exp(-x_1^Tx_1/2\sigma^2)\{1+\frac{x_1^Tx_2}{\sigma^2}+\frac{(\frac{x_1^Tx_2}{\sigma^2})^2}{2!} +...\}exp(-x_2^Tx_2/2\sigma^2)\] <p>而且，高斯核并不仅仅局限于欧氏距离，我们甚至可以用另一个非线性核代替高斯核内的 \(x_1^Tx_2\)，即</p> \[k(x_1,x_2) = exp\{-\frac{1}{2\sigma^2}(k'(x_1,x_1)+k'(x_2,x_2)-2k'(x_1,x_2)) \}\] <p>同时，kernel method 也可以作用与离散变量。我们假设有两个集合 \(A_1\) 和 \(A_2\) ，此时我们可以定义kernel</p> \[k(A_1,A_2)=2^{|A_1\cap A_2|}\] <p>最后，我们可以用生成模型来生成kernel，比如 Fisher kernel，或者是</p> \[k(x_1,x_2)=\sum_i p(x_1\vert i)p(x_2\vert i)p(i)\] <h2 id="radial-basis-function-networks">Radial Basis Function Networks</h2> <p>radial basis function (rbf) 是指只依赖于径向距离(通常是欧氏距离)的basis function，例如 \(\phi_i(x)=h(||x-\mu_i||)\)</p> <p>在历史上，rbf的引入是为了完全拟合训练集所有数据。我们通过 rbf 的线性组合来得到对应的函数 \(f(x)\) 即</p> \[f(x) = \sum_{i=1}^nw_ih(||x-x_i||)\] <p>这里的系数 \(w_i\) 通过最小二乘确定。但显然这种方式在模式识别中是不合适的，一方面是计算量要求大，每个训练集数据都有一个待优化系数对应；另一方面是过拟合现象严重。</p> <p>为此我们的解决方法是只选取有限个rbf进行线性组合，这就涉及到 rbf 中心点的选取（训练数据子集的选取）。我们可以用 k-means 聚类来选数据点，或者在每次迭代中选择使loss下降最大的那个数据</p> <p>接下来我们从 Nadaraya-Watson model 的角度分析kernel回归模型。<br/> 对于训练集 \(\{X,Y\}\) ，我们用密度函数来建模联合分布 \(P(X,Y)\)，即</p> \[p(x,y) = \frac{1}{n}\sum_{i=1}^nf(x-x_i,y-y_i)\] <p>基于这个联合分布，我们可以表示出回归函数 \(y(x)\) ，即</p> \[y(x) = E[y\vert x] = \int_{-\infty}^{\infty}yP(y\vert x)dy = \frac{\int y P(x,y)dy}{\int P(x,y)dy} = \frac{\sum_n g(x-x_n)y_n}{\sum_m g(x-x_m)}\] <p>这里我们用到了一个假设，假设密度函数的均值为零，即 \(\int_{-\infty}^{\infty}f(x,y)dy=0\) 基于这个假设，我们定义 \(g(x) = \int_{-\infty}^{\infty}f(x,y)dy\) 得到上式。此时我们定义 kernel function 为</p> \[k(x,x_i) = \frac{g(x-x_i)}{\sum_{j=1}^ng(x-x_j)}\] <p>就可以得到 Nadaraya-Watson model（kernel regression）的形式</p> \[y(x) = \sum_{i=1}^n k(x,x_i)y_i^*\] <h2 id="gaussian-processes">Gaussian Processes</h2> <p>从高斯过程的角度来看，我们不需要求解具体的模型，而是直接定义函数的先验分布。（ we can obtain the predictive distribution either by taking a parameter space viewpoint and using the linear regression result or by taking a function space viewpoint and using the Gaussian process result.）我们以回归任务为例，\(y_i^* = y_{pred}(x_i) + \epsilon_i\) ，我们假设噪声 \(\epsilon\) 服从高斯分布，则有</p> \[p(y^*_i\vert y_i) = N(y^*_i\vert y_i,\alpha^{-1})\] <p>这里 \(\alpha\) 是控制噪声的超参，我们写成矩阵的形式为 \(P(Y^\star\vert Y) = N(Y^\star\vert Y,\alpha^{-1}I_n)\) 。而根据高斯过程的定义，我们同样可以写出边缘分布 \(P(Y) = N(Y\vert 0,K)\) （这源于我们对模型的先验分布为高斯分布的假设）。这里的 K 就是kernel matrix，我们需要选择合适的 kernel function 使得相似的两个数据 \(X_i\) 和 \(X_j\) 对应的预测值接近。在高斯回归中最常使用的 kernel function 是</p> \[k(x_i,x_j) = \theta_0exp\{-\frac{\theta_1}{2}||x_i-x_j||^2\} + \theta_2 + \theta_3 x_i^Tx_j\] <p>接下来我们就可以求 ground-truth 的边缘分布 \(P(Y^\star)\) 。这用到了一条结论</p> \[If \qquad p(x) = N(x\vert \mu, M^{-1}),\quad p(y\vert x) = N(y\vert Ax+b,N^{-1})\] \[Then \qquad p(y) = N(y\vert A\mu +b,N^{-1}+AM^{-1}A^T)\] <p>基于这个结论，我们也可以写出 ground-truth 的边缘分布，\(P(Y^{\star})=N(Y^{\star}\vert 0,C)\) ，这里的 C 代表协方差矩阵，\(C(x_i,x_j) = k(x_i,x_j)+\alpha^{-1}I_{ij}\)</p> <p>以上都是针对训练集中的数据进行的变换。我们更关心的是在未知新数据上的表现，也就是说，对于一个新数据 \(x_{new}\) ，我们想知道它对应的 ground-truth 的分布情况。我们利用训练集中的数据进行预测，即确定 \(p(y^{\star}_{new}\vert Y^\star)\)</p> <p>我们在这里还需要引入一个结论</p> \[If \qquad p(x_1) \sim N(\mu_1, \Sigma_{11}),\quad p(x_2) \sim N(\mu_2,\Sigma_{22})\] \[Then \qquad p(x_2\vert x_1) \sim N(\mu_2+\Sigma_{21}\Sigma_{11}^{-1}(x_1-\mu_1), \Sigma_{22}-\Sigma_{21}\Sigma_{11}^{-1}\Sigma_{12})\] <p>结合上面的变换，我们已经知道了</p> \[P(Y^*) \sim N(0,C) \qquad P(y^*_{new})\sim N(0,k(x_{new},x_{new})+\alpha^{-1})\] <p>那么代入结论中的通式就可以得到</p> \[p(y^*_{new}\vert Y^*) \sim N(\mathbf{k}^TC^{-1}Y^*,c-\mathbf{k}^TC^{-1}\mathbf{k})\] <p>这里 \(\mathbf{k} = (k(x_1,x_{new}),...,k(x_n,x_{new}))^T\) ，而 \(c = k(x_{new},x_{new})+\alpha^{-1}\)</p> <p>自此就得到了针对未知新数据的预测分布，下一步就是超参的学习。我们用 \(\theta\) 表示高斯过程模型中的超参，我们可以写出极大似然对应的 log-likelihood 形式</p> \[\ln P(Y\vert \theta) = -\frac{1}{2}\ln |C_N| - \frac{1}{2} Y^TC_N^{-1}Y -\frac{N}{2} \ln (2\pi)\] <p>这里同样考虑利用梯度来优化我们的目标，我们可以写出上式对应的梯度为</p> \[\frac{\partial}{\partial \theta_i}\ln P(Y\vert \theta) = -\frac{1}{2}Tr(C_N^{-1}\frac{\partial C_N}{\partial \theta_i}) + \frac{1}{2}Y^TC_N^{-1}\frac{\partial C_N}{\partial \theta_i}C_N^{-1}Y\] <p>以上都基于我们对误差的方差为常数的假设，如果误差也取决于输入变量，我们需要引入二次高斯过程来建模方差对输入的依赖。</p>]]></content><author><name></name></author><category term="MachineLearning"/><summary type="html"><![CDATA[Book Notes on Pattern Recognition and Machine Learning (PRML)]]></summary></entry><entry><title type="html">Linear Methods for Classification</title><link href="https://jjjaaafff.github.io/blog/2021/ml3/" rel="alternate" type="text/html" title="Linear Methods for Classification"/><published>2021-07-25T00:00:00+00:00</published><updated>2021-07-25T00:00:00+00:00</updated><id>https://jjjaaafff.github.io/blog/2021/ml3</id><content type="html" xml:base="https://jjjaaafff.github.io/blog/2021/ml3/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>在分类任务中，输入一个 vector x，我们需要将其划分到 K 个离散类中的某一类。而线性分类模型是指我们划分决策区域的边界是关于输入 vector 的线性方程。</p> <p>在分类任务中，我们更希望能预测出离散的label，或者是更广泛的后验概率。因此，我们需要在之前的线性模型外嵌套一层非线性方程 \(f(\cdot)\)，保证输出值为落在 0 到 1 之间的概率，即此时</p> \[y_{pred}(X) = f(X\beta)\] <h2 id="discriminant-functions">Discriminant Functions</h2> <p>我们在这里考虑不添加非线性方程，直接利用线性模型的输出来进行分类。</p> <p>首先是最简单的二分类问题。在这个任务下，我们可以根据线性模型输出 y(x) 的正负来对应将输入 x 分为两类。此时的分类边界即为 \(y(x)=0\) 。在模型中，\(\beta\) 确定决策平面的方向，而截距 \(\beta_0\) 确定该平面的位置。此外，我们还可以求出输入vector到决策平面的距离为 \(r = y(x)/\vert\vert\beta\vert\vert\)</p> <p>然而，在多分类(K)问题中，我们就不能采用和二分类一样的分类标准了。</p> <ul> <li>如果我们用 K-1 个分类器来分类，每个分类器判断是否属于类别 i。这种方式被称为 one-versus-the-rest ，可能会出现某数据同时属于若干个类。</li> <li>如果我们用 K(K-1) 个分类器来分类，即每两个类之间都用一个分类器来判断划分。这种方式被称为 one-versus-one ，计算开销很大。</li> <li>我们还可以用 K 个分类器分别对应十个类，我们取分类器输出值最大的对应的类作为最终预测标签。此时的决策区域一定是 singly connected and convex</li> </ul> <p>在确定分类方式之后，我们接下来介绍三种学习分类方程参数的方法</p> <h3 id="least-squares-for-classification">Least squares for classification</h3> <p>和之前回归任务类似，唯一不同的是 ground-truth 被二进制编码为 target vector，即每个输入数据对应的标签被转换为一个 0-1 数组（只有一项为1）。</p> <p>但在实际中，这种方法的效果很差。尽管根据线性特征，我们的预测输出 vector 内元素和也为1，但每个元素我们无法保证落在0-1之间。而且，最小二乘误差会让那些 “很正确” 的数据点对模型产生负面影响。此外，最小二乘在多分类任务下的表现更加糟糕</p> <h3 id="fishers-linear-discriminant-lda">Fisher’s linear discriminant (LDA)</h3> <p>该方法的思路是利用线性模型，将输入的高维vector降为一维。我们可以通过控制模型参数 \(\beta\) 来使得不同类别的数据降维后相差尽可能地大。</p> <p>我们首先考虑最简单的二分类的应用。假设我们有 \(N_1\) 个数据属于类别 \(C_1\) ；\(N_2\) 个数据属于类别 \(C_2\) 。最简单的衡量两个类别间差异的方式是比较他们的均值。我们分别求出两个类别数据的均值向量，记为</p> \[\mathbf{m_1} = \frac{1}{N_1}\sum_{n\in C_1}\mathbf{x_n}, \quad \mathbf{m_2} = \frac{1}{N_2}\sum_{n\in C_2}\mathbf{x_n}\] <p>这里我们想要降维后的两类数据相差尽可能大，所以我们的目标是最大化两均值向量降维后的差值，即</p> \[max (m_2-m_1) = \beta^T(\mathbf{m_2}-\mathbf{m_1})\] <p>此外我们还需要对模型参数归一化（\(\sum_i \beta_i = 1\)），否则模型参数越大，降维差异就越大。但仅仅这样还不够，还是会出现不同类之间部分数据有交叉。我们希望同类数据之间相互靠近，异类数据之间相互远离。上式定义了异类之间的差异，我们还需要衡量同类数据的靠近程度。在各个类内，求方差再相加到一起作为整个数据集的同类相似度，即</p> \[\sigma_{within}^2=\sum_{n\in C_1}(\beta^T\mathbf{x_n}-m_1)^2+\sum_{n\in C_2}(\beta^T\mathbf{x_n}-m_2)^2\] <p>我们最终的优化目标为</p> \[maxJ(\beta) = \frac{(m_2-m_1)^2}{\sigma_{within}^2} = \frac{\beta^TS_B\beta}{\beta^TS_W\beta}\] <p>其中，\(S_B\) 为类间协方差矩阵，\(S_W\) 为类内协方差矩阵，分别如下</p> \[S_B = (\mathbf{m_2}-\mathbf{m_1})(\mathbf{m_2}-\mathbf{m_1})^T\] \[S_W = \sum_{n\in C_1}(\mathbf{x_n}-\mathbf{m_1})(\mathbf{x_n}-\mathbf{m_1})^T+\sum_{n\in C_2}(\mathbf{x_n}-\mathbf{m_2})(\mathbf{x_n}-\mathbf{m_2})^T\] <p>为了求解这个优化问题，我们令分母为值为 1，用 Lagrange 方法，可得</p> \[\lambda S_W \beta = S_B\beta\] <p>我们并不关心模型的具体数值，我们只想知道对应的方向。在上面的概念中，我们已经知道 \(\beta^T(\mathbf{m_2}-\mathbf{m_1})\) 的结果是一个常数，所以上式等号右边对应的方向就是 \(\mathbf{m_2}-\mathbf{m_1}\) ，最后我们有</p> \[\beta \propto S_w^{-1}(\mathbf{m_2}-\mathbf{m_1})\] <p>可以证明，在二分类的任务下，LDA是最小二乘的一种特殊形式。我们可以设第一类的标签值为 \(N/N_1\) ，第二类的标签值为 \(-N/N_2\) ，此时最小二乘的解等价于 LDA 的解。这种设置下最小二乘对应的二分类标准为 \((\mathbf{x}-\mathbf{m})\beta &gt;0\) 时划为第一类，否则划为第二类</p> <p>对于 K 分类的任务，我们则不能再降至一维，而是将其降为 H 维。和二维的情况类似，我们定义降维后的数据类间方差和类内方差，即</p> \[\sigma_{within} = \sum_{k=1}^K\sum_{n\in C_k} (\mathbf{y_n}-\mathbf{\mu_k})(\mathbf{y_n}-\mathbf{\mu_k})^T\] \[\sigma_{between} = \sum_{k=1}^KN_k (\mathbf{\mu_k}-\mathbf{\mu})(\mathbf{\mu_k}-\mathbf{\mu})^T\] <p>这里的 \(\mu_k\) 表示 K 类别下数据降维后输出值的均值，\(\mu\) 表示所有数据降维后输出值的均值。我们有很多中优化标准，比如二分类中的分子分母，这里我们用</p> \[J(\beta) = Tr\{\sigma_{within}^{-1}\sigma_{between}\} = Tr\{(\beta S_W\beta^T)^{-1} (\beta S_B\beta^T)\}\] <p>而</p> \[S_W = \sum_{k=1}^K\sum_{n\in C_k} (\mathbf{x_n}-\mathbf{m_k})(\mathbf{x_n}-\mathbf{m_k})^T\] \[S_B = \sum_{k=1}^KN_k (\mathbf{m_k}-\mathbf{m})(\mathbf{m_k}-\mathbf{m})^T\] <p>最后，我们进行求解。模型的权重值由矩阵 \(S_W^{-1}S_B\) 的前 H 大的特征值确定。</p> <h3 id="the-perceptron-algorithm">The perceptron algorithm</h3> <p>这种算法用于处理二分类问题，很难泛化到多分类的任务中。这种算法是将非线性函数作用与输入vector x，再用线性模型处理。最后正值为一类，负值为另一类。可写成</p> \[y(x) = \beta^T \phi(x)\] <p>接下来是损失函数的选择。尽管该算法关注的是错误分类的样本，我们不能直接用错误分类样本数量作为损失函数，因为其导数几乎处处为零，无法优化。所以我们最后确定的 perceptron criterion 是</p> \[L(\beta) = -\sum_{n\in W}\beta^T\phi_ny_n^*\] <p>这里 W 表示被错误分类的样本集合。之后我们就可以用 SGD 方法来迭代优化。从这里也可以看出，这个算法的解释是不断遍历训练集，忽略分类正确的数据，利用分类错误的数据修改模型，直到最后收敛。</p> <p>从中我们也可以发现问题，即在训练过程中，随着模型的修改。有些初始被正确分类的数据可能会被错误分类，所以该方法不能保证稳定降低损失函数。perceptron convergence theorem 告诉我们，当训练集是线性可分时，我们可以在有限训练次数里得到一个解。（这里理论上不止一个解，我们得到的具体某个解取决于模型参数初值和训练顺序等）而当数据是线性不可分时，该算法永远无法收敛</p> <h2 id="probabilistic-generative-models">Probabilistic Generative Models</h2> <p>在下面的内容中，我们从概率分布的角度去分析分类任务。</p> <p>这里我们采用生成模型的方式，建模基于类别的条件概率 \(P(x\vert C_k)\) ，以及类别分布的先验概率 \(P(C_K)\) 。这样我们就可以通过贝叶斯定理得到后验的分类概率 \(P(C_k\vert x)\) 。以二分类问题为例，类别 \(C_1\) 的后验概率可以写成</p> \[P(C_1 \vert x ) = \frac{P(x\vert C_1)P(C_1)}{P(x\vert C_1)P(C_1)+P(x\vert C_2)P(C_2)} = \frac{1}{1+exp(-a)} = \sigma(a)\] \[where \quad a = ln\frac{P(x\vert C_1)P(C_1)}{P(x\vert C_2)P(C_2)}\] <p>我们这样写是为了凑出 logistic sigmoid function \(\sigma(a) = 1/(1+exp(a))\)</p> <ul> <li>该函数具有对称性，\(\sigma(-a) = 1-\sigma(a)\)</li> <li>如果我们对其求逆函数，则有 \(a = ln(\frac{\sigma}{1-\sigma})\) ，该函数被称为 logit函数，用来表示两类的分类概率比，即 \(ln[P(C_1\vert x)/P(C_2\vert x)]\)</li> <li>对该函数求导时，\(\frac{d\sigma}{da} = \sigma(1-\sigma)\)</li> </ul> <p>进而，在 K 分类的问题中，我们按相同的思路可以得到</p> \[P(C_k \vert x ) = \frac{P(x\vert C_k)P(C_k)}{\sum_j P(x\vert C_j)P(C_j)} = \frac{exp(a_k)}{\sum_jexp(a_j)}\] \[where \quad a_k = ln[P(x\vert C_k)P(C_k)]\] <p>这时的函数形式被称为 softmax。下面的内容我们来考虑选用不同形式条件概率 \(P(x\vert C_k)\) 的效果及求解。将分别从连续型输入变量和离散型输入变量讨论</p> <h3 id="input-type">Input Type</h3> <p>我们首先假设条件概率 \(P(x\vert C_k)\) 服从高斯分布，同时假设所有类的协方差矩阵均相同，那么我们可以写出它的概率密度函数，即</p> \[P(x\vert C_k) = \frac{1}{(2\pi)^{D/2}}\frac{1}{|\Sigma|^{1/2}}exp\{-\frac{(x-\mu_k)^T\Sigma^{-1}(x-\mu_k)}{2}\}\] <p>结合上文提到的贝叶斯定理，我们可以得到后验概率</p> \[P(C_k\vert x) = \sigma(\beta_k^Tx+\beta_{k0})\] <p>其中</p> \[\beta_k = \Sigma^{-1}\mu_k\] \[\beta_{k0} = -\frac{1}{2}\mu_k^T\Sigma^{-1}\mu_k + \ln P(C_k)\] <p>可以发现，在假设高斯分布后，我们又回到了线性模型。而通式中的先验概率 \(P(C_k)\) 只出现在线性模型的截距项 \(\beta_0\) ，表明先验概率只会改变分类边界的位置（控制其平移），不会影响分类边界的形状。在当前假设下，分类边界为线性。</p> <p>值得一提的是，如果我们放宽假设，假设不同类的高斯分布均有各自的协方差矩阵，那么此时分类边界变为二次函数.</p> <p>在之前的分析中，我们都假设条件概率 \(P(x\vert C_k)\) 服从高斯分布。如果我们进一步放宽假设，假设 \(P(x\vert C_k)\) 是指数函数，即具有如下形式</p> \[P(x\vert \lambda_k) = h(x)g(\lambda_k)exp\{\lambda_k^Tx\}\] <p>此时我们同样可推导出线性方程，这里直接给出结果 \(a_k(x) = \lambda_k^Tx + \ln g(\lambda_k) + \ln P(C_k)\)</p> <p>最后我们考虑离散类型的输入。为了简便，我们假设输入数据 \(x_i\) 为二分类，零或一。数据集总共包含 N 个数据。此时我们同样可以写出条件概率 \(P(x\vert C_k)\) 如下</p> \[P(x\vert C_k) =\prod_{i=1}^N\mu_{ki}^{x_i}(1-\mu_{ki})^{1-x_i}\] <p>同样结合贝叶斯定理，我们求出后验概率中 logistic 函数的作用变量</p> \[a_k(x) = \ln P(C_k) +\sum_{i=1}^N (x_i\ln\mu_{ki}+(1-x_i)\ln (1-\mu_{ki}))\] <p>我们发现和连续型变量一样，最终得到的是关于 X 的线性模型。</p> <h3 id="maximum-likelihood-solution">Maximum Likelihood Solution</h3> <p>在这一节我们介绍如何利用极大似然来确定模型求解过程中需要的参数。在求解时我们需要知道先验概率，高斯分布的均值和方差等信息，这些参数如何取最合适呢？</p> <p>为了便于说明，我们考虑二分类任务，数据集为 \(\{x_i,y_i^*\}\) where i=1,2,…,N ，数据的标签是二进制的，即 1 表示属于类别 \(C_1\) ，0 表示属于类别 \(C_2\) 。此外，我们给出两个类别的先验分布为 \(P(C_1)=\pi\) ， \(P(C_2) = 1-\pi\)</p> <p>对于类别 \(C_1\) ，对应的标签值为 1，我们可以写出其联合分布为</p> \[P(x_n,C_1) =P(C_1)P(x_n\vert C_1) = \pi N(x_n\vert \mu_1,\Sigma)\] <p>类别 \(C_2\) 是相似的，我们直接写出似然方程</p> \[P(y^*\vert \pi ,\mu_1,\mu_2,\Sigma) = \prod_{n=1}^N [ \pi N(x_n\vert \mu_1,\Sigma)]^{y_n^*} [ (1-\pi) N(x_n\vert \mu_2,\Sigma)]^{1-y_n^*}\] <ul> <li>同样，我们取log得到 log-likelihood，首先考虑先验概率对优化的影响，log-likelihood 中和先验概率相关的部分是</li> </ul> \[f(\pi) = \sum_{i=1}^N\{y_i^*\ln \pi+(1-y_i^*)\ln (1-\pi)\}\] <p>对其求导并令导数为零可以发现，此时 \(\pi\) 就是类别 \(C_1\) 所占全部数据的比例。所以极大似然对应的先验概率就是各个类别下的数据所占整体数据比例。我们解决了先验概率的问题。这个结论同样可以泛化到多分类任务中。</p> <ul> <li>接下来我们考虑高斯分布均值对优化的影响，这里考虑第一类的均值 \(\mu_1\) 的求解，其他类别的均值求解方式与之一致。我们写出log-likelihood中和 \(\mu_1\) 相关的部分</li> </ul> \[f(\mu_1) = -\frac{1}{2}\sum_{i=1}^N y_i^*(x_i-\mu_1)^T\Sigma^{-1}(x_i-\mu_1) + constant\] <p>对其求导并令导数为零，可以得到</p> \[\mu_1 =\frac{1}{N_1}\sum_{i=1}^N y_i^* x_i, \quad \mu_2 =\frac{1}{N_2}\sum_{i=1}^N (1-y_i^*) x_i\] <p>同样可以发现，极大似然对应的各类别高斯分布均值就是该类别内所有数据的均值</p> <ul> <li>最后我们考虑共享的高斯分布协方差矩阵对优化的影响。此时对应的部分是</li> </ul> \[f(\Sigma) = -\frac{N}{2}\ln |\Sigma| - \frac{N}{2}Tr\{\Sigma^{-1} S\}\] \[where \quad S = \frac{N_1}{N}(\frac{1}{N_1}\sum_{n\in C_1}(x_n-\mu_1)(x_n-\mu_1)^T)+ \frac{N_2}{N}(\frac{1}{N_2}\sum_{n\in C_2}(x_n-\mu_2)(x_n-\mu_2)^T)\] <p>可以直接看出，当 \(\Sigma=S\) 时，对应取到极大似然。这些结果可以扩展到 K 分类任务中。</p> <h2 id="probabilistic-discriminative-models">Probabilistic Discriminative Models</h2> <p>在上一节中，我们讨论的是用生成模型结合先验概率来进行分类。在这一节中我们直接用极大似然去估计后验概率 \(P(C_K\vert x)\) ，这样的好处是许多参数不需要知道，而且可以提升预测性能（尤其是条件概率分布的假设和真实分布相差很大的时候）</p> <h3 id="logistic-regression">Logistic regression</h3> <p>其实我们已经在生成模型中见过 logistics 函数了。还是先考虑最基本的二分类任务，我们假设对应标签分别为 0 或 1。由于我们直接对后验概率建模，可以写出</p> \[P_i = P(C_1\vert x) = \sigma(X\beta) = 1/(1+e^{-X\beta})\] <p>由于是二分类问题，\(P(C_0\vert x) =1-P(C_1\vert x)\)，此时我们可以写出极大似然的目标</p> \[P(Y\vert \beta) = \prod_{i=1}^n P(C_1\vert x)^{y_i^*} P(C_0\vert x)^{1-y_i^*}\] <p>将极大似然取 log 再取反作为损失函数，我们可以得到交叉熵，即</p> \[L(\beta) = -\ln P(Y\vert \beta) = -\sum_{i=1}^n\{y_i^*\ln p_i+(1-y_i^*)\ln (1-p_i) \}\] <p>我们将 \(p_i = 1/(1+e^{-X_i\beta})\) 代入上式可得到最后的模型</p> \[\hat{\beta} = argmin_{\beta} \sum_{i=1}^n[y_i^*X_i\beta - \log (1+e^{X_i\beta})]\] <p>用 SGD 的方式进行迭代求解，我们还需要求误差函数的梯度，我们可以得到如下</p> \[\nabla L(\beta) = -\sum_{i=1}^n(y_i^*-p_i)X_i\] <p>在多分类的任务中，我们需要 K 个二分类模型 \(\beta_i\)，sigmoid 函数变为 softmax 函数。对于某类别 k 来说，此时后验概率可写为</p> \[P_k = P(C_k\vert X) = \frac{exp(X\beta_k)}{\sum_j exp(X\beta_j)}\] <p>我们用 \(y_{ik}^*\) 表示第 i 个数据在 k 类别下的真实标签（零或一），\(p_{ik}\)表示第 i 个数据在 k 类别下的预测概率（\(\sum_{k}p_{ik} = 1\)）。那么相应的，极大似然应改为</p> \[P(Y\vert \mathbf{\beta}) = \prod_{i=1}^n\prod_{k=1}^K p_{ik}^{y_{ik}^*}\] <p>我们同样可以写出误差函数的梯度，对于 j 类别对应的模型 \(\beta_j\) 而言</p> \[\nabla_{\beta_j} L(\beta) = \nabla_{\beta_j} L(\beta_1,...\beta_K) = -\sum_{i=1}^N (y_{ij}^*-p_{ij})X_i\] <h3 id="probit-regression">Probit regression</h3> <p>在 logistic regression 中，我们采用 sigmoid 函数 \(\sigma(\cdot)\) 作为线性模型的激活函数。而实际上，我们也可以采用某一概率密度函数 \(p(\theta)\)的积分作为激活函数，即此时</p> \[f(a) = \int_{-\infty}^ap(\theta)d\theta\] <p>这样一种基于 probit activation function 的线性模型被称为 probit regression。在实际中，probit regression 的结果和 logistic regression 的结果很相似。而 probit model 可能会对 outlier 更加敏感</p>]]></content><author><name></name></author><category term="MachineLearning"/><summary type="html"><![CDATA[Book Notes on Pattern Recognition and Machine Learning (PRML)]]></summary></entry></feed>