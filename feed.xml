<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://jjjaaafff.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://jjjaaafff.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-11-14T05:14:19+00:00</updated><id>https://jjjaaafff.github.io/feed.xml</id><title type="html">blank</title><subtitle>Aofan Jiang&apos;s personal website. </subtitle><entry><title type="html"></title><link href="https://jjjaaafff.github.io/blog/2023/2021-07-13-causal4/" rel="alternate" type="text/html" title=""/><published>2023-11-14T05:14:19+00:00</published><updated>2023-11-14T05:14:19+00:00</updated><id>https://jjjaaafff.github.io/blog/2023/2021-07-13-causal4</id><content type="html" xml:base="https://jjjaaafff.github.io/blog/2023/2021-07-13-causal4/"><![CDATA[<h2 id="the-do-operator">The do-operator</h2> <p>Conditioning vs. intervening</p> <ul> <li>Conditioning通过增加条件限制，将整体数据划分为一个子集，并针对该子集进行分析</li> <li>Intervening是对整体的所有数据采取同一个treatment，没有对其划分</li> </ul> <p>对于Interventional distributions，通常可记作</p> \[P(Y (t) = y) \triangleq P(Y = y \vert do(T = t)) \triangleq P(y \vert do(t))\] <p>在 Identification 的过程中，我们借助 Causal model 将 $P(y\vert do(t))$ 转化为 $P(y\vert t)$ (这是在没有confounder的情况下)。前者可由实验获取，后者可由观察数据获取。</p> <h2 id="main-assumption-modularity">Main assumption: modularity</h2> <p>在这里我们引入一个重要的假设，我们假设 the causal mechanisms are modular<br/> 具体来说，在DAG中，如果我们 intervene on node $X_i$，则只改变$P(x_i\vert parent(x_i))$。对于其他 $j \neq i$ 的节点，$P(x_j\vert parent(x_j))$保持不变。</p> <p>也就是说，我们通过do operation，对选取的intervene节点 $X_i$，将其概率$P(x_i\vert parent(x_i))$直接设置为1，而不再关注父节点对其的影响。(注意，这里为了一致性，我们需要保证$x_i$就是do operation中$X_i$被设置的值，否则概率为0)</p> <p>该假设还有其他称呼：independent mechanisms, autonomy, invariance, etc.</p> <p>基于这种假设，我们可以得到对应的数学表达形式，即</p> \[P(x_1,x_2,...,x_n\vert do(S=s)) = \prod_{i\neq S}P(x_i\vert parent(x_i))\] <p>回到 introduction中的例子，X 共同影响 T 和 Y，T 影响 Y，此时</p> \[P(y\vert do(t)) = \sum_xP(y,x\vert do(t)) = \sum_xP(x)P(y\vert t,x)\] <p>而</p> \[P(y\vert t) = \sum_xP(y,x\vert t) = \sum_xP(x\vert t)P(y\vert t,x)\] <p>可以看出$P(y\vert do(t))\neq P(y\vert t)$，这也从另一个角度说明了Association not equal causation</p> <h2 id="backdoor-adjustment">Backdoor adjustment</h2> <p>我们可以通过do-operation来消除其他原因产生的影响，但我们想从观测数据出发，就需要利用条件概率。这也引出了backdoor adjustment</p> <p>我们首先定义 backdoor criteria。对于由 T 到 Y 的因果关系，假设存在一组其他变量W，backdoor criteria的要求是</p> <ol> <li>W 能阻塞从 T 到 Y 的所有backdoor path</li> <li>W 不能包含 T 的所有子节点</li> </ol> <p>我们可以利用该标准，来选择 conditional exchangeability 假设中的条件。那么，结合 Modularity 假设和满足 backdoor criteria 的 W，We can identify the causal efftec of T on Y，即</p> \[P(y \vert do(t)) = \sum_w P(y | t, w) P(w)\] <p>这个式子即为 backdoor adjustment</p> <h2 id="structural-causal-models">Structural causal models</h2> <p>在因果推理中，等号并不能传递任何的因果信息。那么，为了表示 A 是 B 的一个原因，我们用结构方程来表示，即 $B:=f(A)$<br/> 为了提升泛化能力，我们在这里增加一项U，表示可能存在的隐藏原因，即$B:=f(A, U)$</p> <p>在结构化因果模型(SCMs)中，我们用一系列这样的方程来进行建模。其中，直接原因称为endogenous variables，而可能存在的隐藏原因称为exogenous variables</p> <p>在 Interventional SCM 中，我们需要改写部分结果对应的方程，例如从$T := f_T (X, U_T)$ 变到 $T:=t$。we get this by performing the intervention do(T = t).</p> <p>在建立 SCM 之后，我们再回头看之前定义的 backdoor criteria 第二条，为什么不能对子节点进行条件处理呢？有两种可能</p> <ol> <li>对子节点condition，可能会阻塞 chain 形式的因果图模型，即 block causal association</li> <li>可能会产生新的association，如果对 immorality 类型的子节点condition，则会产生新的 unblocked path，对结果产生影响。而隐藏原因的存在增大了这样 immorality 类型的出现。这样一种影响称为 Collider bias</li> </ol>]]></content><author><name></name></author></entry><entry><title type="html">a post with bibliography</title><link href="https://jjjaaafff.github.io/blog/2023/post-bibliography/" rel="alternate" type="text/html" title="a post with bibliography"/><published>2023-07-12T13:56:00+00:00</published><updated>2023-07-12T13:56:00+00:00</updated><id>https://jjjaaafff.github.io/blog/2023/post-bibliography</id><content type="html" xml:base="https://jjjaaafff.github.io/blog/2023/post-bibliography/"><![CDATA[<p>This post shows how to add bibliography to simple blog posts. If you would like something more academic, check the <a href="/blog/2021/distill/">distill style post</a>.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="bib"/><summary type="html"><![CDATA[an example of a blog post with bibliography]]></summary></entry><entry><title type="html">Causal12</title><link href="https://jjjaaafff.github.io/blog/2021/causal12/" rel="alternate" type="text/html" title="Causal12"/><published>2021-07-21T00:00:00+00:00</published><updated>2021-07-21T00:00:00+00:00</updated><id>https://jjjaaafff.github.io/blog/2021/causal12</id><content type="html" xml:base="https://jjjaaafff.github.io/blog/2021/causal12/"><![CDATA[<h1 id="transfer-learning-and-transportability">Transfer Learning and Transportability</h1> <p>Here’s the table of contents:</p> <ol id="markdown-toc"> <li><a href="#transfer-learning-and-transportability" id="markdown-toc-transfer-learning-and-transportability">Transfer Learning and Transportability</a> <ol> <li><a href="#transfer-learning" id="markdown-toc-transfer-learning">Transfer learning</a></li> <li><a href="#transportability-of-causal-effects-across-populations" id="markdown-toc-transportability-of-causal-effects-across-populations">Transportability of Causal Effects Across Populations</a></li> </ol> </li> </ol> <h2 id="transfer-learning">Transfer learning</h2> <p>在迁移学习中，我们将任务1中由训练数据1得到的模型1迁移到任务2，帮助从训练数据2得到模型2，实际中可能有多个任务。我们在这里主要讨论的是 Domain Generalization，其框架如下<br/> <img src="/images/ICI_lec12_1.JPG" alt="Domain Generalization" title="Domain Generalization"/></p> <p>在 domain generalization中，我们设定 $P_{train}(x,y)\neq P_{test}(x,y)$ ，如果这两者相等，此时任务则退化为常规的监督学习。我们的目标是在只接触 $P_{train}(x,y)$ 时，建模 $E_{test}(Y\vert x)$ 。</p> <p>在这里我们还需要做一个假设称为 Covariate Shift Assumption，即</p> \[P_{train}(y\vert x) = P_{test}(y \vert x) \qquad P_{train}(x)\neq P_{test}(x)\] <p>此外，还要求 train 和 test 的数据范围相同</p> <p>在分布内预测 Y 时，我们用无结构的vector X 来预测 Y ，而我们也可以用因果结构的角度来理解预测。这时的任务为 in-distribution prediction of Y from out-of-sample data for X ，即给出 $P_{train}$ 中没有见过的 X，预测对应的落在 $P_{train}$ 中的 Y 。</p> <p>那么此时最自然的一个问题是，我们最少需要多少个变量就可以得到最优的预测结果呢？这时我们需要因果图中找到 Y 的 Markov Blanket，集合内的元素就是最少需要的变量。</p> <p>Markov Blanket 的目的是 block 因果图中所有节点到 Y 的path。因此它包含 Y 所有的父节点，子节点和子节点的其他父节点三类。</p> <p>除了这个任务外，还有其他任务也可以从因果推理的角度理解。比如用从 $P_{test}$ 中采样得到的 X 来预测 Y。我们认为所有的 test 分布都可以看成对因果图部分节点做intervention生成。此时结合之前提到的Modularity假设，即 Intervening on a variable only changes the causal mechanism (structural equation) for that variable. All other causal mechanisms remain unchanged. 我们有结论：Causal Mechanism is Optimal in Robust Sense。当condition 包含 Y 的非父节点时，intervention on other nodes 会对最终的结果产生干扰影响。</p> <p>这可以看成是对 Covariate shift 假设的放松，此时我们只要求 $P_{train}(y\vert parent(Y)) = P_{test}(y \vert parent(Y))$</p> <h2 id="transportability-of-causal-effects-across-populations">Transportability of Causal Effects Across Populations</h2> <p>Transportability: transport causal effects across different populations<br/> 具体来说，已知源人群数据 $P(y,t,…)$ 和 目标人群数据 $P^{\star}(y,t,…)$ ，给出源模型 $P(y\vert do(t),x)$ ，我们的目标是得到对应模型 $P^{\star}(y\vert do(t),x)$ ，判断两者是否相等</p> <p>我们首先引入 Selection Diagrams 的概念，它允许两个分布有不同的causal mechanism。具体方法是增加节点 S 指向原图节点。此时我们有 $P^{\star}(y \vert do(t), x) \triangleq P(y \vert do(t), x, s^{\star})$</p> <p>这里有一些不同的 Transportability，列举如下</p> <ul> <li>Direct Transportability<br/> 我们有 \(P(y \vert do(t), x) = P^{\star}(y \vert do(t), x) \quad if\ Y \perp \!\!\! \perp_{G_{\overline{T}}} S\vert T,X\)<br/> 这是利用了 do-calculus 的 rule1 进行化简，表明两组人群的causal effect 完全相同</li> <li>Trivial Transportability<br/> 如果我们无法得到Direct Transportability，但可以接触到目标人群的观测数据，那么我们可以用观测数据来 identify estimand，即 $P^{\star}(y \vert do(t), x) = P^{\star}(y \vert t, x)$ 这利用的是 do-calculus 的 rule2</li> <li> <p>S-Admissibility and Transport Formula<br/> 我们首先定义 S-Admissibility 的概念，对于一个变量集合W，如果 \(Y \perp \!\!\! \perp_{G_{\overline{T}}} S\vert T,W\) , 那么我们称该集合 W 为 S-admissible</p> <p>如果 W 是 S-admissible, 那么我们有</p> \[P^*(y\vert do(t))=\sum_wP(y\vert do(t),w)P^*(w)\] <p>这类似于之前提到的 backdoor adjustment，将问题转化为源模型与集合 W 的观测数据结合</p> </li> </ul>]]></content><author><name></name></author><summary type="html"><![CDATA[Transfer Learning and Transportability]]></summary></entry><entry><title type="html">Causal13</title><link href="https://jjjaaafff.github.io/blog/2021/causal13/" rel="alternate" type="text/html" title="Causal13"/><published>2021-07-21T00:00:00+00:00</published><updated>2021-07-21T00:00:00+00:00</updated><id>https://jjjaaafff.github.io/blog/2021/causal13</id><content type="html" xml:base="https://jjjaaafff.github.io/blog/2021/causal13/"><![CDATA[<h1 id="counterfactuals-and-mediation">Counterfactuals and Mediation</h1> <p>Here’s the table of contents:</p> <ol id="markdown-toc"> <li><a href="#counterfactuals-and-mediation" id="markdown-toc-counterfactuals-and-mediation">Counterfactuals and Mediation</a> <ol> <li><a href="#counterfactuals-basics" id="markdown-toc-counterfactuals-basics">Counterfactuals Basics</a></li> <li><a href="#mediation" id="markdown-toc-mediation">Mediation</a></li> </ol> </li> </ol> <h2 id="counterfactuals-basics">Counterfactuals Basics</h2> <p>正如我们在之前提到的，因果推理中的根本问题，对于一个个体而言，我们只能观察到causal effect 中的一项，此时另外一项即称为 Counterfactuals 。其数学形式如下</p> \[P(Y(t)\vert T=t',Y=y')\] <p>可以看到，观察到的数据与假定的条件是不一致的。这与CATE不同，在CATE中，$E[Y (t) \vert X = x] = E[Y \vert do(t), X = x]$ ，这两者是一致的。由此也表明，我们无法用 do-notation 来表示 counterfactuals</p> <p>那么，从个体的角度来看，应该如何计算 counterfactuals 呢？<br/> 在该问题下，我们已知的是观测数据 (T,Y)，我们假设知道 Y 的正确的structural equation，此时我们需要计算出个体层次的 Y(t’)，计算流程如下</p> <ol> <li>Abduction：我们首先利用观测数据来确定 Y 的结构方程中的隐藏变量 U 的值</li> <li>Action：我们修改 T 对应的结构方程，将其替换为不同的treatment，即 T:=t’。同时将 U 的值代入 Y 的结构方程，得到针对该个体的 SCM</li> <li>我们结合步骤一和步骤二，计算出 T=t’ 下该个体对应的 Y 值，即为 counterfactuals 值</li> </ol> <p>这时存在一个问题，即使我们有 Y 的结构方程，我们也不能百分百地确定counterfactuals的值。比如当我们无法计算U的值时（U和Y不是一一对应时），那么当我们观测到一个 Y 值时，我们无法确定具体哪个 U 值可以对应到 Y（有若干个不同的选项）。在这种情况下，我们需要结合 U 的个体分布先验概率，计算流程如下</p> <ol> <li>Abduction：我们首先利用观测数据 Z 来更新 U 的分布，$P(U\vert Z)$</li> <li>Action：我们修改 T 对应的结构方程，将其替换为不同的treatment，即 T:=t’</li> <li>我们结合步骤一和步骤二，计算出 T=t’ 下该个体对应的 Y(t’) 分布，即为 counterfactuals 分布。（对于个体而言，此时我们只能得到一个分布，无法得到具体的counterfactuals值）</li> </ol> <p>以上这些方法都是基于一个假设，我们知道 Y 的parametric model。但这个假设是很强的，如果没有这个假设，我们就无法计算个体层面的 counterfactuals。而如果我们想计算整个人群的 counterfactuals，那么我们就不需要知道 Parametric model</p> <p>Population-level counterfactual：$E[Y(t)\vert T=t’]$ 。此时的计算方式就像我们之前的ATE一样，如果它们是 identifiable ，我们就可以完全按照 ATE 的处理方式来计算 Population-level counterfactual</p> <h2 id="mediation">Mediation</h2> <p>举个例子，如果我养了一只狗，那么我会很高兴。但应该如何衡量养狗对我心情的直接影响呢？可能养狗会让我交到更多的朋友，而交朋友对我的心情有重大影响。那么此时养狗对我心情的直接影响就没有那么大了，我应该考虑多交朋友而不是多养狗。由此，我们需要衡量 treatment 对结果的直接影响。</p> <p>第一种衡量方式称为 Controlled Direct Effect (CDE)，我们直接对中间原因干预，计算干预下的causal effect，即 $E[Y \vert do(T = 1, M = m)] - E[Y \vert do(T = 0, M = m)]$ 。注意，这里我们采用 do 而不是观测数据，这是因为观测数据可能会引入新的联系，对结果产生干扰</p> <p>这种衡量方式存在两个问题</p> <ol> <li>CDE 很大程度上受中间变量的影响，当 M 的值不同时，对应的causal effect可能相差会很大</li> <li>我们没办法计算 indirect effect，我们不能直接用总的causal effect减去CDE作为 indirect effect</li> </ol> <p>第二种方式称为 Natural Direct and Indirect Effects (NDE,NIE)，在介绍这种方式之前，首先引入一些记号</p> \[E[Y_{t,m}] \triangleq E[Y \vert do(T = t, M = m)] \quad E[M_t] \triangleq E[M\vert do(T=t)]\] <p>基于这些记号，我们可以定义衡量方式</p> \[CDE \triangleq E[Y_{1,m}-Y_{0,m}]\] \[NDE \triangleq E[Y_{1,M_0}-Y_{0,M_0}]\] \[NIE \triangleq E[Y_{0,M_1}-Y_{0,M_0}]\] <p>之所以称为 natural，是因为在计算 direct effect时，treatment 分别采取 0 和 1，而中间变量保持一致，保持为无treatment下的期望。同样，在计算 indirect effect时，treatment保持一致，保持为无treatment。此时的total effect也可以表示出来，即</p> \[TE = NDE-NIE_r\] <p>$NIE_r$ 表示将NIE表达式中所有的 0 和 1 对应替换</p> <p>接下来的一个问题是，给出这样一种衡量方式后，我们在什么情况下可以用这种方式呢？这需要一些前提条件，假设 adjustment set 记为 W</p> <ol> <li>W中不包含 T 的子节点</li> <li>W blocks all backdoor paths from M to Y</li> </ol> <p>在这两个条件下，我们已经可以通过实验(do operation)来计算 NDE 的值，计算式如下</p> \[NDE = \sum_m\sum_w(E[Y_{1,m}\vert W=w] - E[Y_{0,m}\vert W=w])\times P(M = m \vert do(T = 0), W = w)P(W = w)\] <p>如果我们想更进一步，利用观测数据而不是 do operation 来计算 NDE，则需要在上述两个假设的基础上，进一步进行假设</p> <ol> <li>$P(M=m\vert do(T=0),W=w)$ is identifiable，即从 T 到 M 没有不可阻断的 backdoor path</li> <li>$E[Y\vert do(T=t,M=m),W=w]$ is identifiable，即从 T 到 Y 没有不可阻断的 backdoor path</li> </ol> <p>在补充的两个假设下，我们可以去掉上述 NDE 计算式中的 do-operation，并将其替换为观测结果</p> <p>最后我们比较一下 controlled mediation 和 natural mediation</p> <ul> <li>CDE 永远都可以利用实验（do-operator）来测量，但我们无法得到明确的 undirect effect</li> <li>NDE 不能保证始终可以用实验测量，但它允许我们分别计算得到 direct effect 和 undirect effect，并可以组合得到 total effect</li> </ul>]]></content><author><name></name></author><summary type="html"><![CDATA[Counterfactuals and Mediation]]></summary></entry><entry><title type="html">Causal11</title><link href="https://jjjaaafff.github.io/blog/2021/causal11/" rel="alternate" type="text/html" title="Causal11"/><published>2021-07-20T00:00:00+00:00</published><updated>2021-07-20T00:00:00+00:00</updated><id>https://jjjaaafff.github.io/blog/2021/causal11</id><content type="html" xml:base="https://jjjaaafff.github.io/blog/2021/causal11/"><![CDATA[<h1 id="causal-discovery-from-interventions">Causal Discovery from Interventions</h1> <p>Here’s the table of contents:</p> <ol id="markdown-toc"> <li><a href="#causal-discovery-from-interventions" id="markdown-toc-causal-discovery-from-interventions">Causal Discovery from Interventions</a> <ol> <li><a href="#single-node-structural-intervention" id="markdown-toc-single-node-structural-intervention">Single-Node Structural Intervention</a></li> <li><a href="#multi-node-structural-intervention" id="markdown-toc-multi-node-structural-intervention">Multi-Node Structural Intervention</a></li> <li><a href="#parametric-interventions" id="markdown-toc-parametric-interventions">Parametric Interventions</a></li> <li><a href="#miscellaneous-other-settings" id="markdown-toc-miscellaneous-other-settings">Miscellaneous Other Settings</a></li> </ol> </li> </ol> <h2 id="single-node-structural-intervention">Single-Node Structural Intervention</h2> <p>我们首先考虑最简单的情况，即只有 A 和 B 两个变量，此时真实的因果图有三种情况：$A \rightarrow B$，$A \leftarrow B$ 和 $A \quad B$。<br/> 以第一种情况为例，我们可以写出 A 和 B 的结构方程，$A:=N_A$，$B:=f(A,N_B)$ 。在我们intervene B 之后，此时 B 不受 A 的影响，B 的结构方程变为 $B:=N_B’$ 。由此我们可以得到三种情况下，分别对A，B干预，或者是不干预对应的 Interventional essential graphs 如下<br/> <img src="/images/ICI_lec11_1.JPG" alt="Interventional essential graphs" title="Interventional essential graphs"/><br/> 我们可以发现，如果我们只干预其中一个变量，此时我们无法确定真实的因果图。而当我们分别干预两个变量时，此时我们可以唯一确定真实的因果图。</p> <p>根据已有研究，对于单变量的intervention，当变量数 n&gt;2 时，(n-1) 次intervention足够得到真实的因果图。（注意，如果这(n-1) 次intervention中包含空intervention，即只有观测结果时，此时最差情况下我们需要n次intervention来得到因果图）</p> <p>反过来同样成立，(n-1)次intervention也是必要条件，在最差情况下，我们需要(n-1)次intervention，其他情况下intervention的必需次数要少一些。</p> <p>以上定理提到的最差情况是指，essential graph是完全图，任何两个节点之间都存在一条无向边</p> <h2 id="multi-node-structural-intervention">Multi-Node Structural Intervention</h2> <p>多节点intervention是指，在每次intervention，我们可以同时intervene on multiple nodes。<br/> 那么此时需要多少次intervention才能确定真实的因果图呢？在这里我们直接给出结论，并和单节点intervention的结论进行对比，假设节点个数为n</p> <ul> <li>Single-node intervention：(n-1)是充分条件，(n-1)在最差完全图情况下是必要条件</li> <li>Multi-node intervention：这里我们假设每次intervention中，对干预节点数量没有限制，此时 $\lfloor log_2(n) \rfloor +1$ 是充分条件， $\lfloor log_2(n) \rfloor +1$ 在最差完全图情况下是必要条件</li> </ul> <p>接下来的一个问题是，如果不是完全图这种最差情况，那么我们需要多少次intervention可以确定因果图呢？</p> <p>为此我们首先引入 clique 的概念，clique 表示原图中最大的完全子图节点集合。举个例子，如果原图恰好为完全图，那么最大的clique就是图中所有节点的集合</p> <p>基于clique的概念，我们有定理：在 multi-node intervention 下， $\lceil log_2(c) \rceil$ 次intervention可以得到真实因果图。这里 c 是最大clique中的节点个数</p> <h2 id="parametric-interventions">Parametric Interventions</h2> <p>在structural intervention中，我们的处理方式是将 $Y:=f_\theta(X,N_Y)$ 变为 $Y:=N_Y’$<br/> 而在parametric intervention中，我们的处理方式是将 $Y:=f_\theta(X,N_Y)$ 变为 $Y:=f_{\theta’}(X,N_Y)$<br/> 换言之，我们不是改变 Y 让其不依赖parent，而是改变 Y 对parent的依赖方式，即改变给定parent后 Y 的条件概率分布。所以，仅从概念上来看，parametric intervention包含了structural intervention。但实际上我们称呼 parametric intervention 是指原集合除去 structural intervention 后的部分。除此之外，这两种intervention 方式还有一些其他称呼，比如 hard vs. soft，perfect vs. imperfect</p> <p>在单节点干预下，parametric intervention和structural intervention的结论相同，即 (n-1) 次intervention是充要条件</p> <p>这引出了下一个问题，当我们采取少于 (n-1) 次intervention时，我们得到的是什么样的结果，即怎样的图呢？</p> <p>在单节点的干预下，我们每次intervention，都会引入 immorality。当采取少于 (n-1) 次intervention时，我们会得到部分边有方向，部分边无向的图。<br/> 我们有定理：Two graphs augmented with single-node interventions are interventionally Markov equivalent if any only if they have the same skeletons and immoralities</p> <p>在多节点的干预下，我们有类似的定理：Given the observational data, two graphs augmented with multinode interventions are interventionally Markov equivalent if and only if they have the same skeletons and immoralities</p> <h2 id="miscellaneous-other-settings">Miscellaneous Other Settings</h2> <p>这里列举一些其他情况下的处理方法及研究</p> <ul> <li>Randomized algorithms：Only need O(log log n) interventions</li> <li>Intervene on at most k variables per intervention</li> <li>Only k interventions</li> <li>Unobserved confounding</li> </ul>]]></content><author><name></name></author><summary type="html"><![CDATA[Causal Discovery from Interventions]]></summary></entry><entry><title type="html">Causal10</title><link href="https://jjjaaafff.github.io/blog/2021/causal10/" rel="alternate" type="text/html" title="Causal10"/><published>2021-07-19T00:00:00+00:00</published><updated>2021-07-19T00:00:00+00:00</updated><id>https://jjjaaafff.github.io/blog/2021/causal10</id><content type="html" xml:base="https://jjjaaafff.github.io/blog/2021/causal10/"><![CDATA[<h1 id="causal-discovery-from-observational-data">Causal Discovery from Observational Data</h1> <p>Here’s the table of contents:</p> <ol id="markdown-toc"> <li><a href="#causal-discovery-from-observational-data" id="markdown-toc-causal-discovery-from-observational-data">Causal Discovery from Observational Data</a> <ol> <li><a href="#motivation" id="markdown-toc-motivation">Motivation</a></li> <li><a href="#independence-based-causal-discovery" id="markdown-toc-independence-based-causal-discovery">Independence-Based Causal Discovery</a></li> <li><a href="#semi-parametric-causal-discovery" id="markdown-toc-semi-parametric-causal-discovery">Semi-Parametric Causal Discovery</a></li> </ol> </li> </ol> <h2 id="motivation">Motivation</h2> <p>在之前的内容中，我们都是基于 causal graph 去进行化简分析。那么如果我们没有 causal graph，只有观测到的数据应该怎么办呢？那么这就要用到 causal discovery 方法，根据数据去建立 causal graph</p> <p>causal discovery 大致可分为两类，independence-based 完全基于数据去建图； Semi-Parametric 针对 parametric form 作假设建模</p> <h2 id="independence-based-causal-discovery">Independence-Based Causal Discovery</h2> <p>首先我们需要作出一些假设</p> <ul> <li>Faithfulness<br/> 在之前的马尔科夫假设中，我们从因果图出发分析数据，假设如果 X 和 Y 在 G 图中的 Z 节点条件下独立，那么 X 和 Y 基于 Z 条件独立。<br/> 这里的faithfulness假设则是从反方向假设，即如果 X 和 Y 在数据上对 Z 条件独立，那么在其对应的因果图中，同样有此条件独立关系</li> <li>Causal Sufficiency：对图中的任何变量而言，都不存在没有被观察到的潜在原因对其作用影响</li> <li>Acyclicity：假设是无环图</li> </ul> <p>我们还需要引入马尔科夫等价类（Markov equivalence class）的概念。 马尔科夫等价意味着相同的条件独立分布，比如chain和fork类型属于同一种马尔科夫等价类，而immorality属于另一种马尔科夫等价类。</p> <p>还有skeleton的概念，我们将因果图中的所有的有向边变为无向边，此时得到的图称为 skeleton</p> <p>在介绍完假设及新概念后，我们在这里给出主要定理。两幅因果图是马尔科夫等价的 当且仅当 他们拥有相同的 skeleton 和 immoralities</p> <p>进而由此我们得到 Essential graph（aka CPDAG completed partially） 的概念，Essential graph 是 skeleton 和 immorality 的组合，所有immorality子结构中的边是有向的，其余边仍为无向边。</p> <p>现在来到了下一个问题，我们应该如何得到 Essential graph 呢？其中一种方法称为 PC Algorithm，该算法分为三步</p> <ol> <li>Identify the skeleton<br/> 我们首先从无向完全图开始，对于边 X-Y，如果存在一个 Condition set Z 使得 $X \perp !!! \perp Y \vert Z$ ，那么我们删除连接 X 和 Y 的这条边。condition set 从空集开始，逐渐增加集合内元素的个数进行判断</li> <li>Identify immoralities<br/> 经过第一步后，对图中所有的 X-Z-Y 路径进行判断，当同时满足以下两个条件时，我们可以判断 X-Z-Y 形成了immorality，并为其添加对应的方向 <ul> <li>X 和 Y 之间没有边（在算法的第一步中被删去）</li> <li>Z 不在使得 X 和 Y 条件独立的 condition set 中</li> </ul> </li> <li>Orient qualifying edges that are incident on colliders<br/> 经过第二步后，所有的immorality都别识别出并添加了边的方向。在现在的图中，针对所有 $X \rightarrow Z - Y$ 的路径，当 X 和 Y 之间没有边连接时，我们可以对 Z 和 Y 之间的边添加方向，即 $Z \rightarrow Y$</li> </ol> <p>我们从 PC Algorithm 得到的因果图只是 Essential graph 中的一种形式，并不能保证得到和真实因果图一模一样的graph。</p> <p>除了 PC Algorithm 外，还有一些算法针对更加广泛的情况（即移除部分假设）进行应用，这里列举一些</p> <ul> <li>No assumed causal sufficiency: FCI algorithm</li> <li>No assumed acyclicity: CCD algorithm</li> <li>Neither causal sufficiency nor acyclicity: SAT-based causal discovery</li> </ul> <p>Independence-Based Causal Discovery 也存在一些局限性。</p> <ul> <li>最大的约束是这些算法都依赖准确的条件独立测试。这一点在拥有无限数据时是很容易进行的，但现实中我们得到的数据都是有限的，而且研究表明有时需要相当多的数据才能得到准确的测试结果。</li> <li>需要 faithfulness 假设</li> <li>只能 identify the Markov equivalence class</li> </ul> <p>接下来一个很自然的疑问就是，我们可以做的更好吗？<br/> 在faithfulness的假设下，我们已经可以 identify the essential graph （Markov equivalence class）。现有研究表明，当数据是多正态分布，或者是线性高斯结构方程时，在最好的情况下我们也只能identify a essential graph （Markov equivalence class）</p> <p>那如果是非高斯结构方程，或者是非线性结构方程呢？这就引出了第二类 causal discovery 的方法</p> <h2 id="semi-parametric-causal-discovery">Semi-Parametric Causal Discovery</h2> <p>首先考虑最简单的双变量情况，即 $X\rightarrow Y$ 和 $Y\rightarrow X$ 。如果从马尔科夫等价的角度来看，我们得到的essential graph是相同的，因此无法区分这两种情况。如果从结构方程的角度来看，前一种情况对应 $Y=f_Y(X,U_Y)$ ，X 与 $U_Y$ 相互独立。后一种情况对应 $X=f_X(Y,U_X)$ ，Y 与 $U_X$ 相互独立。此时同样无法进行区分</p> <p>所以在这里我们需要对 parametric form 做一些假设。</p> <ul> <li>Linear Non-Gaussian Assumption：第一种假设噪声为线性非高斯分布的，即 $Y := f(X) + U$ ，X 与 U 相互独立，$U$为非高斯分布。此时根据现有研究，我们有如下定理<br/> linear non-Gaussian 假设下，如果真实的 SCM 为 $Y=f(X)+U $ ，X 与 U 相互独立，那么此时不存在能产生一致 P(x,y) 数据的相反方向的 SCM，即 $X=g(Y)+\tilde{U}$ ，Y 与 $\tilde{U}$ 相互独立，具体证明可见课程教材</li> <li>Nonlinear additive noise assumption：第二种假设噪声为加性的，方程时非线性的，即 $Y := f(X) + U$ ，X 与 U 相互独立， $f$ 是非线性方程。根据现有研究，此时结合Markov assumption, causal sufficiency, acyclicity assumption, 我们可以 identify the causal graph<br/> 此外，我们也可以在外面继续嵌套非线性方程，将线性噪声转换为非线性噪声，即 $Y := g(f(X) + U)$ ，X 与 U 相互独立，则称为 Post-Nonlinear Assumption</li> </ul>]]></content><author><name></name></author><summary type="html"><![CDATA[Causal Discovery from Observational Data]]></summary></entry><entry><title type="html">Causal9</title><link href="https://jjjaaafff.github.io/blog/2021/causal9/" rel="alternate" type="text/html" title="Causal9"/><published>2021-07-18T00:00:00+00:00</published><updated>2021-07-18T00:00:00+00:00</updated><id>https://jjjaaafff.github.io/blog/2021/causal9</id><content type="html" xml:base="https://jjjaaafff.github.io/blog/2021/causal9/"><![CDATA[<h1 id="difference-in-differences">Difference-in-Differences</h1> <p>Here’s the table of contents:</p> <ol id="markdown-toc"> <li><a href="#difference-in-differences" id="markdown-toc-difference-in-differences">Difference-in-Differences</a> <ol> <li><a href="#motivation" id="markdown-toc-motivation">Motivation</a></li> <li><a href="#dif-in-dif" id="markdown-toc-dif-in-dif">Dif-in-dif</a></li> <li><a href="#assumption-and-proof" id="markdown-toc-assumption-and-proof">Assumption and proof</a></li> <li><a href="#existing-problems" id="markdown-toc-existing-problems">Existing problems</a></li> </ol> </li> </ol> <h2 id="motivation">Motivation</h2> <p>在之前，我们一直讨论的因果推理并没有包含时间这一维度。那么现在我们加入时间这一维度，针对treatment group，我们假设从时刻 t 开始，才对其开始施加treatment。对于control group，则始终不对其施加treatment</p> <p>此外，我们还需要引入一个新的概念 Average Treatment Effect on the Treated (ATT)。相比与ATE，ATT对数据进行condition，表示condition之后的causal effect，具体表示如下</p> <ul> <li>ATE：$E[Y (1) - Y (0)]$，如果我们作Unconfoundedness的假设，即 (Y(0),Y(1)) 与 T 相互独立，则可将其化简为 $E[Y \vert T = 1] - E[Y \vert T = 0]$</li> <li>ATT：$E[Y (1) - Y (0)\vert T=1]$，这里我们作弱一些的假设，即Y(0) 与 T 相互独立，则同样可将其化简为 $E[Y \vert T = 1] - E[Y \vert T = 0]$</li> </ul> <p>以上是没有包含时间的ATT，如果把时间考虑进来，此时假设 Y(0) 与 T 不再相互独立，我们用$E[Y_i\vert T=1]$表示时刻 i 对应的数值。时刻 i 下的ATT计算式变为 $E[Y_i (1) - Y_i (0)\vert T=1]$ 。对于计算式中的第一项 $E[Y_i(1)\vert T=1]$ ，我们可以直接从观测数据中获取。对于计算机中的第二项 $E[Y_i(0)\vert T=1]$ ，则需要通过本章节介绍的 dif-in-dif 方法求解</p> <h2 id="dif-in-dif">Dif-in-dif</h2> <p>从上节Motivation中可以看出，dif-in-dif方法用来求解包含时间的ATT中，无法通过观测而获得的 $E[Y_i(0)\vert T=1]$ 这一项。具体求解的方法是利用control group。</p> <p>因为control group全程没有施加treatment，所以我们可以得到无treatment时，实验对象的变化情况，即 $E[Y_1 \vert T = 0] - E[Y_0 \vert T = 0]$ ，我们假设treatment group 在没有施加treatment时，同样按照该趋势变化，所以我们就可以得到 $E[Y_i(0)\vert T=1]$ ，即</p> \[E[Y_i(0)\vert T=1] = E[Y_0 \vert T = 1] - (E[Y_1 \vert T = 0] - E[Y_0 \vert T = 0])\] <p>上述式子第一项是初始时刻 treatment group 的观察数据，第二项是control group的变化情况。在得到该项之后，我们就可以很自然地求出时刻 t=1 下的ATT，即</p> \[ATT_i = (E[Y_1 \vert T = 1] - E[Y_0 \vert T = 1]) - (E[Y_1 \vert T = 0] - E[Y_0 \vert T = 0])\] <p>我们可以发现，此时的计算式为 treatment group 的时间差减去 control group的时间差。正因为此，该方法被称为difference-in-difference，意为两差相减。这种方法还可以去除常数级 confounder 对结果的影响</p> <h2 id="assumption-and-proof">Assumption and proof</h2> <p>为了使用dif-in-dif方法，我们需要做一定的假设来进行条件约束</p> <ul> <li>Consistency Assumption：该假设和之前一样，但扩展到了时间维度，即 $\forall \tau,\ T=t \Rightarrow Y_{\tau} = Y_{\tau}(t)$</li> <li>Parallel Trends Assumption：该假设是为了保证treatment group与control group的变化趋势是相同的 (在未施加treatment时)，用数学形式来表达就是 $E[Y_1(0)-Y_0(0) \vert T = 1] = E[Y_1(0)-Y_0(0) \vert T = 0]$</li> <li>No Pretreatment Effect Assumption：该假设是为了保证初始时间下，treatment对结果无干扰，用数学形式来表达就是 $E[Y_0(1) \vert T = 1] = E[Y_0(0) \vert T = 1]$</li> </ul> <p>基于这些假设，我们来证明 dif-in-dif 可以用来求某时刻下的 ATT，即 $ATT_i = (E[Y_1 \vert T = 1] - E[Y_0 \vert T = 1]) - (E[Y_1 \vert T = 0] - E[Y_0 \vert T = 0])$</p> <p>首先我们将某时刻下的ATT展开，可得到</p> \[ATT_i = E[Y_1(1) - Y_1(0) \vert T = 1] = E[Y_1 \vert T = 1] - E[Y_1(0) \vert T = 1]\] <p>利用Parallel Trends Assumption，我们替换掉上式中的 $E[Y_1(0) \vert T = 1]$ ，可得到</p> \[ATT_i = E[Y_1 \vert T = 1] -(E[Y_0(0) \vert T = 1] + E[Y_1 \vert T = 0] - E[Y_0 \vert T = 0])\] <p>利用No Pretreatment Effect Assumption，我们替换上式的 $E[Y_0(0) \vert T = 1]$ ，将其变为 $E[Y_0(1) \vert T = 1]$ 。最后利用consistency assumption 化简合并，即可得到 dif-in-dif 的数学表达式，完成证明。</p> <h2 id="existing-problems">Existing problems</h2> <ol> <li>我们对 Parallel Trend 的假设有可能被违反。比如当 treatment 和时间同时影响结果时，该假设就不再成立</li> <li>Parallel Trends 是针对特定尺度的。意思是说，如果我们对结果 Y 进行一系列变换（如 logY），那么此时 Parallel Trends 则不再成立。换句话说，parallel trends assumptions isn’t nonparametric</li> </ol>]]></content><author><name></name></author><summary type="html"><![CDATA[Difference-in-Differences]]></summary></entry><entry><title type="html">Causal8</title><link href="https://jjjaaafff.github.io/blog/2021/causal8/" rel="alternate" type="text/html" title="Causal8"/><published>2021-07-17T00:00:00+00:00</published><updated>2021-07-17T00:00:00+00:00</updated><id>https://jjjaaafff.github.io/blog/2021/causal8</id><content type="html" xml:base="https://jjjaaafff.github.io/blog/2021/causal8/"><![CDATA[<h1 id="instrumental-variables">Instrumental Variables</h1> <p>Here’s the table of contents:</p> <ol id="markdown-toc"> <li><a href="#instrumental-variables" id="markdown-toc-instrumental-variables">Instrumental Variables</a> <ol> <li><a href="#motivation" id="markdown-toc-motivation">Motivation</a></li> <li><a href="#linear-example" id="markdown-toc-linear-example">Linear Example</a></li> <li><a href="#nonparametric-identification-of-local-ate" id="markdown-toc-nonparametric-identification-of-local-ate">Nonparametric Identification of Local ATE</a></li> </ol> </li> </ol> <h2 id="motivation">Motivation</h2> <p>在之前，我们研究了 no unobserved confounding 的情况。这种情况下，我们可以利用 backdoor adjustment 很容易地进行处理。而后来提出的 unconfounded children criterion 从更广泛的范围内处理无隐藏原因的情况。</p> <p>在实际中，无法观察到的隐藏原因很常见，Instrumental Variables 针对的就是一种特殊的隐藏原因。instrumental variable 的目的是想找因果关系，减小 estimation error 产生的影响。对于系统来说，某原因 T 是可以观察到的，但是可能有偏差，因此要找一个只影响该原因 T 的变量来抵消相应的估计误差。这就是 instrumental variable</p> <p>我们首先对 instrumental variable 做一些假设</p> <ul> <li>Relevance：我们假设 instrumental variable Z 对原因 T 有因果影响</li> <li>Exclusion Restriction：Z对结果 Y 的影响必须全部经过 T。换句话说，不能存在由 Z 越过 T 到达 Y 的关系</li> <li>Unconfoundedness：不存在未观测到的其他原因同时作用与 Z 和 Y。换句话说，no unblockable backdoor paths to Y。我们允许 Z &lt;- W -&gt; Y，但不允许 Z &lt;- U -&gt; Y</li> </ul> <p>为什么我们没有再之前的内容中提过 instrumental variable 呢？<br/> 这是因为之前的内容基本上都是 nonparametric identification，而在这里，nonparametric identification的必要条件 (如果已知identifiability，我们可以block每一条从 T 到其子节点之间(同时也是Y的祖先节点)的backdoor path) 被潜在原因打破了。</p> <h2 id="linear-example">Linear Example</h2> <p>在这个例子中，我们引入一个线性假设，即 $Y:=\delta T +\alpha_u U$ 。根据之前的Exclusion Restriction假设，这里的 Y 中不包含 instrumental variable Z。我们首先考虑最基本的情况，即 Z 和 T 均为布尔值。</p> <p>我们首先来计算一下 Y 与 Z 之间的 association difference，即 $E[Y \vert Z = 1] - E[Y \vert Z = 0]$ 。首先根据我们的线性假设，我们代入 Y 的线性表达式并展开合并，可以得到</p> \[AD = \delta (E[T \vert Z = 1] - E[T | Z = 0]) + \alpha_u (E[U \vert Z = 1] - E[U \vert Z = 0])\] <p>再根据 Unconfoundedness 假设，U 的取值与 Z 无关，因此上式的第二项为0，最后可得到</p> \[\delta = \frac{E[Y \vert Z = 1] - E[Y \vert Z = 0]}{E[T \vert Z = 1] - E[T | Z = 0]}\] <p>如果我们假设 Z 对 T 的线性影响系数为 $\alpha_z$ ，则上式可写为 $\delta = \delta \alpha_z/\alpha_z$<br/> 在现实中，我们显然无法直接去量化 Z 对 T 的影响，为此我们需要对 $\delta$ 进行估计。最直接的估计是 Wald estimator，利用统计的方式估计，此时估计值 $\hat{\delta}$ 的计算式为</p> \[\hat{\delta} = \frac{\frac{1}{n_1}\sum_{i:z_i=1}Y_i - \frac{1}{n_0}\sum_{i:z_i=0}Y_i}{\frac{1}{n_1}\sum_{i:z_i=1}T_i - \frac{1}{n_0}\sum_{i:z_i=0}T_i}\] <p>接下来我们考虑 T 和 Z 均为连续值的情况。此时我们计算的不是 $E[Y \vert Z = 1] - E[Y \vert Z = 0]$ 而是 Cov(Y,Z)。按和上面相同的过程，我们可以推出 $\delta = Cov(Y,Z)/Cov(T,Z)$ 。我们同样可以用 Wald estimator 去统计估计近似，这里提出一种新的近似方法，称为 Two-Stage Least Squares Estimator</p> <ol> <li>利用 T 对 Z 的线性回归来估计 $E[T\vert Z]$，我们可以得到 T 投影到 Z 空间的方程 $\hat{T}$，这里的 $\hat{T}$ 是一个关于 Z 的函数，不包含其他隐藏原因 U</li> <li>利用 Y 对 $\hat{T}$ 的线性回归来估计 $E[Y \vert \hat{T}]$ ，最后 $\hat{T}$ 的拟合系数就是我们对 $\delta$ 的估计</li> </ol> <p>该方法可同样用于布尔 T Z 的情况</p> <h2 id="nonparametric-identification-of-local-ate">Nonparametric Identification of Local ATE</h2> <p>上一节中我们线性假设的约束还是太强了，它约束了所有个体的treatment effect均相同(Homogeneity)。如果没有这么强的约束，我们能否进行identification呢？</p> <p>我们首先针对 instrument affects the treatment，将整体数据分为四组</p> <ul> <li>Compliers: T(Z=1)=1, T(Z=0)=0，T 完全取决于 Z</li> <li>Defiers：T(Z=1)=0, T(Z=0)=1，T 永远和 Z 反着来</li> <li>Always-takers：T(Z=1)=1, T(Z=0)=1，无论 Z 怎样，T 永远为 1</li> <li>Never-takers：T(Z=1)=0, T(Z=0)=0，无论 Z 怎样，T 永远为 0</li> </ul> <p>在前两种情况中，Z 还有指向 T 的边；后两种情况中则没有，Z 作为孤立的点，没有连接任何其他节点。在我们只得知某一个条件(如T(Z=1)=1)时，我们无法确定该数据属于哪个组。</p> <p>在推导Local ATE Identification之前，我们还需要引入一个假设，称为Monotonicity Assumption，$\forall i, T_i(Z=1)\ge T_i(Z=0)$ ，该假设完全消除了 Defiers 组</p> <p>在该假设下，我们可以写出 local ATE $E[Y (Z = 1) - Y (Z = 0)]$ 的式子，即</p> \[E[Y (Z = 1) - Y (Z = 0)] = E[Y (Z = 1) - Y (Z = 0) \vert T(1) = 1, T(0) = 0] P(T(1) = 1, T(0) = 0)\] <p>由此我们可得到Local ATE (LATE) 也称为 Complier average causal effect (CACE):</p> \[E[Y (T = 1) - Y (T = 0) \vert T(1) = 1, T(0) = 0] =\frac{E[Y (Z = 1) - Y (Z = 0)]}{P(T(1) = 1, T(0) = 0)}\] <p>根据 Unconfoundedness 假设，Y 和 Z 之间不存在任何的confounder，因此我们可以将分子改写为 $E[Y\vert Z=1]-E[Y \vert Z=0]$<br/> 对于分母，我们可将其化简为 $E[T \vert Z = 1] - E[T \vert Z = 0]$ ，化简的思路是结合 Monotonicity Assumption 和 伯努利分布。<br/> 最后，我们重写化简之后的Local ATE 如下</p> \[E[Y (T = 1) - Y (T = 0) \vert T(1) = 1, T(0) = 0] =\frac{E[Y \vert Z = 1] - E[Y \vert Z = 0]}{E[T \vert Z = 1] - E[T | Z = 0]}\] <p>为了对比，我们写出 ATE 的形式</p> \[E[Y (T = 1) - Y (T = 0]\] <p>可以看到，在 Monotonicity Assumption 下，我们推导出的 local ATE 是只针对complier group的，并不是包含所有的数据。而 local ATE 正好和我们在线性假设下推导出的形式一致。</p> <p>这里总结一下 local ATE 存在的问题</p> <ul> <li>Monotonicity Assumption 并不是永远都能满足的</li> <li>我们对整体数据要更感兴趣，而并不只针对complier。更何况我们甚至无法区分哪些个体属于complier group</li> </ul>]]></content><author><name></name></author><summary type="html"><![CDATA[Instrumental Variables]]></summary></entry><entry><title type="html">Causal6</title><link href="https://jjjaaafff.github.io/blog/2021/causal6/" rel="alternate" type="text/html" title="Causal6"/><published>2021-07-15T00:00:00+00:00</published><updated>2021-07-15T00:00:00+00:00</updated><id>https://jjjaaafff.github.io/blog/2021/causal6</id><content type="html" xml:base="https://jjjaaafff.github.io/blog/2021/causal6/"><![CDATA[<h1 id="estimation">Estimation</h1> <p>Here’s the table of contents:</p> <ol id="markdown-toc"> <li><a href="#estimation" id="markdown-toc-estimation">Estimation</a> <ol> <li><a href="#preliminaries" id="markdown-toc-preliminaries">Preliminaries</a></li> <li><a href="#conditional-outcome-modeling-com" id="markdown-toc-conditional-outcome-modeling-com">Conditional outcome modeling (COM)</a></li> <li><a href="#increasing-data-efficiency" id="markdown-toc-increasing-data-efficiency">Increasing Data Efficiency</a></li> <li><a href="#propensity-scores" id="markdown-toc-propensity-scores">Propensity scores</a></li> <li><a href="#inverse-probability-weighting-ipw" id="markdown-toc-inverse-probability-weighting-ipw">Inverse probability weighting (IPW)</a></li> <li><a href="#other-methods" id="markdown-toc-other-methods">Other Methods</a></li> </ol> </li> </ol> <h2 id="preliminaries">Preliminaries</h2> <p>在之前的内容中，我们通过indentification，将Causal Estimand转换为Statistical Estimand，即 $P(Y\vert do(t)) \rightarrow P(Y\vert t)$ 。接下来在本章的部分，我们进行的是下一阶段，对Statistical Estimand $P(Y\vert t)$ 进行估计。在Estimation中，我们输入数据，得到预测结果</p> <p>此外，我们还需要引入一个新的概念Conditional average treatment effects (CATEs)，和之前讲过的ATE相比，多了一个条件，记为</p> \[\tau(x) \triangleq E[Y(1)-Y(0)\vert X=x]\] <p>按与之类似的写法，之前的ATE可以表示为</p> \[\tau \triangleq E[Y(1)-Y(0)]\] <p>在该公式中，X不一定必须是观测变量，尽管通常都是。</p> <h2 id="conditional-outcome-modeling-com">Conditional outcome modeling (COM)</h2> <p>展开我们之前写出的ATE的公式，我们可以得到熟悉的<br/> \(\tau = E_W [E[Y \vert T = 1, W] - E[Y \vert T = 0, W]]\)<br/> 在estimation阶段，我们需要对$E[Y \vert T = 1, W]$进行建模，为了方便，我们重写ATE的公式</p> \[\tau = E_W [\mu(1,W) - \mu(0,W)]\] <p>这里的 $\mu(1,W)$ 和 $\mu(0,W)$ 即为我们的建模(比如利用DNN，则这里表示两个网络模型)。接下来我们需要对W近似，因为可能其维度太高，数据太多，无法得到准确的期望值，此时近似后的ATE我们称为ATE COM Estimator，即</p> \[\hat{\tau} = \frac{1}{n} \sum_i(\hat{\mu}(1,w_i) - \hat{\mu}(0,w_i))\] <p>同理，对于CATE，我们也是首先定义$\mu$来方便表示我们建立的模型，因为包含条件概率，我们记作</p> \[\mu(t,w,x)\triangleq E[Y\vert T=t,W=w,X=x]\] <p>再对W进行近似，得到近似后的 $\hat{\tau(x)}$，我们称为CATE COM Estimator，即</p> \[\hat{\tau}(x) = \frac{1}{n_x} \sum_{i:x_i=x}(\hat{\mu}(1,w_i,x) - \hat{\mu}(0,w_i,x))\] <p>COM还有一些其它的称呼，比如G-computation estimators、Parametric G-formula、Standardization and S-learner where “S” is for “Single”</p> <p>但现在存在一个问题，此时模型的输入为 W 和 T，W 为高维数据，T为一维数据。大量从 T 出来的权值都为0或极小值，对结果的影响几乎为零。该问题称为 estimate can be biased toward zero，那么我们应该怎么做来让模型不再忽略 T 的作用呢，由此我们引出Grouped COM (GCOM)</p> <p>在 GCOM 下，我们用两个网络(模型)分别去模拟T=0和T=1的情况，此时T信息就被隐含地编码的不同网络中了，此时可以写出对应的GCOM Estimator，即</p> \[\hat{\tau} = \frac{1}{n} \sum_i(\hat{\mu}_1(w_i) - \hat{\mu}_0(w_i))\] <p>对于T=1的网络，我们称为treatment group，就只用包含T=1的数据训练；同样，对于T=0的网络，我们称为control group，只用包含T=0的数据训练。这又引出了新的问题，这样数据的利用效率是很低的，我们应该如何提升利用效率呢？</p> <h2 id="increasing-data-efficiency">Increasing Data Efficiency</h2> <ul> <li> <p>TARNet<br/> <img src="/images/ICI_lec6_1.JPG" alt="TARNet结构" title="TARNet结构"/> <br/> 相比与GCOM，TARNet的第一步利用的是全部数据，因此数据利用效率更高。但此方式仍然有局限性，那就是在第二步，指向 $T=0$ 和 $T=1$ 时，这里还是分别用treatment 和 control group的数据</p> </li> <li> <p>X-Learner<br/> 该方法流程如下</p> <ol> <li>估计 $\hat{\mu}_1(x)$ 和 $\hat{\mu}_0(x)$</li> <li>提前计算ITE，对于treatment group, \(\hat{\tau}_{1,i} = Y_i(1) - \hat{\mu}_0(x_i)\)<br/> 对于control group, \(\hat{\tau}_{0,i} = \hat{\mu}_1(x_i) - Y_i(0)\)</li> <li>用 treatment group 中的 $x_i$ 拟合模型 \(\hat{\tau}_{1}(x)\) 来预测 \(\hat{\tau}_{1,i}\)<br/> 用 control group 中的 $x_i$ 拟合模型 \(\hat{\tau}_{0}(x)\) 来预测 \(\hat{\tau}_{0,i}\)</li> <li>最终的估计, \(\hat{\tau}(x) = g(x)\hat{\tau}_{0}(x) + (1-g(x))\hat{\tau}_{1}(x)\) ,这里的g(x)是权重方程，比如可以是propensity score</li> </ol> </li> </ul> <h2 id="propensity-scores">Propensity scores</h2> <p>我们定义Propensity scores e(w)为 $e(w)\triangleq P(T=1 \vert W)$<br/> 我们可以发现，无论 W 是多少维的数据，其Propensity scores e(w)永远是一维数据。基于Propensity scores，我们有一个定理</p> \[(Y(1),Y(0)) \perp \!\!\! \perp T\vert W \Rightarrow (Y(1),Y(0)) \perp \!\!\! \perp T\vert e(W)\] <p>这个定理成立是因为condition on W 时，我们相当于移除因果图中 W 这个节点，使Y与T独立。而condition on e(W)时，我们相当于移除因果图中 W 到 T 的所有边，这样block掉了所有的backdoor path，同样得到独立</p> <p>为此我们想到了Positivity-Unconfoundedness Tradeoff，我们能不能用e(W)去代替W实现降维呢？这样的话overlap的程度就会更高。</p> <p>但这样是不行的，因为我们无法得到 $P(T=1 \vert W)$，在实际中，最好的方式是对其建模，把降维问题转化为对e(W)的建模问题</p> <h2 id="inverse-probability-weighting-ipw">Inverse probability weighting (IPW)</h2> <p>在介绍IPW之前，我们首先说明一下应用背景。在经典的(T,W,Y)三元例子中，correlation并不等于causality，即 $P(T\vert W)\neq P(T)$ ，这也导致我们无法分析T与Y的causal effect。但是如果 $P(T\vert W)= P(T)$ 或者是 $P(T\vert W)=1$ ，则此时 T 与 Y 之间就只存在因果关系，没有其他关系了。为了实现这种情况，我们可以对 $P(T\vert W)$ 这一项除以相同大小的值，即可将其变为1。由此引出 IPW</p> <p>在IPW中，我们对 Y 这一变量进行处理，此时 $E[Y(t)]=E[\frac{1(T=t)Y}{p(t\vert W)}]$ ，ATE的公式也随之发生改变，即</p> \[\tau \triangleq E[Y(1)-Y(0)] = E[\frac{1(T=1)Y}{e(W)}] - E[\frac{1(T=0)Y}{1-e(W)}]\] <p>对 W 近似后的公式为</p> \[\hat{\tau} = \frac{1}{n_1} \sum_{i:t_i=1}\frac{y_i}{\hat{e}(w_i)} - \frac{1}{n_0} \sum_{i:t_i=0}\frac{y_i}{1-\hat{e}(w_i)}\] <p>在CATE estimation下应该如何应用呢？这超出了课程范围，可以阅读参考文献<br/> <a href="https://www.tandfonline.com/doi/full/10.1080/07350015.2014.975555">https://www.tandfonline.com/doi/full/10.1080/07350015.2014.975555</a></p> <h2 id="other-methods">Other Methods</h2> <p>这里简要介绍一些其他的建模估计方法</p> <ul> <li>同时利用COM和propensity score models，分别对 $\mu(t,w)$ 和e(w)进行建模<br/> Consistent if either or is consistent<br/> 理论上比 COM/IPW 更快地收敛到estimand</li> <li>Matching，将treatment group中的点对应到control group，使其对应两点间距离最小，有各种不同的criteria</li> <li>Double machine learning<br/> 该方法分为两步，首先训练一个模型从W预测Y，得到预测值$\hat{Y}$，再训练一个模型从W预测T，得到预测值$\hat{T}$。第二步训练模型从$T-\hat{T}$中预测$Y-\hat{Y}$，以此来消除W的影响</li> <li>Causal trees and forests<br/> Flexible and yield valid confidence intervals (for sampling variability)</li> </ul>]]></content><author><name></name></author><summary type="html"><![CDATA[Estimation]]></summary></entry><entry><title type="html">Causal7</title><link href="https://jjjaaafff.github.io/blog/2021/causal7/" rel="alternate" type="text/html" title="Causal7"/><published>2021-07-15T00:00:00+00:00</published><updated>2021-07-15T00:00:00+00:00</updated><id>https://jjjaaafff.github.io/blog/2021/causal7</id><content type="html" xml:base="https://jjjaaafff.github.io/blog/2021/causal7/"><![CDATA[<h1 id="bounds-and-sensitivity-analysis">Bounds and Sensitivity Analysis</h1> <p>Here’s the table of contents:</p> <ol id="markdown-toc"> <li><a href="#bounds-and-sensitivity-analysis" id="markdown-toc-bounds-and-sensitivity-analysis">Bounds and Sensitivity Analysis</a> <ol> <li><a href="#bounds" id="markdown-toc-bounds">Bounds</a> <ol> <li><a href="#no-assumption-bound" id="markdown-toc-no-assumption-bound">No-Assumption Bound</a></li> <li><a href="#monotone-treatment-bound" id="markdown-toc-monotone-treatment-bound">Monotone Treatment Bound</a></li> <li><a href="#optimal-treatment-selection" id="markdown-toc-optimal-treatment-selection">Optimal Treatment Selection</a></li> </ol> </li> <li><a href="#sensitivity-analysis" id="markdown-toc-sensitivity-analysis">Sensitivity Analysis</a></li> </ol> </li> </ol> <h2 id="bounds">Bounds</h2> <p>在之前的(T,W,Y)例子中，还可能存在潜在原因U同时作用与T和Y。此时，不存在未观察到的Confounding这样一种假设是不现实的。如果还是基于这种unconfoundedness假设，那么我们indentify的其实是一个point (一个具体的值)，而如果我们做一些更弱的假设，则此时我们indentify的是一个区间。在这里，我们来确定不同假设下该区间的范围，即为bounds</p> <h3 id="no-assumption-bound">No-Assumption Bound</h3> <p>在这里，我们假设所有的potential outcomes都具有统一的bound，即 $\forall t, a\le Y(t) \le b$<br/> 由此我们可以得到 $a-b\le E[Y(1)-Y(0)] \le b-a$ ，整个区间的长度为 2(b-a) 。我们可以通过Observational-Counterfactual Decomposition来进一步压缩区间长度。首先我们用 $\pi$ 来表示 P(T=1)，根据定义展开ATE，可得到</p> \[E[Y(1)-Y(0)]=\pi E[Y\vert T=1]+(1-\pi) E[Y(1)\vert T=0] -\pi E[Y(0)\vert T=1]-(1-\pi) E[Y\vert T=0]\] <p>其中，展开后的第一项和第四项称为 observation term，可以从观察结果中直接计算得到。而第二项和第三项称为 Counterfactual term，无法通过计算得到。为此，我们保留observation term，将counterfactual term替换为(a,b) bound 区间。此时我们可以得到</p> \[E[Y(1)-Y(0)]\le \pi E[Y\vert T=1]+(1-\pi) b -\pi a-(1-\pi) E[Y\vert T=0]\] \[E[Y(1)-Y(0)]\ge \pi E[Y\vert T=1]+(1-\pi) a -\pi b-(1-\pi) E[Y\vert T=0]\] <p>我们可以发现，此时 E[Y(1)-Y(0)] 的区间长度被压缩到了 b-a</p> <h3 id="monotone-treatment-bound">Monotone Treatment Bound</h3> <ul> <li> <p>Monotone Treatment Response (MTR)<br/> 这个假设是指，我们假设treatment永远有帮助，即 $\forall i,\ Y_i(1) \ge Y_i(0)$</p> <p>基于此假设，我们可以得到 $E[Y(1)\vert T=0]\ge E[Y\vert T=0]$ ，再结合Observational-Counterfactual Decomposition 得到的式子，我们可以将区间的下限提升至0，即 $E[Y(1)-Y(0)]\ge 0$</p> <p>同样，如果我们假设treatment永远帮倒忙，则是将区间的上限降至0</p> </li> <li> <p>Monotone Treatment Selection (MTS)<br/> 这个假设是指，假设treatment group的潜在结果永远比control group结果更好，即 $E[Y (1) \vert T = 1] \ge E[Y (1) \vert T = 0], \ E[Y (0) \vert T = 1] \ge E[Y (0) \vert T = 0]$ ，再结合Observational-Counterfactual Decomposition 得到的式子，我们可以得到区间的上界，即 $E[Y(1)-Y(0)]\le E[Y\vert T=1]-E[Y\vert T=0]$</p> </li> </ul> <h3 id="optimal-treatment-selection">Optimal Treatment Selection</h3> <ul> <li> <p>OST1<br/> 这个假设是指，我们假设每个个体永远接受最好的treatment，即 $T_i=1 \Rightarrow Y_i(1) \ge Y_i(0), \ T_i=0 \Rightarrow Y_i(0) &gt; Y_i(1)$</p> <p>基于此假设，我们可以得到 $E[Y(1)\vert T=0]\le E[Y\vert T=0], \ E[Y (0) \vert T = 1] \le E[Y \vert T = 1]$ ，再结合展开式子，我们可以得到</p> \[E[Y(1)-Y(0)]\le \pi E[Y\vert T=1]-\pi a\] \[E[Y(1)-Y(0)]\ge (1-\pi)a - (1-\pi) E[Y\vert T=0]\] </li> <li> <p>OST2<br/> 以上提到的假设，都使得ATE区间包含0，即无法indentify ATE的符号。为此我们结合OST1假设及其逆否命题，得到OST2假设，可确定区间内的值均为正或负。</p> <p>在OST2假设中，我们可以得到 $E[Y (1) \vert T = 0] \le E[Y \vert T = 1]$ 。该关系的证明如下：<br/> 首先利用OST1中的假设，我们有 $E[Y (1) \vert T = 0] = E[Y (1) \vert Y_i(0)&gt;Y_i(1)] \le E[Y (1) \vert Y_i(0)\le Y_i(1)]$<br/> 在结合OST1假设的逆否命题，我们有 $E[Y (1) \vert Y_i(0)\le Y_i(1)] = E[Y(1)\vert T=1]$<br/> 结合以上两个式子，即可得到 OST2 假设的内容， $E[Y (1) \vert T = 0] \le E[Y \vert T = 1]$</p> <p>在知道这个假设之后，我们结合展开式化简，可以得到对应的区间上下界，即</p> \[E[Y(1)-Y(0)]\le E[Y\vert T=1]-\pi a - (1-\pi)E[Y\vert T=0]\] \[E[Y(1)-Y(0)]\ge \pi E[Y\vert T=1]+(1-\pi) a - E[Y\vert T=0]\] </li> </ul> <p>总的来说，具体使用哪种假设取决于具体问题。在有的问题里，某些假设可能完全没有意义，而在其他问题里，又可能是最合适的假设 (区间范围最小等)。因此需要具体情况具体分析</p> <h2 id="sensitivity-analysis">Sensitivity Analysis</h2> <p>正如之前所提到的 (T,W,U,Y) 例子，真实的causal effect应该是 $E_{W,U}[…]$ ，而因为我们无法观测到U，实际上我们计算的是 $E_{W}[…]$ ，这就导致了偏差的产生。sensitivity analysis 就是为了分析这样一种偏差程度</p> <ul> <li> <p>Linear Single Confounder<br/> 我们主要考虑最简单的一种情况，即线性关系下的敏感性分析。<br/> 我们定义 $T:=\alpha_w W+\alpha_u U$ 和 $Y:=\beta_w W+\beta_u U + \delta T$ 。<br/> 在理想情况(全知全能)下，causal effect 就是 $\delta$ ，我们的目的也就是恢复 $\delta$ 。<br/> 而近似情况下，$E_W[…] = \delta + \frac{\beta_u}{\alpha_u}$<br/> 此时的偏置值 (bias) 为近似减真实，即 $E_W[…]-E_{W,U}[…]=\beta_u / \alpha_u$<br/> 对应的causal effect可视为 $\delta = Constant-\beta_u / \alpha_u$ ，我们也可以借此找到 causal effect&gt;0 的分界线。根据 $\beta_u - 1/\alpha_u$ 坐标轴作图找分界线的方式也称为 contour plot，经常应用于敏感性分析。</p> <p>接下来是上述公式的证明</p> <ol> <li>首先通过化简得到 $E_W [E[Y \vert T = t, W]]=(\delta+\frac{\beta_u}{\alpha_u})t+(\beta_w-\frac{\beta_u\alpha_w}{\alpha_u})E[W]$</li> <li>分别代入t=1和t=0，并相减即可得到 $E_W [E[Y \vert T = 1, W] - E[Y \vert T = 0, W]] = \delta+\frac{\beta_u}{\alpha_u}$</li> </ol> </li> </ul> <p>以上是最简单形式的 Linear SCM，for arbitrary estimands in arbitrary graphs, where the structural equations are still linear，对应的参考文献为 <a href="http://proceedings.mlr.press/v97/cinelli19a.html">Sensitivity Analysis of Linear Structural Causal Models” from Cinelli et al. (2019)</a></p> <p>其他更广泛形式下的敏感性分析方法见课后参考文档</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Bounds and Sensitivity Analysis]]></summary></entry></feed>