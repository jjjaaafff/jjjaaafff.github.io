---
---

@misc{liu2023rethinking,
  abbr={ARR},
  bibtex_show={true},
  title={Rethinking Tabular Data understanding of Large Language Models},
  abstract = {Coming soon},
  author={Tianyang Liu and Fei Wang and Muhao Chen},
  journal={Coming soon},
  year={2023},
  selected={true}
}

@misc{liu2023repobench,
  abbr={preprint},
  bibtex_show={true},
  author = {Tianyang Liu and Canwen Xu and Julian McAuley},
  title = {RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems},
  abstract = {Large Language Models (LLMs) have greatly advanced code auto-completion systems, with a potential for substantial productivity enhancements for developers. However, current benchmarks mainly focus on single-file tasks, leaving an assessment gap for more complex, real-world, multi-file programming scenarios. To fill this gap, we introduce RepoBench, a new benchmark specifically designed for evaluating repository-level code auto-completion systems. RepoBench consists of three interconnected evaluation tasks: RepoBench-R (Retrieval), RepoBench-C (Code Completion), and RepoBench-P (Pipeline). Each task respectively measures the system's ability to retrieve the most relevant code snippets from other files as cross-file context, predict the next line of code with cross-file and in-file context, and handle complex tasks that require a combination of both retrieval and next-line prediction. RepoBench aims to facilitate a more complete comparison of performance and encouraging continuous improvement in auto-completion systems. RepoBench is publicly available at https://github.com/leolty/RepoBench},
  year = {2023},
  arxiv = {2306.03091},
  journal={arXiv preprint},
  code = {https://github.com/leolty/RepoBench},
  selected = {true}
}



@inproceedings{huang2022registration,
  abbr={ECCV},
  bibtex_show={false},
  title={Registration based few-shot anomaly detection},
  author={Huang, Chaoqin and Guan, Haoyan and Jiang, Aofan and Zhang, Ya and Spratling, Michael and Wang, Yan-Feng},
  journal={ECCV <strong style="color:#cc3333">(Oral)</strong>},
  pages={303--319},
  year={2022},
  code={https://github.com/MediaBrain-SJTU/RegAD},
  selected={true},
  abstract={This paper considers few-shot anomaly detection (FSAD), a practical yet under-studied setting for anomaly detection (AD), where only a limited number of normal images are provided for each category at training. So far, existing FSAD studies follow the one-model-per-category learning paradigm used for standard AD, and the inter-category commonality has not been explored. Inspired by how humans detect anomalies, i.e., comparing an image in question to normal images, we here leverage registration, an image alignment task that is inherently generalizable across categories, as the proxy task, to train a category-agnostic anomaly detection model. During testing, the anomalies are identified by comparing the registered features of the test image and its corresponding support (normal) images. As far as we know, this is the first FSAD method that trains a single generalizable model and requires no re-training or parameter fine-tuning for new categories.},
}




@inproceedings{cao2022oodhdr,
  abbr={AAAI},
  bibtex_show={false},
  author={Cao, Linfeng and Jiang, Aofan and Li, Wei and Wu, Huaying and Ye, Nanyang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  title={OoDHDR-Codec: Out-of-Distribution Generalization for HDR Image Compression},
  pages={158--166},
  year={2022},
  abstract={Recently, deep learning has been proven to be a promising approach in standard dynamic range (SDR) image compression. However, due to the wide luminance distribution of high dynamic range (HDR) images and the lack of large standard datasets, developing a deep model for HDR image compression is much more challenging. To tackle this issue, we view HDR data as distributional shifts of SDR data and the HDR image compression can be modeled as an out-of-distribution generalization (OoD) problem. Herein, we propose a novel out-of-distribution (OoD) HDR image compression framework (OoDHDR-codec). It learns the general representation across HDR and SDR environments, and allows the model to be trained effectively using a large set of SDR datases supplemented with much fewer HDR samples. Specifically, OoDHDR-codec consists of two branches to process the data from two environments. The SDR branch is a standard blackbox network. For the HDR branch, we develop a hybrid system that models luminance masking and tone mapping with white-box modules and performs content compression with black-box neural networks. To improve the generalization from SDR training data on HDR data, we introduce an invariance regularization term to learn the common representation for both SDR and HDR compression. Extensive experimental results show that the OoDHDR codec achieves strong competitive in-distribution performance and state-of-the-art OoD performance. To the best of our knowledge, our proposed approach is the first work to model HDR compression as OoD generalization problems and our OoD generalization algorithmic framework can be applied to any deep compression model in addition to the network architectural choice demonstrated in the paper. Code available at https://github.com/caolinfeng/OoDHDR-codec.},
  url={https://ojs.aaai.org/index.php/AAAI/article/view/19890},
}